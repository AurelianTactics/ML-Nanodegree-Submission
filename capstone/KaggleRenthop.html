<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<title>KaggleRenthop</title>

<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.6 (http://getbootstrap.com)
 * Copyright 2011-2015 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    color: #000 !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: thin dotted;
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: thin dotted;
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: thin dotted;
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.2.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.2.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.2.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.2.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.2.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.2.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=1);
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2);
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=3);
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1);
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1);
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
@media (max-width: 991px) {
  #ipython_notebook {
    margin-left: 10px;
  }
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#login_widget {
  float: right;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  text-align: center;
  vertical-align: middle;
  display: inline;
  opacity: 0;
  z-index: 2;
  width: 12ex;
  margin-right: -12ex;
}
.alternate_upload .btn-upload {
  height: 22px;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
ul#tabs {
  margin-bottom: 4px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: baseline;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
#tree-selector {
  padding-right: 0px;
}
#button-select-all {
  min-width: 50px;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
@-moz-document url-prefix() {
  div.inner_cell {
    overflow-x: hidden;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul {
  list-style: disc;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ul ul {
  list-style: square;
  margin: 0em 2em;
}
.rendered_html ul ul ul {
  list-style: circle;
  margin: 0em 2em;
}
.rendered_html ol {
  list-style: decimal;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
  margin: 0em 2em;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  background-color: #fff;
  color: #000;
  font-size: 100%;
  padding: 0px;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: 1px solid black;
  border-collapse: collapse;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  border: 1px solid black;
  border-collapse: collapse;
  margin: 1em 2em;
}
.rendered_html td,
.rendered_html th {
  text-align: left;
  vertical-align: middle;
  padding: 4px;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget {
  float: right !important;
  float: right;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 20ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  margin-top: 6px;
}
span.save_widget span.filename {
  height: 1em;
  line-height: 1em;
  padding: 3px;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  display: none;
}
.command-shortcut:before {
  content: "(command)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}

@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Udacity-Machine-Learning-Nanodegree-Capstone-Project">Udacity Machine Learning Nanodegree Capstone Project<a class="anchor-link" href="#Udacity-Machine-Learning-Nanodegree-Capstone-Project">&#182;</a></h1><p>Analysis of kaggle competition for <a href="https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries">renthop.com apartment listing data</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[66]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">Counter</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The train and test data sets are stored in json format. Import the data and convert it to pandas dataframes. Image data is handled later.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[219]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">json</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;renthop_train.json&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">json_data</span><span class="p">:</span>
    <span class="n">data_json</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">json_data</span><span class="p">)</span>
    
<span class="n">df_raw</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_records</span><span class="p">(</span><span class="n">data_json</span><span class="p">)</span>
<span class="n">df_raw</span><span class="p">[</span><span class="s2">&quot;created&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df_raw</span><span class="p">[</span><span class="s2">&quot;created&quot;</span><span class="p">])</span> <span class="c1">#changes feature to datetime, can access various elements easier in datetime format</span>

<span class="sd">&#39;&#39;&#39;with open(&#39;renthop_test.json&#39;) as json_data:</span>
<span class="sd">    test_data_json = json.load(json_data)</span>
<span class="sd">    </span>
<span class="sd">df_test = pd.DataFrame.from_records(test_data_json)&#39;&#39;&#39;</span>

<span class="n">df_raw</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt output_prompt">Out[219]:</div>

<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bathrooms</th>
      <th>bedrooms</th>
      <th>building_id</th>
      <th>created</th>
      <th>description</th>
      <th>display_address</th>
      <th>features</th>
      <th>interest_level</th>
      <th>latitude</th>
      <th>listing_id</th>
      <th>longitude</th>
      <th>manager_id</th>
      <th>photos</th>
      <th>price</th>
      <th>street_address</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>10</th>
      <td>1.5</td>
      <td>3</td>
      <td>53a5b119ba8f7b61d4e010512e0dfc85</td>
      <td>2016-06-24 07:54:24</td>
      <td>A Brand New 3 Bedroom 1.5 bath ApartmentEnjoy ...</td>
      <td>Metropolitan Avenue</td>
      <td>[]</td>
      <td>medium</td>
      <td>40.7145</td>
      <td>7211212</td>
      <td>-73.9425</td>
      <td>5ba989232d0489da1b5f2c45f6688adc</td>
      <td>[https://photos.renthop.com/2/7211212_1ed4542e...</td>
      <td>3000</td>
      <td>792 Metropolitan Avenue</td>
    </tr>
    <tr>
      <th>10000</th>
      <td>1.0</td>
      <td>2</td>
      <td>c5c8a357cba207596b04d1afd1e4f130</td>
      <td>2016-06-12 12:19:27</td>
      <td></td>
      <td>Columbus Avenue</td>
      <td>[Doorman, Elevator, Fitness Center, Cats Allow...</td>
      <td>low</td>
      <td>40.7947</td>
      <td>7150865</td>
      <td>-73.9667</td>
      <td>7533621a882f71e25173b27e3139d83d</td>
      <td>[https://photos.renthop.com/2/7150865_be3306c5...</td>
      <td>5465</td>
      <td>808 Columbus Avenue</td>
    </tr>
    <tr>
      <th>100004</th>
      <td>1.0</td>
      <td>1</td>
      <td>c3ba40552e2120b0acfc3cb5730bb2aa</td>
      <td>2016-04-17 03:26:41</td>
      <td>Top Top West Village location, beautiful Pre-w...</td>
      <td>W 13 Street</td>
      <td>[Laundry In Building, Dishwasher, Hardwood Flo...</td>
      <td>high</td>
      <td>40.7388</td>
      <td>6887163</td>
      <td>-74.0018</td>
      <td>d9039c43983f6e564b1482b273bd7b01</td>
      <td>[https://photos.renthop.com/2/6887163_de85c427...</td>
      <td>2850</td>
      <td>241 W 13 Street</td>
    </tr>
    <tr>
      <th>100007</th>
      <td>1.0</td>
      <td>1</td>
      <td>28d9ad350afeaab8027513a3e52ac8d5</td>
      <td>2016-04-18 02:22:02</td>
      <td>Building Amenities - Garage - Garden - fitness...</td>
      <td>East 49th Street</td>
      <td>[Hardwood Floors, No Fee]</td>
      <td>low</td>
      <td>40.7539</td>
      <td>6888711</td>
      <td>-73.9677</td>
      <td>1067e078446a7897d2da493d2f741316</td>
      <td>[https://photos.renthop.com/2/6888711_6e660cee...</td>
      <td>3275</td>
      <td>333 East 49th Street</td>
    </tr>
    <tr>
      <th>100013</th>
      <td>1.0</td>
      <td>4</td>
      <td>0</td>
      <td>2016-04-28 01:32:41</td>
      <td>Beautifully renovated 3 bedroom flex 4 bedroom...</td>
      <td>West 143rd Street</td>
      <td>[Pre-War]</td>
      <td>low</td>
      <td>40.8241</td>
      <td>6934781</td>
      <td>-73.9493</td>
      <td>98e13ad4b495b9613cef886d79a6291f</td>
      <td>[https://photos.renthop.com/2/6934781_1fa4b41a...</td>
      <td>3350</td>
      <td>500 West 143rd Street</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Benchmark-model:">Benchmark model:<a class="anchor-link" href="#Benchmark-model:">&#182;</a></h3><p>Predicts percentage of low, medium, high interest based on overall rates. Standard of comparison when exploring data and creating models.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[68]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">interest_counts</span> <span class="o">=</span> <span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">interest_counts</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">total_records</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df_raw</span><span class="p">))</span>
<span class="n">benchmark_dict</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)):</span>
    <span class="n">benchmark_dict</span><span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">interest_counts</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">/</span><span class="n">total_records</span>
    
<span class="nb">print</span><span class="p">(</span><span class="n">benchmark_dict</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>low       34284
medium    11229
high       3839
Name: interest_level, dtype: int64
{&#39;low&#39;: 0.6946830928837737, &#39;medium&#39;: 0.22752877289674178, &#39;high&#39;: 0.07778813421948452}
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="1.-Feature-Analysis,-Extraction,-and-Transformation">1. Feature Analysis, Extraction, and Transformation<a class="anchor-link" href="#1.-Feature-Analysis,-Extraction,-and-Transformation">&#182;</a></h2><p>In general, no outliers removed or modified. Even obviously mistaken entries can have predictive power on interest level as it can be an indicator of a poorly created apartment listing. Brief overview: <br/></p>
<ul>
<li>'bathrooms': no change <br/></li>
<li>'bedrooms': no change and added a feature that modified 0 bedroom entries (studio apartment) to roughly .83 <br/></li>
<li>'building_id': removed and replaced with counts that id shows up in data and results of the other listings <br/></li>
<li>'created': added features for hour, day of week, day of month, and month <br/></li>
<li>'description': removed and replaced with length of description feature <br/></li>
<li>'display_address': removed as location is provided by latitude and longitude <br/></li>
<li>'features': removed and replaced by length of number of features and one hot encoding of the 10 most popular features <br/></li>
<li>'interest_level': target variable <br/></li>
<li>'latitude/longitude': no change <br/></li>
<li>'listing_id': removed <br/></li>
<li>'manager_id': removed and replaced with counts that id shows up in data and results of the other listings <br/></li>
<li>'photos': removed and replaced by count of number of photos for that listing <br/></li>
<li>'price': no change and also added another field that also shows the price_per_bed <br/></li>
<li>'street_address': removed as location is provided by latitude and longitude <br/></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="1.1-Bathrooms,-Bedrooms,-and-Price">1.1 Bathrooms, Bedrooms, and Price<a class="anchor-link" href="#1.1-Bathrooms,-Bedrooms,-and-Price">&#182;</a></h3><p>Analysis of bathrooms led me to decide to keep almost all the outliers. In a way you could see 0 bathroom entries as an outlier or mistaken data entry. There is no 0 option bathroom button to click when making or searching for a listing on the renthop.com website. In looking at the descriptions of 0 bathroom listings, they do not appear to be the type of apartments that do not have any bathrooms. 0 bathroom entries are most likely a mistaken entry. In some data sets I would argue for excluding the 0 bathroom entries but here I think it makes sense to keep them. By comparing the interest count of 0 bathroom entries to the benchmark rate, 0 bathroom entries skew more heavily towards low interest. While a 0 bathroom entry may be a mistake or nonsense, it has a real effect on interest level and should be left in. Sloppy and unusual entries in many input features show a similar trend. Rather than eliminate them from the training set, it makes more sense to let them remain and be used to help predict interest level.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[69]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_numeric</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span> <span class="p">{</span><span class="s1">&#39;bathrooms&#39;</span><span class="p">:</span> <span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;bathrooms&#39;</span><span class="p">],</span><span class="s1">&#39;bedrooms&#39;</span><span class="p">:</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;bedrooms&#39;</span><span class="p">],</span><span class="s1">&#39;price&#39;</span><span class="p">:</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]})</span>
<span class="n">df_numeric</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt output_prompt">Out[69]:</div>

<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bathrooms</th>
      <th>bedrooms</th>
      <th>price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>49352.00000</td>
      <td>49352.000000</td>
      <td>4.935200e+04</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>1.21218</td>
      <td>1.541640</td>
      <td>3.830174e+03</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.50142</td>
      <td>1.115018</td>
      <td>2.206687e+04</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>4.300000e+01</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>1.00000</td>
      <td>1.000000</td>
      <td>2.500000e+03</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>1.00000</td>
      <td>1.000000</td>
      <td>3.150000e+03</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1.00000</td>
      <td>2.000000</td>
      <td>4.100000e+03</td>
    </tr>
    <tr>
      <th>max</th>
      <td>10.00000</td>
      <td>8.000000</td>
      <td>4.490000e+06</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[42]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Number of Bathrooms&quot;</span><span class="p">)</span>
<span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;bathrooms&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;hist&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Number of Bedrooms&quot;</span><span class="p">)</span>
<span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;bedrooms&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;hist&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Price&quot;</span><span class="p">)</span>
<span class="n">n</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">patches</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">],</span> <span class="mi">30</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">10000</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>


<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAZUAAAEICAYAAACXo2mmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

<div class="output_area"><div class="prompt"></div>


<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAZUAAAEICAYAAACXo2mmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz
AAALEgAACxIB0t1+/AAAHl5JREFUeJzt3X24XWV95vHvbYK8yptJMSTBk6mRNjA6QsTUlxZNlVgU
6IzQ0FJim0JbqNW+jCbWKdo2HWwdsXQGrlJAEgRiClLSAh0jFJ3Whnh4sSFASpSXJARyKmLAQjBw
zx/rObiyOSH7JGufdY65P9e1r/Ps31rPen5rE87vPGutvZZsExER0YRXtJ1ARET86EhRiYiIxqSo
REREY1JUIiKiMSkqERHRmBSViIhoTIpK7NEkXSHpT1oaW5I+L+m7klaNwHiflPSFXo8Te7YUlRhV
JD0kabOk/WuxX5N0W4tp9crbgXcDU2wf17lQ0gclPS/p6fL6tqTfHPk0I7qXohKj0Tjgw20nMVyS
xg2zy2uBh2x//2XW+RfbB9g+APhvwJ9JetMuJ7kDksY3vc3YM6WoxGj058DvSzq4c4GkPkmu/xKU
dJukXyvtD0r6Z0kXSHqy/HX/1hJfX2ZB8zo2O0HSCklPSfqqpNfWtv0TZdkTktZKOq227ApJF0u6
SdL3gXcOke/hkpaX/usknVXi84FLgZ8qs5BP7exDsX0XcB/wk7Xtz5L09bKv35R0fG3ZtLI/T0la
AUwY4nOcL+kR4NYSP0nSmrK92yTVx/rJEnuyrHNSx2dxkaSby/78s6TXSPpcObx3f70YSvqYpI0l
t7WSZu9s/2NsSFGJ0agfuA34/V3s/xbgX4FXA1cDS4E3A68DzgD+t6QDauv/EvDHVL907wauAiiH
4FaUbfwYMBe4SNKMWt9fBBYBrwL+aYhclgIbgMOBDwB/Kuldti8DfoMfzkTO29lOSXoz8HqqzwdJ
k4EbgT8BDqX6vK6TNLF0uRq4o+zXHwOdxRTgZ6iK1AmSXg9cA3wEmAjcBPydpFdK2gv4O+DL5bP4
EHCVpCNr2zoN+EQZbyvwL8Cd5f21wGdL3kcCvwW82fargBOAh3a2/zE2pKjEaPWHwIdqvyCH40Hb
n7f9PPBFYCrwR7a32v4y8BxVgRl0o+2v2d4K/AHV7GEq8D6qw1Oft72tzBSuA06t9b3B9j/bfsH2
s/UkyjbeBnzM9rO276aanZw5jH2ZVWYGTwGrgCuBB8qyM4CbbN9Uxl9BVXB+TtIRVIX0f5T9/hpV
Uej0Sdvft/0M8Avls1hh+wfAZ4B9gbcCs4ADgPNtP2f7VuDvgdNr27re9h3lc7geeNb2ktp/h8GZ
yvPA3sAMSXvZfsj2t4bxmcQolqISo5Lte6h+aS3Yhe6P19rPlO11xuozlfW1cZ8GnqCaWbwWeEv5
pf6kpCepZjWvGarvEA4HnrD9VC32MDB5GPuy0vbB5S/61wBHAX9alr0WOLUjv7cDk8rY3+04X/Pw
ENuv5394fR3bL5Tlk8uy9SW2o33p/IyH/Mxtr6OaDX0S2CxpqaTDd/wRxFiSohKj2XnAWWz/i2vw
l+R+tVj9l/yumDrYKIfFDgUepfqF+tXyS33wdYDt+hVYL3eb70eBQyW9qhY7Ati4K0mWwngd8P4S
Wg9c2ZHf/rbPBzYBh9Svoitjv2SzHfnWzyeJ6rPZWJZNlVT/nbE7+3K17beX8Qx8ele2E6NPikqM
WuUv2i8Cv12LDVD9IjtD0jhJvwr8+G4O9XOS3i7plVTnHlbaXk81U3q9pF+WtFd5vbl+8non+a8H
vg78T0n7SHoDMB/Ype+KSHo18PPAmhL6AvB+SSeUz2IfScdLmmL7YapDYZ8q50Tezg+L0Y4sA06U
NLucQ/k9qnMjXwduB/4D+Gj5HI4v21u6C/txpKR3SdobeJZqFvPCTrrFGJGiEqPdHwH7d8TOAv47
8B2qw0Ff380xrqaaFT0BHEt1roJy2Oo9VCfoHwUeo/qLeu9hbPt0oK/0vx44z/ZXhtF/8Oqwp6mu
/BqgOkk+WLROBj5e4uupPpfB/69/keqihSfK/i15uYFsr6Xa978E/p2qaLy/nEN5rrx/b1l2EXCm
7fuHsS+D9gbOL9t5jOrE/8Jd2E6MQspDuiIioimZqURERGNSVCIiojEpKhER0ZgUlYiIaMwedxO5
CRMmuK+vr+00IiLGlDvuuOPfbe/0Dhd7XFHp6+ujv7+/7TQiIsYUSUPdkeElcvgrIiIak6ISERGN
6VlRkXR5eXbFPR3xD5VnK6yR9Ge1+MLyvIm1kk6oxY+VtLosu7DcjwhJe0v6YonfLqmvV/sSERHd
6eVM5QpgTj0g6Z1Ut5V4o+2jqG6tTXk+xVyqW27MoXpmxeBT9C6mui3H9PIa3OZ8qruwvg64gNyQ
LiKidT0rKuX5DU90hH+T6nkMW8s6m0v8ZGBpee7Dg8A64DhJk4ADba90dT+ZJcAptT6LS/taYPbg
LCYiItox0udUXg+8oxyu+mp5kh1UtzavP9dhQ4lNLu3O+HZ9bG8Dvkf1pL+XkHS2pH5J/QMDA43t
TEREbG+ki8p4qmdVzKK6m+qykZhd2L7E9kzbMydO3JUHCUZERDdGuqhsAL7kyiqqZyhMoHo+xtTa
elNKbGNpd8ap95E0HjiI6lboERHRkpEuKn8LvBNA0uuBV1I9U2E5MLdc0TWN6oT8KtubgC2SZpUZ
zZnADWVby4F5pf0B4FbnPv4REa3q2TfqJV0DHA9MkLSB6iFBlwOXl8uMnwPmlUKwRtIy4F5gG3Cu
7efLps6hupJsX+Dm8gK4DLhS0jqqCwLm9mpfRoO+BTe2Mu5D55/YyrgRMTb1rKjYPn0Hi87YwfqL
gEVDxPuBo4eIPwucujs5RkREs/KN+oiIaEyKSkRENCZFJSIiGpOiEhERjUlRiYiIxqSoREREY1JU
IiKiMSkqERHRmBSViIhoTIpKREQ0JkUlIiIak6ISERGNSVGJiIjG9OwuxfGjoa1b7kNuux8xFmWm
EhERjUlRiYiIxqSoREREY1JUIiKiMT0rKpIul7S5PI++c9nvSbKkCbXYQknrJK2VdEItfqyk1WXZ
hZJU4ntL+mKJ3y6pr1f7EhER3enlTOUKYE5nUNJU4D3AI7XYDGAucFTpc5GkcWXxxcBZwPTyGtzm
fOC7tl8HXAB8uid7ERERXetZUbH9NeCJIRZdAHwUcC12MrDU9lbbDwLrgOMkTQIOtL3StoElwCm1
PotL+1pg9uAsJiIi2jGi51QknQxstP3NjkWTgfW19xtKbHJpd8a362N7G/A94NU7GPdsSf2S+gcG
BnZ7PyIiYmgjVlQk7Qd8HPjDkRpzkO1LbM+0PXPixIkjPXxExB5jJGcqPw5MA74p6SFgCnCnpNcA
G4GptXWnlNjG0u6MU+8jaTxwEPCdHuYfERE7MWJFxfZq2z9mu892H9WhrGNsPwYsB+aWK7qmUZ2Q
X2V7E7BF0qxyvuRM4IayyeXAvNL+AHBrOe8SEREt6eUlxdcA/wIcKWmDpPk7Wtf2GmAZcC/wD8C5
tp8vi88BLqU6ef8t4OYSvwx4taR1wO8CC3qyIxER0bWe3VDS9uk7Wd7X8X4RsGiI9fqBo4eIPwuc
untZRkREk/KN+oiIaEyKSkRENCZFJSIiGpOiEhERjUlRiYiIxqSoREREY1JUIiKiMSkqERHRmBSV
iIhoTIpKREQ0JkUlIiIak6ISERGNSVGJiIjGpKhERERjUlQiIqIxKSoREdGYFJWIiGhMLx8nfLmk
zZLuqcX+XNL9kv5V0vWSDq4tWyhpnaS1kk6oxY+VtLosu7A8q57yPPsvlvjtkvp6tS8REdGdXs5U
rgDmdMRWAEfbfgPwb8BCAEkzgLnAUaXPRZLGlT4XA2cB08trcJvzge/afh1wAfDpnu1JRER0pWdF
xfbXgCc6Yl+2va28XQlMKe2TgaW2t9p+EFgHHCdpEnCg7ZW2DSwBTqn1WVza1wKzB2cxERHRjjbP
qfwqcHNpTwbW15ZtKLHJpd0Z365PKVTfA1491ECSzpbUL6l/YGCgsR2IiIjttVJUJP0BsA24aiTG
s32J7Zm2Z06cOHEkhoyI2CONeFGR9EHgfcAvlUNaABuBqbXVppTYRn54iKwe366PpPHAQcB3epZ4
RETs1IgWFUlzgI8CJ9n+j9qi5cDcckXXNKoT8qtsbwK2SJpVzpecCdxQ6zOvtD8A3ForUhER0YLx
vdqwpGuA44EJkjYA51Fd7bU3sKKcU19p+zdsr5G0DLiX6rDYubafL5s6h+pKsn2pzsEMnoe5DLhS
0jqqCwLm9mpfIiKiOz0rKrZPHyJ82cusvwhYNES8Hzh6iPizwKm7k2NERDQr36iPiIjGpKhERERj
UlQiIqIxKSoREdGYFJWIiGhMikpERDQmRSUiIhqTohIREY1JUYmIiMakqERERGNSVCIiojEpKhER
0ZgUlYiIaEyKSkRENCZFJSIiGpOiEhERjUlRiYiIxvSsqEi6XNJmSffUYodKWiHpgfLzkNqyhZLW
SVor6YRa/FhJq8uyC8uz6inPs/9iid8uqa9X+xIREd3p5UzlCmBOR2wBcIvt6cAt5T2SZlA9Y/6o
0uciSeNKn4uBs4Dp5TW4zfnAd22/DrgA+HTP9iQiIrrSVVGR9J+Hu2HbXwOe6AifDCwu7cXAKbX4
UttbbT8IrAOOkzQJOND2StsGlnT0GdzWtcDswVlMRES0o9uZykWSVkk6R9JBuzHeYbY3lfZjwGGl
PRlYX1tvQ4lNLu3O+HZ9bG8Dvge8eqhBJZ0tqV9S/8DAwG6kHxERL6eromL7HcAvAVOBOyRdLend
uzNwmXl4d7YxjLEusT3T9syJEyeOxJAREXukrs+p2H4A+ATwMeBngAsl3S/pvw5jvMfLIS3Kz80l
vpGqYA2aUmIbS7szvl0fSeOBg4DvDCOXiIhoWLfnVN4g6QLgPuBdwPtt/2RpXzCM8ZYD80p7HnBD
LT63XNE1jeqE/KpyqGyLpFnlfMmZHX0Gt/UB4NYy+4mIiJaM73K9vwQuBT5u+5nBoO1HJX1iqA6S
rgGOByZI2gCcB5wPLJM0H3gYOK1sZ42kZcC9wDbgXNvPl02dQ3Ul2b7AzeUFcBlwpaR1VBcEzO1y
XyIioke6LSonAs8M/qKX9ApgH9v/YfvKoTrYPn0H25q9g/UXAYuGiPcDRw8RfxY4tbv0IyJiJHR7
TuUrVDOFQfuVWERExIu6nansY/vpwTe2n5a0X49yGrX6FtzYdgoREaNatzOV70s6ZvCNpGOBZ15m
/YiI2AN1O1P5CPA3kh4FBLwG+IWeZRUREWNSV0XF9jck/QRwZAmttf2D3qUVERFjUbczFYA3A32l
zzGSsL2kJ1lFRMSY1FVRkXQl8OPA3cDg90cGb/AYEREBdD9TmQnMyDfWIyLi5XR79dc9VCfnIyIi
dqjbmcoE4F5Jq4Ctg0HbJ/Ukq4iIGJO6LSqf7GUSERHxo6HbS4q/Kum1wHTbXynfph+3s34REbFn
6fbW92dRPbL3r0poMvC3vUoqIiLGpm5P1J8LvA3YAi8+sOvHepVURESMTd0Wla22nxt8U560mMuL
IyJiO90Wla9K+jiwb3k2/d8Af9e7tCIiYizqtqgsAAaA1cCvAzdRPa8+IiLiRV0VFdsv2P5r26fa
/kBp7/LhL0m/I2mNpHskXSNpH0mHSloh6YHy85Da+gslrZO0VtIJtfixklaXZReW59hHRERLur36
60FJ3+587cqAkiYDvw3MtH001aXJc6lmQ7fYng7cUt4jaUZZfhQwB7hI0uDlzBcDZwHTy2vOruQU
ERHNGM69vwbtQ/Vs+EN3c9x9Jf2A6tHEjwILgePL8sXAbcDHgJOBpba3Ag9KWgccJ+kh4EDbKwEk
LQFOAW7ejbwiImI3dHv46zu110bbnwNO3JUBbW8EPgM8AmwCvmf7y8BhtjeV1R4DDivtycD62iY2
lNjk0u6MR0RES7q99f0xtbevoJq5DOdZLPVtHUI1+5gGPEn1RMkz6uvYtqTGLlmWdDZwNsARRxzR
1GYjIqJDt4Xhf9Xa24CHgNN2ccyfBR60PQAg6UvAW4HHJU2yvUnSJGBzWX8jMLXWf0qJbSztzvhL
2L4EuARg5syZ+X5NRESPdHvvr3c2OOYjwKxy/7BngNlAP/B9YB5wfvl5Q1l/OXC1pM8Ch1OdkF9l
+3lJWyTNAm4HzgT+ssE8IyJimLo9/PW7L7fc9me7HdD27ZKuBe6kmvXcRTWLOABYJmk+8DBlJmR7
jaRlwL1l/XNtDz598hzgCmBfqhP0OUkfEdGi4Vz99WaqWQPA+4FVwAO7Mqjt84DzOsJbqWYtQ62/
CFg0RLwfOHpXcoiIiOZ1W1SmAMfYfgpA0ieBG22f8bK9IiJij9LtbVoOA56rvX+OH17yGxERAXQ/
U1kCrJJ0fXl/CtUXFCMiIl7U7dVfiyTdDLyjhH7F9l29SysiIsai4XyBcT9gi+3PS5ooaZrtB3uV
WETfghtbGfeh83fpZhERQfc3lDyP6j5cC0toL+ALvUoqIiLGpm5P1P88cBLVFxSx/Sjwql4lFRER
Y1O3ReW58vwUA0jav3cpRUTEWNVtUVkm6a+AgyWdBXwF+OvepRUREWNRt1d/faY8m34LcCTwh7ZX
9DSziIgYc3ZaVMpTFr9SbiqZQhIRETu008Nf5eaNL0g6aATyiYiIMazb76k8DayWtIJyBRiA7d/u
SVYRETEmdVtUvlReERERO/SyRUXSEbYfsZ37fEVExE7t7JzK3w42JF3X41wiImKM21lRUa39n3qZ
SEREjH07KyreQTsiIuIldlZU3ihpi6SngDeU9hZJT0nasquDSjpY0rWS7pd0n6SfknSopBWSHig/
D6mtv1DSOklrJZ1Qix8raXVZdqEkDT1iRESMhJctKrbH2T7Q9qtsjy/twfcH7sa4fwH8g+2fAN4I
3AcsAG6xPR24pbxH0gxgLnAUMAe4qHwhE+Bi4CxgennN2Y2cIiJiN3V776/GlC9R/jRwGYDt52w/
CZzMD58muZjq6ZKU+FLbW8vzW9YBx0maBBxoe2W52eWSWp+IiGjBiBcVYBowAHxe0l2SLi13PT7M
9qayzmPAYaU9GVhf67+hxCaXdmf8JSSdLalfUv/AwECDuxIREXVtFJXxwDHAxbbfRPUN/QX1Feq3
2W+C7Utsz7Q9c+LEiU1tNiIiOrRRVDYAG2zfXt5fS1VkHi+HtCg/N5flG4Gptf5TSmxjaXfGIyKi
JSNeVGw/BqyXdGQJzQbuBZYD80psHnBDaS8H5kraW9I0qhPyq8qhsi2SZpWrvs6s9YmIiBZ0e++v
pn0IuErSK4FvA79CVeCWSZoPPAycBmB7jaRlVIVnG3BuuXMywDnAFcC+wM3lFRERLWmlqNi+G5g5
xKLZO1h/EbBoiHg/cHSz2UVExK5q45xKRET8iEpRiYiIxqSoREREY1JUIiKiMSkqERHRmBSViIho
TIpKREQ0JkUlIiIak6ISERGNSVGJiIjGpKhERERjUlQiIqIxKSoREdGYFJWIiGhMikpERDQmRSUi
IhqTohIREY1prahIGifpLkl/X94fKmmFpAfKz0Nq6y6UtE7SWkkn1OLHSlpdll1YnlUfEREtaXOm
8mHgvtr7BcAttqcDt5T3SJoBzAWOAuYAF0kaV/pcDJwFTC+vOSOTekREDKWVoiJpCnAicGktfDKw
uLQXA6fU4kttb7X9ILAOOE7SJOBA2yttG1hS6xMRES1oa6byOeCjwAu12GG2N5X2Y8BhpT0ZWF9b
b0OJTS7tzvhLSDpbUr+k/oGBgQbSj4iIoYx4UZH0PmCz7Tt2tE6ZebipMW1fYnum7ZkTJ05sarMR
EdFhfAtjvg04SdLPAfsAB0r6AvC4pEm2N5VDW5vL+huBqbX+U0psY2l3xiMioiUjPlOxvdD2FNt9
VCfgb7V9BrAcmFdWmwfcUNrLgbmS9pY0jeqE/KpyqGyLpFnlqq8za30iIqIFbcxUduR8YJmk+cDD
wGkAttdIWgbcC2wDzrX9fOlzDnAFsC9wc3lFRERLWi0qtm8Dbivt7wCzd7DeImDREPF+4OjeZRgR
EcORb9RHRERjUlQiIqIxKSoREdGYFJWIiGhMikpERDQmRSUiIhqTohIREY1JUYmIiMakqERERGNS
VCIiojEpKhER0ZgUlYiIaEyKSkRENCZFJSIiGpOiEhERjUlRiYiIxqSoREREY0a8qEiaKukfJd0r
aY2kD5f4oZJWSHqg/Dyk1mehpHWS1ko6oRY/VtLqsuzC8qz6iIhoSRszlW3A79meAcwCzpU0A1gA
3GJ7OnBLeU9ZNhc4CpgDXCRpXNnWxcBZwPTymjOSOxIREdsb8aJie5PtO0v7KeA+YDJwMrC4rLYY
OKW0TwaW2t5q+0FgHXCcpEnAgbZX2jawpNYnIiJa0Oo5FUl9wJuA24HDbG8qix4DDivtycD6WrcN
JTa5tDvjERHRkvFtDSzpAOA64CO2t9RPh9i2JDc41tnA2QBHHHFEU5uNaFTfghtbG/uh809sbez4
0dLKTEXSXlQF5SrbXyrhx8shLcrPzSW+EZha6z6lxDaWdmf8JWxfYnum7ZkTJ05sbkciImI7bVz9
JeAy4D7bn60tWg7MK+15wA21+FxJe0uaRnVCflU5VLZF0qyyzTNrfSIiogVtHP56G/DLwGpJd5fY
x4HzgWWS5gMPA6cB2F4jaRlwL9WVY+fafr70Owe4AtgXuLm8IiKiJSNeVGz/E7Cj75PM3kGfRcCi
IeL9wNHNZRcREbsj36iPiIjGpKhERERjUlQiIqIxKSoREdGYFJWIiGhMikpERDQmRSUiIhqTohIR
EY1JUYmIiMakqERERGNSVCIiojEpKhER0ZgUlYiIaEyKSkRENCZFJSIiGpOiEhERjUlRiYiIxqSo
REREY9p4Rn2jJM0B/gIYB1xq+/yWU4oYc/oW3NjKuA+df2Ir40bvjOmZiqRxwP8B3gvMAE6XNKPd
rCIi9lxjfaZyHLDO9rcBJC0FTgbubTWriOhKWzMkyCypV8Z6UZkMrK+93wC8pXMlSWcDZ5e3T0ta
u4vjTQD+fRf79lLyGp6XzUufHsFMtjdaPy8Yvbntcl49/u/8I/d5Aa/tZqWxXlS6YvsS4JLd3Y6k
ftszG0ipUclreJLX8I3W3JLX8IxEXmP6nAqwEZhaez+lxCIiogVjvah8A5guaZqkVwJzgeUt5xQR
scca04e/bG+T9FvA/6W6pPhy22t6OORuH0LrkeQ1PMlr+EZrbslreHqel2z3eoyIiNhDjPXDXxER
MYqkqERERGNSVLokaY6ktZLWSVrQdj4Aki6XtFnSPW3nUidpqqR/lHSvpDWSPtx2TgCS9pG0StI3
S16fajunOknjJN0l6e/bzmWQpIckrZZ0t6T+tvMZJOlgSddKul/SfZJ+ahTkdGT5nAZfWyR9pO28
ACT9Tvk3f4+kayTt07Oxck5l58rtYP4NeDfVFyy/AZxuu9Vv7kv6aeBpYInto9vMpU7SJGCS7Tsl
vQq4AzhlFHxeAva3/bSkvYB/Aj5se2WbeQ2S9LvATOBA2+9rOx+oigow0/ao+iKfpMXA/7N9abny
cz/bT7ad16DyO2Mj8BbbD7ecy2Sqf+szbD8jaRlwk+0rejFeZirdefF2MLafAwZvB9Mq218Dnmg7
j062N9m+s7SfAu6juvtBq1x5urzdq7xGxV9VkqYAJwKXtp3LaCfpIOCngcsAbD83mgpKMRv4VtsF
pWY8sK+k8cB+wKO9GihFpTtD3Q6m9V+SY4GkPuBNwO3tZlIph5juBjYDK2yPiryAzwEfBV5oO5EO
Br4i6Y5yu6PRYBowAHy+HC68VNL+bSfVYS5wTdtJANjeCHwGeATYBHzP9pd7NV6KSvSMpAOA64CP
2N7Sdj4Atp+3/V+o7r5wnKTWDxtKeh+w2fYdbecyhLeXz+u9wLnlkGvbxgPHABfbfhPwfWBUnOcE
KIfjTgL+pu1cACQdQnVkZRpwOLC/pDN6NV6KSndyO5hhKucsrgOusv2ltvPpVA6X/CMwp+1cgLcB
J5XzF0uBd0n6QrspVcpfudjeDFxPdSi4bRuADbVZ5rVURWa0eC9wp+3H206k+FngQdsDtn8AfAl4
a68GS1HpTm4HMwzlhPhlwH22P9t2PoMkTZR0cGnvS3Xhxf3tZgW2F9qeYruP6t/WrbZ79pdktyTt
Xy60oBxeeg/Q+pWGth8D1ks6soRmM7oed3E6o+TQV/EIMEvSfuX/zdlU5zl7YkzfpmWktHA7mK5I
ugY4HpggaQNwnu3L2s0KqP7y/mVgdTl/AfBx2ze1mBPAJGBxuTLnFcAy26Pm8t1R6DDg+ur3EOOB
q23/Q7spvehDwFXlj7xvA7/Scj7Ai8X33cCvt53LINu3S7oWuBPYBtxFD2/XkkuKIyKiMTn8FRER
jUlRiYiIxqSoREREY1JUIiKiMSkqERHRmBSViIhoTIpKREQ05v8DGSWtjE/9XowAAAAASUVORK5C
YII=
"
>
</div>

</div>

<div class="output_area"><div class="prompt"></div>


<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYEAAAEICAYAAAC55kg0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz
AAALEgAACxIB0t1+/AAAFDBJREFUeJzt3X+s3fV93/HnqyYhLAkJHp7l2FbsbFYrgxR+3DJnqaou
rMUNWcwfG3KlFG8i+A/oluyHOnudtHWSJ1pNVYs22ChJMWsS6iZpcEG0I26yrdPAuSykYIOHE0Nt
y+AbppQkk2ig7/1xPoTTi8091773HnM+z4d0dD7f9/f7+frzAczrfj/f7zk3VYUkqU8/Mu4BSJLG
xxCQpI4ZApLUMUNAkjpmCEhSxwwBSeqYISDNU5IHk2wb9zikhRA/JyBBkmeAlcArwPeBB4FfqKrv
jXNc0mLzSkB6zd+tqncAVwBTwL8a3pkB/85oovgftDRLVR1ncCVwaZKvJtmV5H8C/w94X6t9/NXj
k9yU5Mkk301yMMkVrf6eJF9IMpPkSJJ/PJ4ZSadnCEizJFkLfBj4eiv9PLAdeCfw7Kxj/z7wb4Ab
gAuBjwIvtCuG3we+AawGrgY+meSaJZiCNDJDQHrNl5J8B/hj4L8B/67V766qA1X1clX9YFafjwO/
WlVfq4HDVfUs8OPAiqr6t1X151X1LeA3ga1LNRlpFOeNewDSOeS6qvrycCEJwNE36LMW+OYp6u8F
3tNC5VXLgP9xtoOUFpIhIM3tjR6hOwr89dPUj1TVhsUZkrQwXA6Szs5dwD9PcmV7euhvJHkvsB/4
bpJ/keSCJMuSXJrkx8c8XukvMQSks1BVvwvsAj4LfBf4ErC8ql4BPgJcBhwBvs0gMN41pqFKp+SH
xSSpY14JSFLHDAFJ6pghIEkdMwQkqWPn/OcELr744lq3bt24hyFJbyqPPvrot6tqxVzHnfMhsG7d
Oqanp8c9DEl6U0ny7NxHuRwkSV0zBCSpY4aAJHXMEJCkjhkCktQxQ0CSOmYISFLHDAFJ6pghIEkd
O+c/MazFsW7HAyMd98yt1y7ySCSNk1cCktQxQ0CSOmYISFLHvCegN+S9A2myeSUgSR0zBCSpY4aA
JHXMEJCkjhkCktQxQ0CSOmYISFLHRgqBJO9O8vkkTyV5MskHkixP8lCSp9v7RUPH70xyOMmhJNcM
1a9M8njbd1uSLMakJEmjGfVK4DeAP6iqHwPeDzwJ7AD2VdUGYF/bJslGYCtwCbAZuD3JsnaeO4Cb
gA3ttXmB5iFJOgNzhkCSdwE/CXwKoKr+vKq+A2wBdrfDdgPXtfYW4N6qeqmqjgCHgauSrAIurKqH
q6qAe4b6SJLGYJQrgfXADPBbSb6e5K4kbwdWVtWJdsxzwMrWXg0cHep/rNVWt/bs+usk2Z5kOsn0
zMzM6LORJM3LKCFwHnAFcEdVXQ58n7b086r2k30t1KCq6s6qmqqqqRUrVizUaSVJs4wSAseAY1X1
SNv+PINQeL4t8dDeT7b9x4G1Q/3XtNrx1p5dlySNyZwhUFXPAUeT/GgrXQ0cBPYC21ptG3Bfa+8F
tiY5P8l6BjeA97eloxeTbGpPBd0w1EeSNAajfpX0PwI+k+StwLeAf8ggQPYkuRF4FrgeoKoOJNnD
ICheBm6pqlfaeW4G7gYuAB5sL0nSmIwUAlX1GDB1il1Xn+b4XcCuU9SngUvnM0BJ0uLxE8OS1DFD
QJI6ZghIUscMAUnqmCEgSR0zBCSpY4aAJHXMEJCkjhkCktSxUb82QnpD63Y8MNJxz9x67SKPRNJ8
eCUgSR0zBCSpY4aAJHXMEJCkjhkCktQxQ0CSOmYISFLHDAFJ6pghIEkdMwQkqWOGgCR1zBCQpI4Z
ApLUsZFCIMkzSR5P8liS6VZbnuShJE+394uGjt+Z5HCSQ0muGapf2c5zOMltSbLwU5IkjWo+VwJ/
u6ouq6qptr0D2FdVG4B9bZskG4GtwCXAZuD2JMtanzuAm4AN7bX57KcgSTpTZ7MctAXY3dq7geuG
6vdW1UtVdQQ4DFyVZBVwYVU9XFUF3DPUR5I0BqOGQAFfTvJoku2ttrKqTrT2c8DK1l4NHB3qe6zV
Vrf27PrrJNmeZDrJ9MzMzIhDlCTN16i/Wewnqup4kr8GPJTkqeGdVVVJaqEGVVV3AncCTE1NLdh5
JUl/2UhXAlV1vL2fBH4PuAp4vi3x0N5PtsOPA2uHuq9pteOtPbsuSRqTOUMgyduTvPPVNvAzwBPA
XmBbO2wbcF9r7wW2Jjk/yXoGN4D3t6WjF5Nsak8F3TDUR5I0BqMsB60Efq89zXke8Nmq+oMkXwP2
JLkReBa4HqCqDiTZAxwEXgZuqapX2rluBu4GLgAebC9J0pjMGQJV9S3g/aeovwBcfZo+u4Bdp6hP
A5fOf5iSpMUw6o1haUGs2/HAyMc+c+u1izgSSeDXRkhS1wwBSeqYISBJHfOewISZz5q7JHklIEkd
MwQkqWOGgCR1zBCQpI4ZApLUMUNAkjpmCEhSxwwBSeqYISBJHTMEJKljhoAkdcwQkKSOGQKS1DFD
QJI6ZghIUscMAUnqmCEgSR0zBCSpYyOHQJJlSb6e5P62vTzJQ0mebu8XDR27M8nhJIeSXDNUvzLJ
423fbUmysNORJM3HfK4EPgE8ObS9A9hXVRuAfW2bJBuBrcAlwGbg9iTLWp87gJuADe21+axGL0k6
KyOFQJI1wLXAXUPlLcDu1t4NXDdUv7eqXqqqI8Bh4Kokq4ALq+rhqirgnqE+kqQxGPVK4NeBXwT+
Yqi2sqpOtPZzwMrWXg0cHTruWKutbu3Z9ddJsj3JdJLpmZmZEYcoSZqvOUMgyUeAk1X16OmOaT/Z
10INqqrurKqpqppasWLFQp1WkjTLeSMc80Hgo0k+DLwNuDDJbwPPJ1lVVSfaUs/JdvxxYO1Q/zWt
dry1Z9clSWMy55VAVe2sqjVVtY7BDd8/qqqPAXuBbe2wbcB9rb0X2Jrk/CTrGdwA3t+Wjl5Msqk9
FXTDUB9J0hiMciVwOrcCe5LcCDwLXA9QVQeS7AEOAi8Dt1TVK63PzcDdwAXAg+0lSRqTeYVAVX0V
+GprvwBcfZrjdgG7TlGfBi6d7yAlSYvDTwxLUscMAUnqmCEgSR0zBCSpY4aAJHXMEJCkjhkCktQx
Q0CSOmYISFLHDAFJ6pghIEkdO5svkNMSWrfjgXEPQdIE8kpAkjpmCEhSx1wO0jlr1CWwZ269dpFH
Ik0urwQkqWOGgCR1zBCQpI4ZApLUMUNAkjpmCEhSxwwBSeqYISBJHZszBJK8Lcn+JN9IciDJL7f6
8iQPJXm6vV801GdnksNJDiW5Zqh+ZZLH277bkmRxpiVJGsUoVwIvAR+qqvcDlwGbk2wCdgD7qmoD
sK9tk2QjsBW4BNgM3J5kWTvXHcBNwIb22ryAc5EkzdOcIVAD32ubb2mvArYAu1t9N3Bda28B7q2q
l6rqCHAYuCrJKuDCqnq4qgq4Z6iPJGkMRronkGRZkseAk8BDVfUIsLKqTrRDngNWtvZq4OhQ92Ot
trq1Z9dP9edtTzKdZHpmZmbkyUiS5mekEKiqV6rqMmANg5/qL521vxhcHSyIqrqzqqaqamrFihUL
dVpJ0izzejqoqr4DfIXBWv7zbYmH9n6yHXYcWDvUbU2rHW/t2XVJ0piM8nTQiiTvbu0LgJ8GngL2
AtvaYduA+1p7L7A1yflJ1jO4Aby/LR29mGRTeyrohqE+kqQxGOX3CawCdrcnfH4E2FNV9yf5X8Ce
JDcCzwLXA1TVgSR7gIPAy8AtVfVKO9fNwN3ABcCD7SVJGpM5Q6Cq/gS4/BT1F4CrT9NnF7DrFPVp
4NLX95AkjYOfGJakjhkCktQxQ0CSOmYISFLHDAFJ6pghIEkdMwQkqWOGgCR1zBCQpI4ZApLUMUNA
kjpmCEhSxwwBSeqYISBJHRvl9wlI57R1Ox4Y6bhnbr12kUcivfl4JSBJHTMEJKljhoAkdcwQkKSO
GQKS1DFDQJI6ZghIUscMAUnq2JwhkGRtkq8kOZjkQJJPtPryJA8lebq9XzTUZ2eSw0kOJblmqH5l
ksfbvtuSZHGmJUkaxShXAi8D/6yqNgKbgFuSbAR2APuqagOwr23T9m0FLgE2A7cnWdbOdQdwE7Ch
vTYv4FwkSfM0ZwhU1Ymq+t+t/V3gSWA1sAXY3Q7bDVzX2luAe6vqpao6AhwGrkqyCriwqh6uqgLu
GeojSRqDed0TSLIOuBx4BFhZVSfarueAla29Gjg61O1Yq61u7dn1U/0525NMJ5memZmZzxAlSfMw
cggkeQfwBeCTVfXi8L72k30t1KCq6s6qmqqqqRUrVizUaSVJs4z0LaJJ3sIgAD5TVV9s5eeTrKqq
E22p52SrHwfWDnVf02rHW3t2XVoSftuo9HqjPB0U4FPAk1X1a0O79gLbWnsbcN9QfWuS85OsZ3AD
eH9bOnoxyaZ2zhuG+kiSxmCUK4EPAj8PPJ7ksVb7l8CtwJ4kNwLPAtcDVNWBJHuAgwyeLLqlql5p
/W4G7gYuAB5sL0nSmMwZAlX1x8Dpnue/+jR9dgG7TlGfBi6dzwAlSYvHTwxLUscMAUnqmCEgSR0z
BCSpY4aAJHXMEJCkjo30iWGpJ36yWD3xSkCSOmYISFLHDAFJ6pghIEkdMwQkqWOGgCR1zBCQpI4Z
ApLUMT8sJp0hP1SmSeCVgCR1zBCQpI4ZApLUMUNAkjpmCEhSx3w6aMxGfcJEkhaDISAtMh8l1bls
zuWgJJ9OcjLJE0O15UkeSvJ0e79oaN/OJIeTHEpyzVD9yiSPt323JcnCT0eSNB+j3BO4G9g8q7YD
2FdVG4B9bZskG4GtwCWtz+1JlrU+dwA3ARvaa/Y5JUlLbM4QqKr/DvzfWeUtwO7W3g1cN1S/t6pe
qqojwGHgqiSrgAur6uGqKuCeoT6SpDE506eDVlbVidZ+DljZ2quBo0PHHWu11a09u35KSbYnmU4y
PTMzc4ZDlCTN5awfEW0/2dcCjGX4nHdW1VRVTa1YsWIhTy1JGnKmIfB8W+KhvZ9s9ePA2qHj1rTa
8daeXZckjdGZhsBeYFtrbwPuG6pvTXJ+kvUMbgDvb0tHLybZ1J4KumGojyRpTOb8nECSzwE/BVyc
5Bjwr4FbgT1JbgSeBa4HqKoDSfYAB4GXgVuq6pV2qpsZPGl0AfBge0lq5vPBQT9ToIWSwZL+uWtq
aqqmp6fHPYxF4yeGtZgMi34lebSqpuY6zu8OkqSOGQKS1DFDQJI6ZghIUscMAUnqmCEgSR0zBCSp
Y4aAJHXM3ywmTTB/q5nm4pWAJHXMEJCkjhkCktQxQ0CSOmYISFLHfDpI0sh82mjyeCUgSR3zSkCS
v9yoY14JSFLHDAFJ6pjLQZIW3ELfQJ7PcpU3pefHEFgErq9Ko/HvyvgZApK0hM61x2wNAUkTZVxL
UW/WZaglD4Ekm4HfAJYBd1XVrUs9Bkla6KWoN+vS1pI+HZRkGfAfgZ8FNgI/l2TjUo5BkvSapb4S
uAo4XFXfAkhyL7AFOLjE4zgjb9akl6TTWeoQWA0cHdo+BvzN2Qcl2Q5sb5vfS3LoDP+8i4Fvn2Hf
Nyvn3Ife5tzbfMmvnPWc3zvKQefkjeGquhO482zPk2S6qqYWYEhvGs65D73Nubf5wtLNeak/MXwc
WDu0vabVJEljsNQh8DVgQ5L1Sd4KbAX2LvEYJEnNki4HVdXLSX4B+EMGj4h+uqoOLOIfedZLSm9C
zrkPvc25t/nCEs05VbUUf44k6Rzkt4hKUscMAUnq2ESGQJLNSQ4lOZxkx7jHczaSrE3ylSQHkxxI
8olWX57koSRPt/eLhvrsbHM/lOSaofqVSR5v+25LknHMaRRJliX5epL72/ZEzxcgybuTfD7JU0me
TPKBSZ53kn/S/pt+Isnnkrxt0uab5NNJTiZ5Yqi2YHNMcn6S32n1R5Ksm/cgq2qiXgxuOH8TeB/w
VuAbwMZxj+ss5rMKuKK13wn8HwZfufGrwI5W3wH8SmtvbHM+H1jf/lksa/v2A5uAAA8CPzvu+b3B
vP8p8Fng/rY90fNt490NfLy13wq8e1LnzeCDo0eAC9r2HuAfTNp8gZ8ErgCeGKot2ByBm4H/1Npb
gd+Z9xjH/Q9pEf6hfwD4w6HtncDOcY9rAed3H/DTwCFgVautAg6dar4MnsT6QDvmqaH6zwH/edzz
Oc0c1wD7gA8NhcDEzreN713tf4qZVZ/IefPatwcsZ/CU4v3Az0zifIF1s0Jgweb46jGtfR6DTxhn
PuObxOWgU301xeoxjWVBtUu9y4FHgJVVdaLteg5Y2dqnm//q1p5dPxf9OvCLwF8M1SZ5vjD4yW8G
+K22DHZXkrczofOuquPAvwf+FDgB/FlV/VcmdL6zLOQcf9inql4G/gz4q/MZzCSGwERK8g7gC8An
q+rF4X01+DFgIp71TfIR4GRVPXq6YyZpvkPOY7BscEdVXQ58n8FSwQ9N0rzbOvgWBuH3HuDtST42
fMwkzfd0zoU5TmIITNxXUyR5C4MA+ExVfbGVn0+yqu1fBZxs9dPN/3hrz66faz4IfDTJM8C9wIeS
/DaTO99XHQOOVdUjbfvzDEJhUuf9d4AjVTVTVT8Avgj8LSZ3vsMWco4/7JPkPAbLii/MZzCTGAIT
9dUU7SmATwFPVtWvDe3aC2xr7W0M7hW8Wt/anhpYD2wA9rfLzxeTbGrnvGGozzmjqnZW1ZqqWsfg
390fVdXHmND5vqqqngOOJvnRVrqawVesT+q8/xTYlOSvtHFeDTzJ5M532ELOcfhcf4/B35f5XVmM
+6bJIt2I+TCDp2i+CfzSuMdzlnP5CQaXi38CPNZeH2aw7rcPeBr4MrB8qM8vtbkfYuhJCWAKeKLt
+w/M8wbSGOb+U7x2Y7iH+V4GTLd/118CLprkeQO/DDzVxvpfGDwVM1HzBT7H4J7HDxhc7d24kHME
3gb8LnCYwRNE75vvGP3aCEnq2CQuB0mSRmQISFLHDAFJ6pghIEkdMwQkqWOGgCR1zBCQpI79f5dD
U5woL6Y4AAAAAElFTkSuQmCC
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Outlier analysis. Due to the reasons listed above, I decided to keep all bathroom and bedroom outliers. Using the 1.5 IQR range, about 20% of bathroom entries are outliers (basically anything not 1 bathroom) and 5% of bedroom entries are outliers.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[25]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#outlier tests</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="k">import</span> <span class="n">display</span> 

<span class="k">def</span> <span class="nf">find_outliers</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="n">iqr_range</span><span class="p">):</span>
    <span class="c1"># For each feature find the data points with extreme high or low values</span>
    <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="c1">#Calculate Q1 (25th percentile of the data) for the given feature</span>
        <span class="n">Q1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">feature</span><span class="p">],</span> <span class="mi">25</span><span class="p">)</span>
        <span class="c1">#Calculate Q3 (75th percentile of the data) for the given feature</span>
        <span class="n">Q3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">feature</span><span class="p">],</span> <span class="mi">75</span><span class="p">)</span>
        <span class="c1">#Use the interquartile range to calculate an outlier step</span>
        <span class="n">step</span> <span class="o">=</span> <span class="p">(</span><span class="n">Q3</span><span class="o">-</span><span class="n">Q1</span><span class="p">)</span><span class="o">*</span><span class="n">iqr_range</span>
        <span class="k">if</span> <span class="n">step</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">step</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">feature</span><span class="p">])</span> <span class="o">*</span> <span class="n">iqr_range</span>
        <span class="c1"># Display the outliers</span>
        <span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;Data points considered outliers for the feature &#39;</span><span class="si">{}</span><span class="s2">&#39;:&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">feature</span><span class="p">))</span>
        <span class="n">display</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="o">~</span><span class="p">((</span><span class="n">df</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">Q1</span> <span class="o">-</span> <span class="n">step</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">Q3</span> <span class="o">+</span> <span class="n">step</span><span class="p">))])</span>
        
<span class="n">find_outliers</span><span class="p">(</span><span class="n">df_numeric</span><span class="p">,</span><span class="mf">1.5</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Data points considered outliers for the feature &#39;bathrooms&#39;:
</pre>
</div>
</div>

<div class="output_area"><div class="prompt"></div>

<div class="output_html rendered_html output_subarea ">
<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bathrooms</th>
      <th>bedrooms</th>
      <th>price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>100014</th>
      <td>2.0</td>
      <td>4</td>
      <td>7995</td>
    </tr>
    <tr>
      <th>100020</th>
      <td>2.0</td>
      <td>1</td>
      <td>5645</td>
    </tr>
    <tr>
      <th>100027</th>
      <td>2.0</td>
      <td>4</td>
      <td>5800</td>
    </tr>
    <tr>
      <th>100048</th>
      <td>2.0</td>
      <td>2</td>
      <td>6895</td>
    </tr>
    <tr>
      <th>10007</th>
      <td>2.0</td>
      <td>4</td>
      <td>7400</td>
    </tr>
    <tr>
      <th>100071</th>
      <td>3.5</td>
      <td>4</td>
      <td>7500</td>
    </tr>
    <tr>
      <th>100081</th>
      <td>2.0</td>
      <td>2</td>
      <td>5600</td>
    </tr>
    <tr>
      <th>100099</th>
      <td>2.0</td>
      <td>2</td>
      <td>6500</td>
    </tr>
    <tr>
      <th>100102</th>
      <td>3.0</td>
      <td>4</td>
      <td>15000</td>
    </tr>
    <tr>
      <th>100136</th>
      <td>2.0</td>
      <td>2</td>
      <td>2100</td>
    </tr>
    <tr>
      <th>100166</th>
      <td>2.0</td>
      <td>2</td>
      <td>5700</td>
    </tr>
    <tr>
      <th>100177</th>
      <td>2.0</td>
      <td>3</td>
      <td>6320</td>
    </tr>
    <tr>
      <th>100181</th>
      <td>2.0</td>
      <td>2</td>
      <td>4600</td>
    </tr>
    <tr>
      <th>100182</th>
      <td>2.0</td>
      <td>2</td>
      <td>7800</td>
    </tr>
    <tr>
      <th>100184</th>
      <td>2.0</td>
      <td>2</td>
      <td>7000</td>
    </tr>
    <tr>
      <th>100203</th>
      <td>3.5</td>
      <td>4</td>
      <td>13500</td>
    </tr>
    <tr>
      <th>100215</th>
      <td>2.0</td>
      <td>3</td>
      <td>4900</td>
    </tr>
    <tr>
      <th>100227</th>
      <td>2.0</td>
      <td>3</td>
      <td>3850</td>
    </tr>
    <tr>
      <th>100235</th>
      <td>2.0</td>
      <td>2</td>
      <td>4823</td>
    </tr>
    <tr>
      <th>100253</th>
      <td>2.0</td>
      <td>2</td>
      <td>3250</td>
    </tr>
    <tr>
      <th>100254</th>
      <td>2.0</td>
      <td>2</td>
      <td>5020</td>
    </tr>
    <tr>
      <th>100263</th>
      <td>2.0</td>
      <td>2</td>
      <td>6475</td>
    </tr>
    <tr>
      <th>100265</th>
      <td>2.0</td>
      <td>4</td>
      <td>5300</td>
    </tr>
    <tr>
      <th>100274</th>
      <td>2.0</td>
      <td>4</td>
      <td>5900</td>
    </tr>
    <tr>
      <th>100282</th>
      <td>2.0</td>
      <td>3</td>
      <td>2000</td>
    </tr>
    <tr>
      <th>100305</th>
      <td>2.0</td>
      <td>2</td>
      <td>5495</td>
    </tr>
    <tr>
      <th>100308</th>
      <td>2.0</td>
      <td>3</td>
      <td>3462</td>
    </tr>
    <tr>
      <th>100310</th>
      <td>2.0</td>
      <td>1</td>
      <td>8400</td>
    </tr>
    <tr>
      <th>100335</th>
      <td>2.0</td>
      <td>3</td>
      <td>6000</td>
    </tr>
    <tr>
      <th>100343</th>
      <td>2.0</td>
      <td>3</td>
      <td>4500</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>99630</th>
      <td>2.0</td>
      <td>2</td>
      <td>4800</td>
    </tr>
    <tr>
      <th>99647</th>
      <td>3.0</td>
      <td>4</td>
      <td>13700</td>
    </tr>
    <tr>
      <th>99653</th>
      <td>3.0</td>
      <td>3</td>
      <td>10000</td>
    </tr>
    <tr>
      <th>99654</th>
      <td>2.0</td>
      <td>3</td>
      <td>6100</td>
    </tr>
    <tr>
      <th>99659</th>
      <td>2.0</td>
      <td>2</td>
      <td>9500</td>
    </tr>
    <tr>
      <th>99663</th>
      <td>3.0</td>
      <td>3</td>
      <td>10250</td>
    </tr>
    <tr>
      <th>99665</th>
      <td>2.0</td>
      <td>4</td>
      <td>5200</td>
    </tr>
    <tr>
      <th>99672</th>
      <td>2.0</td>
      <td>2</td>
      <td>3200</td>
    </tr>
    <tr>
      <th>99683</th>
      <td>2.0</td>
      <td>2</td>
      <td>3400</td>
    </tr>
    <tr>
      <th>99684</th>
      <td>2.0</td>
      <td>0</td>
      <td>6800</td>
    </tr>
    <tr>
      <th>99702</th>
      <td>2.0</td>
      <td>4</td>
      <td>2595</td>
    </tr>
    <tr>
      <th>99704</th>
      <td>2.0</td>
      <td>4</td>
      <td>6100</td>
    </tr>
    <tr>
      <th>99737</th>
      <td>2.0</td>
      <td>3</td>
      <td>4200</td>
    </tr>
    <tr>
      <th>99751</th>
      <td>2.0</td>
      <td>2</td>
      <td>3500</td>
    </tr>
    <tr>
      <th>99759</th>
      <td>2.0</td>
      <td>3</td>
      <td>5100</td>
    </tr>
    <tr>
      <th>99768</th>
      <td>0.0</td>
      <td>2</td>
      <td>15000</td>
    </tr>
    <tr>
      <th>99773</th>
      <td>2.0</td>
      <td>3</td>
      <td>5000</td>
    </tr>
    <tr>
      <th>99778</th>
      <td>2.0</td>
      <td>2</td>
      <td>12500</td>
    </tr>
    <tr>
      <th>99789</th>
      <td>2.5</td>
      <td>3</td>
      <td>3700</td>
    </tr>
    <tr>
      <th>99793</th>
      <td>2.0</td>
      <td>1</td>
      <td>1575</td>
    </tr>
    <tr>
      <th>99812</th>
      <td>2.0</td>
      <td>3</td>
      <td>4535</td>
    </tr>
    <tr>
      <th>99861</th>
      <td>2.0</td>
      <td>3</td>
      <td>4500</td>
    </tr>
    <tr>
      <th>99875</th>
      <td>2.0</td>
      <td>3</td>
      <td>6275</td>
    </tr>
    <tr>
      <th>99876</th>
      <td>2.0</td>
      <td>2</td>
      <td>3500</td>
    </tr>
    <tr>
      <th>99890</th>
      <td>2.0</td>
      <td>1</td>
      <td>2275</td>
    </tr>
    <tr>
      <th>99911</th>
      <td>2.0</td>
      <td>2</td>
      <td>10650</td>
    </tr>
    <tr>
      <th>99923</th>
      <td>2.0</td>
      <td>2</td>
      <td>11950</td>
    </tr>
    <tr>
      <th>99956</th>
      <td>2.0</td>
      <td>2</td>
      <td>5815</td>
    </tr>
    <tr>
      <th>99961</th>
      <td>2.0</td>
      <td>3</td>
      <td>4600</td>
    </tr>
    <tr>
      <th>99965</th>
      <td>2.0</td>
      <td>3</td>
      <td>9200</td>
    </tr>
  </tbody>
</table>
<p>9285 rows  3 columns</p>
</div>
</div>

</div>

<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Data points considered outliers for the feature &#39;bedrooms&#39;:
</pre>
</div>
</div>

<div class="output_area"><div class="prompt"></div>

<div class="output_html rendered_html output_subarea ">
<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bathrooms</th>
      <th>bedrooms</th>
      <th>price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>100013</th>
      <td>1.0</td>
      <td>4</td>
      <td>3350</td>
    </tr>
    <tr>
      <th>100014</th>
      <td>2.0</td>
      <td>4</td>
      <td>7995</td>
    </tr>
    <tr>
      <th>100027</th>
      <td>2.0</td>
      <td>4</td>
      <td>5800</td>
    </tr>
    <tr>
      <th>100055</th>
      <td>1.0</td>
      <td>4</td>
      <td>5000</td>
    </tr>
    <tr>
      <th>10007</th>
      <td>2.0</td>
      <td>4</td>
      <td>7400</td>
    </tr>
    <tr>
      <th>100071</th>
      <td>3.5</td>
      <td>4</td>
      <td>7500</td>
    </tr>
    <tr>
      <th>100102</th>
      <td>3.0</td>
      <td>4</td>
      <td>15000</td>
    </tr>
    <tr>
      <th>100203</th>
      <td>3.5</td>
      <td>4</td>
      <td>13500</td>
    </tr>
    <tr>
      <th>100265</th>
      <td>2.0</td>
      <td>4</td>
      <td>5300</td>
    </tr>
    <tr>
      <th>100274</th>
      <td>2.0</td>
      <td>4</td>
      <td>5900</td>
    </tr>
    <tr>
      <th>100356</th>
      <td>2.0</td>
      <td>4</td>
      <td>5800</td>
    </tr>
    <tr>
      <th>100465</th>
      <td>1.0</td>
      <td>4</td>
      <td>5800</td>
    </tr>
    <tr>
      <th>100553</th>
      <td>2.0</td>
      <td>4</td>
      <td>5800</td>
    </tr>
    <tr>
      <th>100619</th>
      <td>1.0</td>
      <td>4</td>
      <td>3200</td>
    </tr>
    <tr>
      <th>100772</th>
      <td>2.0</td>
      <td>4</td>
      <td>3700</td>
    </tr>
    <tr>
      <th>10082</th>
      <td>3.0</td>
      <td>5</td>
      <td>11257</td>
    </tr>
    <tr>
      <th>100852</th>
      <td>1.0</td>
      <td>4</td>
      <td>4500</td>
    </tr>
    <tr>
      <th>100911</th>
      <td>3.0</td>
      <td>4</td>
      <td>6100</td>
    </tr>
    <tr>
      <th>100931</th>
      <td>2.0</td>
      <td>4</td>
      <td>6500</td>
    </tr>
    <tr>
      <th>100951</th>
      <td>1.0</td>
      <td>5</td>
      <td>6000</td>
    </tr>
    <tr>
      <th>100960</th>
      <td>2.0</td>
      <td>4</td>
      <td>4820</td>
    </tr>
    <tr>
      <th>100987</th>
      <td>3.0</td>
      <td>4</td>
      <td>6250</td>
    </tr>
    <tr>
      <th>101034</th>
      <td>4.0</td>
      <td>5</td>
      <td>9400</td>
    </tr>
    <tr>
      <th>101050</th>
      <td>2.0</td>
      <td>4</td>
      <td>5970</td>
    </tr>
    <tr>
      <th>101143</th>
      <td>1.0</td>
      <td>4</td>
      <td>3395</td>
    </tr>
    <tr>
      <th>101150</th>
      <td>2.0</td>
      <td>4</td>
      <td>5825</td>
    </tr>
    <tr>
      <th>101174</th>
      <td>2.0</td>
      <td>4</td>
      <td>4900</td>
    </tr>
    <tr>
      <th>101178</th>
      <td>2.0</td>
      <td>4</td>
      <td>4900</td>
    </tr>
    <tr>
      <th>101211</th>
      <td>1.0</td>
      <td>4</td>
      <td>5400</td>
    </tr>
    <tr>
      <th>101277</th>
      <td>2.0</td>
      <td>4</td>
      <td>5800</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>98432</th>
      <td>2.0</td>
      <td>4</td>
      <td>7958</td>
    </tr>
    <tr>
      <th>98505</th>
      <td>2.0</td>
      <td>4</td>
      <td>7995</td>
    </tr>
    <tr>
      <th>98531</th>
      <td>2.0</td>
      <td>5</td>
      <td>6000</td>
    </tr>
    <tr>
      <th>98654</th>
      <td>2.0</td>
      <td>4</td>
      <td>6000</td>
    </tr>
    <tr>
      <th>98665</th>
      <td>2.0</td>
      <td>4</td>
      <td>5495</td>
    </tr>
    <tr>
      <th>98752</th>
      <td>3.5</td>
      <td>4</td>
      <td>15000</td>
    </tr>
    <tr>
      <th>9882</th>
      <td>2.0</td>
      <td>5</td>
      <td>12000</td>
    </tr>
    <tr>
      <th>98823</th>
      <td>2.5</td>
      <td>4</td>
      <td>5995</td>
    </tr>
    <tr>
      <th>98866</th>
      <td>3.0</td>
      <td>4</td>
      <td>11955</td>
    </tr>
    <tr>
      <th>98924</th>
      <td>4.0</td>
      <td>4</td>
      <td>12000</td>
    </tr>
    <tr>
      <th>98948</th>
      <td>2.0</td>
      <td>4</td>
      <td>8000</td>
    </tr>
    <tr>
      <th>98998</th>
      <td>1.5</td>
      <td>4</td>
      <td>3000</td>
    </tr>
    <tr>
      <th>99069</th>
      <td>4.0</td>
      <td>4</td>
      <td>16000</td>
    </tr>
    <tr>
      <th>99086</th>
      <td>2.0</td>
      <td>5</td>
      <td>3200</td>
    </tr>
    <tr>
      <th>99158</th>
      <td>2.0</td>
      <td>4</td>
      <td>5300</td>
    </tr>
    <tr>
      <th>99199</th>
      <td>5.5</td>
      <td>4</td>
      <td>30000</td>
    </tr>
    <tr>
      <th>99218</th>
      <td>3.0</td>
      <td>4</td>
      <td>8495</td>
    </tr>
    <tr>
      <th>99330</th>
      <td>1.0</td>
      <td>4</td>
      <td>5250</td>
    </tr>
    <tr>
      <th>99332</th>
      <td>2.0</td>
      <td>5</td>
      <td>7794</td>
    </tr>
    <tr>
      <th>99354</th>
      <td>2.0</td>
      <td>4</td>
      <td>2850</td>
    </tr>
    <tr>
      <th>99381</th>
      <td>1.5</td>
      <td>4</td>
      <td>3495</td>
    </tr>
    <tr>
      <th>9947</th>
      <td>3.0</td>
      <td>4</td>
      <td>14800</td>
    </tr>
    <tr>
      <th>99527</th>
      <td>2.0</td>
      <td>4</td>
      <td>6200</td>
    </tr>
    <tr>
      <th>9958</th>
      <td>1.0</td>
      <td>4</td>
      <td>3500</td>
    </tr>
    <tr>
      <th>99647</th>
      <td>3.0</td>
      <td>4</td>
      <td>13700</td>
    </tr>
    <tr>
      <th>99665</th>
      <td>2.0</td>
      <td>4</td>
      <td>5200</td>
    </tr>
    <tr>
      <th>99702</th>
      <td>2.0</td>
      <td>4</td>
      <td>2595</td>
    </tr>
    <tr>
      <th>99704</th>
      <td>2.0</td>
      <td>4</td>
      <td>6100</td>
    </tr>
    <tr>
      <th>99763</th>
      <td>1.0</td>
      <td>4</td>
      <td>5400</td>
    </tr>
    <tr>
      <th>99824</th>
      <td>1.0</td>
      <td>4</td>
      <td>5795</td>
    </tr>
  </tbody>
</table>
<p>2226 rows  3 columns</p>
</div>
</div>

</div>

<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Data points considered outliers for the feature &#39;price&#39;:
</pre>
</div>
</div>

<div class="output_area"><div class="prompt"></div>

<div class="output_html rendered_html output_subarea ">
<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bathrooms</th>
      <th>bedrooms</th>
      <th>price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>100014</th>
      <td>2.0</td>
      <td>4</td>
      <td>7995</td>
    </tr>
    <tr>
      <th>100048</th>
      <td>2.0</td>
      <td>2</td>
      <td>6895</td>
    </tr>
    <tr>
      <th>10007</th>
      <td>2.0</td>
      <td>4</td>
      <td>7400</td>
    </tr>
    <tr>
      <th>100071</th>
      <td>3.5</td>
      <td>4</td>
      <td>7500</td>
    </tr>
    <tr>
      <th>100102</th>
      <td>3.0</td>
      <td>4</td>
      <td>15000</td>
    </tr>
    <tr>
      <th>100182</th>
      <td>2.0</td>
      <td>2</td>
      <td>7800</td>
    </tr>
    <tr>
      <th>100184</th>
      <td>2.0</td>
      <td>2</td>
      <td>7000</td>
    </tr>
    <tr>
      <th>100203</th>
      <td>3.5</td>
      <td>4</td>
      <td>13500</td>
    </tr>
    <tr>
      <th>100310</th>
      <td>2.0</td>
      <td>1</td>
      <td>8400</td>
    </tr>
    <tr>
      <th>100324</th>
      <td>1.0</td>
      <td>3</td>
      <td>13500</td>
    </tr>
    <tr>
      <th>100457</th>
      <td>2.5</td>
      <td>3</td>
      <td>15500</td>
    </tr>
    <tr>
      <th>100463</th>
      <td>2.0</td>
      <td>3</td>
      <td>8200</td>
    </tr>
    <tr>
      <th>100694</th>
      <td>3.0</td>
      <td>3</td>
      <td>14000</td>
    </tr>
    <tr>
      <th>100710</th>
      <td>1.0</td>
      <td>0</td>
      <td>6650</td>
    </tr>
    <tr>
      <th>100721</th>
      <td>2.0</td>
      <td>2</td>
      <td>7930</td>
    </tr>
    <tr>
      <th>100748</th>
      <td>1.0</td>
      <td>2</td>
      <td>7000</td>
    </tr>
    <tr>
      <th>100818</th>
      <td>2.0</td>
      <td>2</td>
      <td>7000</td>
    </tr>
    <tr>
      <th>10082</th>
      <td>3.0</td>
      <td>5</td>
      <td>11257</td>
    </tr>
    <tr>
      <th>100826</th>
      <td>2.0</td>
      <td>2</td>
      <td>13000</td>
    </tr>
    <tr>
      <th>100833</th>
      <td>3.0</td>
      <td>3</td>
      <td>15000</td>
    </tr>
    <tr>
      <th>100860</th>
      <td>2.0</td>
      <td>3</td>
      <td>7500</td>
    </tr>
    <tr>
      <th>100885</th>
      <td>2.0</td>
      <td>3</td>
      <td>7000</td>
    </tr>
    <tr>
      <th>100940</th>
      <td>3.0</td>
      <td>3</td>
      <td>11077</td>
    </tr>
    <tr>
      <th>100979</th>
      <td>2.0</td>
      <td>3</td>
      <td>7000</td>
    </tr>
    <tr>
      <th>101013</th>
      <td>2.0</td>
      <td>2</td>
      <td>6800</td>
    </tr>
    <tr>
      <th>101034</th>
      <td>4.0</td>
      <td>5</td>
      <td>9400</td>
    </tr>
    <tr>
      <th>101075</th>
      <td>2.0</td>
      <td>3</td>
      <td>9600</td>
    </tr>
    <tr>
      <th>101199</th>
      <td>2.0</td>
      <td>3</td>
      <td>11500</td>
    </tr>
    <tr>
      <th>10146</th>
      <td>2.5</td>
      <td>4</td>
      <td>6900</td>
    </tr>
    <tr>
      <th>101469</th>
      <td>3.0</td>
      <td>3</td>
      <td>13995</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>98752</th>
      <td>3.5</td>
      <td>4</td>
      <td>15000</td>
    </tr>
    <tr>
      <th>9882</th>
      <td>2.0</td>
      <td>5</td>
      <td>12000</td>
    </tr>
    <tr>
      <th>98866</th>
      <td>3.0</td>
      <td>4</td>
      <td>11955</td>
    </tr>
    <tr>
      <th>98924</th>
      <td>4.0</td>
      <td>4</td>
      <td>12000</td>
    </tr>
    <tr>
      <th>98948</th>
      <td>2.0</td>
      <td>4</td>
      <td>8000</td>
    </tr>
    <tr>
      <th>98972</th>
      <td>1.0</td>
      <td>3</td>
      <td>6600</td>
    </tr>
    <tr>
      <th>99013</th>
      <td>2.0</td>
      <td>2</td>
      <td>9500</td>
    </tr>
    <tr>
      <th>99039</th>
      <td>2.0</td>
      <td>2</td>
      <td>7000</td>
    </tr>
    <tr>
      <th>99069</th>
      <td>4.0</td>
      <td>4</td>
      <td>16000</td>
    </tr>
    <tr>
      <th>99081</th>
      <td>2.0</td>
      <td>2</td>
      <td>7350</td>
    </tr>
    <tr>
      <th>99108</th>
      <td>2.0</td>
      <td>2</td>
      <td>7100</td>
    </tr>
    <tr>
      <th>99199</th>
      <td>5.5</td>
      <td>4</td>
      <td>30000</td>
    </tr>
    <tr>
      <th>99218</th>
      <td>3.0</td>
      <td>4</td>
      <td>8495</td>
    </tr>
    <tr>
      <th>99233</th>
      <td>2.0</td>
      <td>2</td>
      <td>6555</td>
    </tr>
    <tr>
      <th>99240</th>
      <td>2.5</td>
      <td>2</td>
      <td>10500</td>
    </tr>
    <tr>
      <th>99332</th>
      <td>2.0</td>
      <td>5</td>
      <td>7794</td>
    </tr>
    <tr>
      <th>9938</th>
      <td>2.0</td>
      <td>2</td>
      <td>8000</td>
    </tr>
    <tr>
      <th>99435</th>
      <td>1.5</td>
      <td>2</td>
      <td>7000</td>
    </tr>
    <tr>
      <th>99437</th>
      <td>2.0</td>
      <td>2</td>
      <td>14250</td>
    </tr>
    <tr>
      <th>9947</th>
      <td>3.0</td>
      <td>4</td>
      <td>14800</td>
    </tr>
    <tr>
      <th>99647</th>
      <td>3.0</td>
      <td>4</td>
      <td>13700</td>
    </tr>
    <tr>
      <th>99653</th>
      <td>3.0</td>
      <td>3</td>
      <td>10000</td>
    </tr>
    <tr>
      <th>99659</th>
      <td>2.0</td>
      <td>2</td>
      <td>9500</td>
    </tr>
    <tr>
      <th>99663</th>
      <td>3.0</td>
      <td>3</td>
      <td>10250</td>
    </tr>
    <tr>
      <th>99684</th>
      <td>2.0</td>
      <td>0</td>
      <td>6800</td>
    </tr>
    <tr>
      <th>99768</th>
      <td>0.0</td>
      <td>2</td>
      <td>15000</td>
    </tr>
    <tr>
      <th>99778</th>
      <td>2.0</td>
      <td>2</td>
      <td>12500</td>
    </tr>
    <tr>
      <th>99911</th>
      <td>2.0</td>
      <td>2</td>
      <td>10650</td>
    </tr>
    <tr>
      <th>99923</th>
      <td>2.0</td>
      <td>2</td>
      <td>11950</td>
    </tr>
    <tr>
      <th>99965</th>
      <td>2.0</td>
      <td>3</td>
      <td>9200</td>
    </tr>
  </tbody>
</table>
<p>2788 rows  3 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Looking at the description for 0 bedroom entries and the renthop.com website showed that 0 bedroom is the indicator for a studio apartment. Roughly 20% of the data is labelled as 0 bedrooms, further indicating that this is an intentional designation and not a mistaken entry like 0 bathroom.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[77]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df_numeric</span><span class="p">[</span><span class="n">df_numeric</span><span class="p">[</span><span class="s1">&#39;bedrooms&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;description&#39;</span><span class="p">][</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;bedrooms&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">:</span><span class="mi">20</span><span class="p">,])</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>9475
100051    Stunning  full renovated studio unit. High cei...
100083    Enjoy the Upper West Side life-style!  This ap...
100096    Location: 141st St. and Malcolm X BlvdSubway: ...
100098    Located in one of Manhattan&#39;s most desirable a...
10010     Prime Location!! This Luxury Chelsea building ...
100107    Wonderful Upper East Side location! This quiet...
100112    Modern postwar building located in the heart o...
100117    Great gut -renovated apartment in charming ele...
100131    Located in a beautiful and classic pre-war bui...
100133    BRAND NEW JR 1 BEDROOM -- GRANITE KITCHEN -- M...
100138                                                     
100144    **No Fee**Second Month Free**East 55th Street*...
100188            Check Out This Lovely Studio Apartment...
1002      (((Spacious 2 bedroom in the Upper East Side))...
100206    Loft, High Ceilings, Hardwood, LightHuge Studi...
100213                                                     
100245    Spacious Studio in UES. Available right now!!!...
100276    This luxury studio has an open -space layout w...
100279    ULTRA SPACIOUS STUDIO HAS 1BATH, STAINLESS STE...
Name: description, dtype: object
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>About 300 entries are labelled as 0 bathroom. The descriptions do not make them seem like they are the type of apartments that do not have a bathroom. The number of blank entries in the description further supports that the 0 bathroom entries are sloppy entries.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[78]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df_numeric</span><span class="p">[</span><span class="n">df_numeric</span><span class="p">[</span><span class="s1">&#39;bathrooms&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;description&#39;</span><span class="p">][</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;bathrooms&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">:</span><span class="mi">20</span><span class="p">,])</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>313
100644    Sky high views with extra high ceiling! This c...
100660    Enjoy the great restaurants, clubs, boutiques ...
101007            Upper West Side-1 BER- Doorman, Elevat...
101068    Amidst the vibrant energy of the West Village ...
101520    SpaciousA StudioA Apartment in Modern New Deve...
101936                                                     
10208                              &lt;p&gt;&lt;a  website_redacted 
10298             This is a fantastic 1 bedroom penthous...
103076            West Village Studio.  Amenities: 24hr ...
103605    This doorman building in the heart of Murray H...
10404             NO FEE!!!&lt;br /&gt;&lt;br /&gt;This building is ...
104363                                                     
10438                                                      
104598    NO FEE PLUS 1 MONTH FREE!!!.. LISTING PRICE IS...
104821                                                     
105507    New Renovation! Upper Level LoftListed on the ...
106808    Featuring high-end amenities, from a stunning ...
107073    We Are Now Offering a 1 Month OP OR 1 Month Fr...
107541                                                     
Name: description, dtype: object
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>By comparing the 0 bedroom and 0 bathroom entries to the benchmark model, you can see that 0 bedroom entries are in line with standard entries while 0 bathroom entries tend to be low interest listings.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[39]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Benchmark: &quot;</span><span class="p">,</span> <span class="n">benchmark_dict</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;0 Bathroom Entries&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_raw</span><span class="p">[</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;bathrooms&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">][</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_raw</span><span class="p">[</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;bathrooms&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">][</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">/</span>
      <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df_raw</span><span class="p">[</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;bathrooms&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">][</span><span class="s1">&#39;interest_level&#39;</span><span class="p">])))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;0 Bedroom Entries&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_raw</span><span class="p">[</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;bedrooms&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">][</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_raw</span><span class="p">[</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;bedrooms&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">][</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">/</span>
      <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df_raw</span><span class="p">[</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;bedrooms&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">][</span><span class="s1">&#39;interest_level&#39;</span><span class="p">])))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Benchmark:  {&#39;medium&#39;: 0.22752877289674178, &#39;high&#39;: 0.07778813421948452, &#39;low&#39;: 0.6946830928837737}
0 Bathroom Entries
low       306
medium      6
high        1
Name: interest_level, dtype: int64
low       0.977636
medium    0.019169
high      0.003195
Name: interest_level, dtype: float64
0 Bedroom Entries
low       6518
medium    2110
high       847
Name: interest_level, dtype: int64
low       0.687916
medium    0.222691
high      0.089393
Name: interest_level, dtype: float64
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In the abstract, renting an apartment is paying money for an amount of space in a location. The number of bedrooms is a rough proxy for that amount of space. However the the gap between 0 (studio apartments) to 1 (one bedroom) is not on the same scale as from 1 bedroom to 2 bedrooms. By looking at price, how similar is a studio apartment to a one bedroom? I want to use that number in order to create a feature that better captures the 'amount of space' and also to come up with a 'price per bedroom' feature. By using the median price of 0 bedroom and 1 bedroom listings, I approximate that number as 0.828 and create a new input feature that replaces 0 bedroom with 0.828 bedroom.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[70]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;0 Bedroom Median: &quot;</span><span class="p">,</span><span class="n">df_raw</span><span class="p">[</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;bedrooms&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">][</span><span class="s1">&#39;price&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">median</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;1 Bedroom Median: &quot;</span><span class="p">,</span><span class="n">df_raw</span><span class="p">[</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;bedrooms&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">][</span><span class="s1">&#39;price&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">median</span><span class="p">())</span>
<span class="n">studio_bedroom</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">df_numeric</span><span class="p">[</span><span class="n">df_numeric</span><span class="p">[</span><span class="s1">&#39;bedrooms&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">][</span><span class="s1">&#39;price&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">median</span><span class="p">()</span>
                       <span class="o">/</span><span class="n">df_numeric</span><span class="p">[</span><span class="n">df_numeric</span><span class="p">[</span><span class="s1">&#39;bedrooms&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">][</span><span class="s1">&#39;price&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">median</span><span class="p">(),</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Studio Bedroom Approx: &quot;</span><span class="p">,</span><span class="n">studio_bedroom</span><span class="p">)</span>
<span class="n">mod_bed</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">df_numeric</span><span class="p">[</span><span class="s1">&#39;bedrooms&#39;</span><span class="p">])</span>
<span class="n">mod_bed</span><span class="p">[</span><span class="n">mod_bed</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">studio_bedroom</span>
<span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;bedrooms_modified&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">mod_bed</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="n">df_raw</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>0 Bedroom Median:  2400.0
1 Bedroom Median:  2900.0
Studio Bedroom Approx:  0.828
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Price-and-Outliers">Price and Outliers<a class="anchor-link" href="#Price-and-Outliers">&#182;</a></h3><p>Unlike bedrooms and bathrooms, some of the price outliers are so extreme that they drastically change the variance of the data. These outliers are either mistaken entries or so outlandish as to not be applicable to most entries. On one hand, there is value in not changing them (like 0 bathroom entries) as they may indicate sloppy listings. On the other hand, price for space in a location is an important feature of real estate and including the extreme prices can skew that important principal. Thus a compromise: rather than removing the outliers I skewed them to a less extreme value. This allows the model to see them as an extreme value while still not exercising undo leverage on the price feature. By changing the 16 entries, the standard deviation is reduced by an order of magnitude from roughly 22000 to 2400.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[55]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df_numeric</span><span class="p">[</span><span class="n">df_numeric</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">100000</span><span class="p">]</span> <span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df_numeric</span><span class="p">[</span><span class="n">df_numeric</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">50000</span><span class="p">]</span> <span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df_numeric</span><span class="p">[</span><span class="n">df_numeric</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">20000</span><span class="p">]</span> <span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df_numeric</span><span class="p">[</span><span class="n">df_numeric</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">10000</span><span class="p">]</span> <span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>6
16
109
878
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[71]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">price_modified</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">df_numeric</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">])</span>
<span class="n">price_modified</span><span class="p">[</span><span class="n">price_modified</span> <span class="o">&gt;=</span> <span class="mi">50000</span><span class="p">]</span> <span class="o">=</span> <span class="mi">50000</span>
<span class="nb">print</span><span class="p">(</span><span class="n">price_modified</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>count    49352.000000
mean      3669.929365
std       2373.377579
min         43.000000
25%       2500.000000
50%       3150.000000
75%       4100.000000
max      50000.000000
Name: price, dtype: float64
count    4.935200e+04
mean     3.830174e+03
std      2.206687e+04
min      4.300000e+01
25%      2.500000e+03
50%      3.150000e+03
75%      4.100000e+03
max      4.490000e+06
Name: price, dtype: float64
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Add two features: price modified and price per bed.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[72]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">per_bed</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">price_modified</span><span class="o">/</span><span class="n">mod_bed</span><span class="p">)</span>
<span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;price_modified&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">price_modified</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="n">df_raw</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;price_per_bed&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">per_bed</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="n">df_raw</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[74]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#df_raw.describe()</span>
<span class="c1">#df_raw.to_pickle(&quot;train_checkpoint_11&quot;)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Some exploration of the price_per_bed feature. Note the drop off in high interest level listings as the price-per-bed value gets large.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[70]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;price_per_bed&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">n</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">patches</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;price_per_bed&#39;</span><span class="p">],</span> <span class="mi">30</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">10000</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;price_per_bed&#39;</span><span class="p">],</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="s1">&#39;low&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;medium&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;high&#39;</span><span class="p">:</span><span class="mi">2</span><span class="p">}),</span><span class="s1">&#39;ro&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">10000</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>count    49352.000000
mean      2449.795559
std       1292.908132
min         51.932367
25%       1600.000000
50%       2294.685990
75%       3097.500000
max      60386.473430
Name: price_per_bed, dtype: float64
</pre>
</div>
</div>

<div class="output_area"><div class="prompt"></div>


<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

<div class="output_area"><div class="prompt"></div>


<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[75]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">random</span>

<span class="n">temp_plot</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]:</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="s1">&#39;low&#39;</span><span class="p">:</span>
        <span class="n">temp_plot</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">gauss</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1000</span><span class="p">))</span>
    <span class="k">elif</span> <span class="n">x</span> <span class="o">==</span> <span class="s1">&#39;medium&#39;</span><span class="p">:</span>
        <span class="n">temp_plot</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">gauss</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span><span class="mi">1000</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">temp_plot</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">gauss</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span><span class="mi">1000</span><span class="p">))</span>
        
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;price_per_bed&#39;</span><span class="p">],</span><span class="n">temp_plot</span><span class="p">,</span><span class="s1">&#39;ro&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">10000</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mi">3000</span><span class="p">,</span><span class="mi">13000</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>


<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAZYAAAD8CAYAAABU4IIeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="1.2-Created">1.2 Created<a class="anchor-link" href="#1.2-Created">&#182;</a></h3><p>Created is a datetime of when the listing was created. Exploration of the training and test data shows that all listings were created between April 1st and June 30th of 2016. Cursory examination of data shows that time of day, day of week, date of month, and month appear to influence interest levels. This makes sense as viewing an apartment listing would be preferable for certain times, days, and parts of the month. Thus the creation of four new features (month, hour, day of week, and day of month).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[79]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;created&#39;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;created&#39;</span><span class="p">]))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>2016-04-01 22:12:41
2016-06-29 21:41:47
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[75]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">created_hour_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">created_dow_list</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1">#0 is monday, 6 is sunday</span>
<span class="n">created_day_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">created_month_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;created&#39;</span><span class="p">]:</span>
    <span class="n">x_hour</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">hour</span>
    <span class="n">x_minute</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">minute</span>
    <span class="n">x_dow</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">dayofweek</span>
    <span class="n">x_day</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">day</span>
    <span class="n">x_month</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">month</span>
    
    <span class="k">if</span> <span class="n">x_minute</span> <span class="o">&gt;</span> <span class="mi">30</span><span class="p">:</span>
        <span class="n">x_hour</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">x_hour</span> <span class="o">&gt;</span> <span class="mi">23</span><span class="p">:</span>
            <span class="n">x_hour</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">if</span> <span class="n">x_day</span> <span class="o">&gt;</span> <span class="mi">29</span><span class="p">:</span> <span class="c1">#only 1 month had a 31st day</span>
        <span class="n">x_day</span> <span class="o">=</span> <span class="mi">30</span>
        
    <span class="n">created_hour_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x_hour</span><span class="p">)</span>
    <span class="n">created_dow_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x_dow</span><span class="p">)</span>
    <span class="n">created_day_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x_day</span><span class="p">)</span>
    <span class="n">created_month_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x_month</span><span class="p">)</span>

<span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;created_hour&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">created_hour_list</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">df_raw</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;created_dow&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">created_dow_list</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">df_raw</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;created_day&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">created_day_list</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">df_raw</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;created_month&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">created_month_list</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">df_raw</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[77]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#df_raw.head()</span>
<span class="c1">#df_raw.to_pickle(&quot;train_checkpoint_12&quot;)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[95]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">benchmark_dict</span><span class="p">)</span>
<span class="n">g2</span> <span class="o">=</span> <span class="n">df_raw</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;created_month&#39;</span><span class="p">,</span> <span class="s1">&#39;interest_level&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">agg</span><span class="p">({</span><span class="s1">&#39;created_month&#39;</span><span class="p">:</span> <span class="s1">&#39;count&#39;</span><span class="p">})</span>
<span class="n">g3</span> <span class="o">=</span> <span class="n">g2</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="mi">100</span> <span class="o">*</span> <span class="n">x</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">sum</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">g3</span><span class="o">.</span><span class="n">to_string</span><span class="p">())</span>
<span class="c1">#print(g2.to_string())</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>{&#39;medium&#39;: 0.22752877289674178, &#39;high&#39;: 0.07778813421948452, &#39;low&#39;: 0.6946830928837737}
                              created_month
created_month interest_level               
4             high                 7.763086
              low                 69.221863
              medium              23.015051
5             high                 7.811610
              low                 69.146040
              medium              23.042350
6             high                 7.763649
              low                 70.001167
              medium              22.235184
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[96]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">benchmark_dict</span><span class="p">)</span>
<span class="n">g2</span> <span class="o">=</span> <span class="n">df_raw</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;created_dow&#39;</span><span class="p">,</span> <span class="s1">&#39;interest_level&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">agg</span><span class="p">({</span><span class="s1">&#39;created_dow&#39;</span><span class="p">:</span> <span class="s1">&#39;count&#39;</span><span class="p">})</span>
<span class="n">g3</span> <span class="o">=</span> <span class="n">g2</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="mi">100</span> <span class="o">*</span> <span class="n">x</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">sum</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">g3</span><span class="o">.</span><span class="n">to_string</span><span class="p">())</span>
<span class="c1">#print(g2.to_string())</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>{&#39;medium&#39;: 0.22752877289674178, &#39;high&#39;: 0.07778813421948452, &#39;low&#39;: 0.6946830928837737}
                            created_dow
created_dow interest_level             
0           high               7.973579
            low               69.143666
            medium            22.882755
1           high               7.508614
            low               69.252703
            medium            23.238684
2           high               7.669429
            low               70.214574
            medium            22.115997
3           high               7.773032
            low               69.212935
            medium            23.014033
4           high               8.547346
            low               66.350586
            medium            25.102068
5           high               7.334963
            low               71.292967
            medium            21.372070
6           high               7.729575
            low               71.504074
            medium            20.766351
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[97]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">benchmark_dict</span><span class="p">)</span>
<span class="n">g2</span> <span class="o">=</span> <span class="n">df_raw</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;created_day&#39;</span><span class="p">,</span> <span class="s1">&#39;interest_level&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">agg</span><span class="p">({</span><span class="s1">&#39;created_day&#39;</span><span class="p">:</span> <span class="s1">&#39;count&#39;</span><span class="p">})</span>
<span class="n">g3</span> <span class="o">=</span> <span class="n">g2</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="mi">100</span> <span class="o">*</span> <span class="n">x</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">sum</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">g3</span><span class="o">.</span><span class="n">to_string</span><span class="p">())</span>
<span class="c1">#print(g2.to_string())</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>{&#39;medium&#39;: 0.22752877289674178, &#39;high&#39;: 0.07778813421948452, &#39;low&#39;: 0.6946830928837737}
                            created_day
created_day interest_level             
1           high              11.409396
            low               60.850112
            medium            27.740492
2           high               8.917555
            low               65.787998
            medium            25.294448
3           high               8.374931
            low               67.886855
            medium            23.738214
4           high               7.903550
            low               69.524447
            medium            22.572003
5           high              10.232301
            low               63.329646
            medium            26.438053
6           high               8.535927
            low               67.855213
            medium            23.608860
7           high               9.693878
            low               67.006803
            medium            23.299320
8           high               7.915408
            low               68.096677
            medium            23.987915
9           high               7.397622
            low               69.947160
            medium            22.655218
10          high               7.361198
            low               70.991890
            medium            21.646912
11          high               7.461810
            low               69.976498
            medium            22.561692
12          high               7.793867
            low               74.190801
            medium            18.015332
13          high               7.718894
            low               68.029954
            medium            24.251152
14          high               8.405946
            low               69.554075
            medium            22.039979
15          high               9.171076
            low               68.430335
            medium            22.398589
16          high               7.456372
            low               69.487044
            medium            23.056584
17          high               7.430341
            low               70.154799
            medium            22.414861
18          high               7.215105
            low               70.262980
            medium            22.521915
19          high               7.294618
            low               69.050992
            medium            23.654391
20          high               9.080590
            low               66.969353
            medium            23.950057
21          high               6.383838
            low               73.898990
            medium            19.717172
22          high               7.549431
            low               70.041941
            medium            22.408628
23          high               5.815062
            low               74.642517
            medium            19.542421
24          high               6.766917
            low               69.871106
            medium            23.361976
25          high               7.064472
            low               70.507545
            medium            22.427984
26          high               5.442177
            low               71.836735
            medium            22.721088
27          high               6.738035
            low               70.591940
            medium            22.670025
28          high               6.569343
            low               70.012165
            medium            23.418491
29          high               7.190737
            low               70.688605
            medium            22.120658
30          high               7.152682
            low               71.664374
            medium            21.182944
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Unsure on how to handle the created_hour data. Some hours have very few submitted entries while some are abnormally large. Due to the large number of entries down in the very early hours of the day, I wonder if renthop either aggregated data from other sources or companies that do the listings transmit their data at a scheduled time in the early hours.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[99]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">benchmark_dict</span><span class="p">)</span>
<span class="n">g1</span> <span class="o">=</span> <span class="n">df_raw</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;created_hour&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">agg</span><span class="p">({</span><span class="s1">&#39;created_hour&#39;</span><span class="p">:</span> <span class="s1">&#39;count&#39;</span><span class="p">})</span>
<span class="n">g2</span> <span class="o">=</span> <span class="n">df_raw</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;created_hour&#39;</span><span class="p">,</span> <span class="s1">&#39;interest_level&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">agg</span><span class="p">({</span><span class="s1">&#39;created_hour&#39;</span><span class="p">:</span> <span class="s1">&#39;count&#39;</span><span class="p">})</span>
<span class="n">g3</span> <span class="o">=</span> <span class="n">g2</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="mi">100</span> <span class="o">*</span> <span class="n">x</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">sum</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">g1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">g3</span><span class="o">.</span><span class="n">to_string</span><span class="p">())</span>
<span class="c1">#print(g2.to_string())</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>{&#39;medium&#39;: 0.22752877289674178, &#39;high&#39;: 0.07778813421948452, &#39;low&#39;: 0.6946830928837737}
              created_hour
created_hour              
0                       61
1                     3637
2                     7219
3                    10600
4                     5882
5                     6047
6                     7484
7                     1888
8                      674
9                      127
10                     187
11                     372
12                     530
13                     677
14                     787
15                     682
16                     610
17                     419
18                     439
19                     391
20                     173
21                     180
22                     178
23                     108
                             created_hour
created_hour interest_level              
0            high               27.868852
             low                40.983607
             medium             31.147541
1            high                2.392081
             low                91.036569
             medium              6.571350
2            high                4.903726
             low                78.792076
             medium             16.304197
3            high                5.924528
             low                71.509434
             medium             22.566038
4            high                6.358382
             low                72.492350
             medium             21.149269
5            high                8.384323
             low                67.851827
             medium             23.763850
6            high               10.275254
             low                58.257616
             medium             31.467130
7            high                9.904661
             low                62.076271
             medium             28.019068
8            high                8.753709
             low                67.655786
             medium             23.590504
9            high               15.748031
             low                55.905512
             medium             28.346457
10           high               14.973262
             low                52.406417
             medium             32.620321
11           high               13.709677
             low                59.408602
             medium             26.881720
12           high               16.603774
             low                57.735849
             medium             25.660377
13           high               12.407681
             low                59.822747
             medium             27.769572
14           high               13.087675
             low                60.736976
             medium             26.175349
15           high               14.369501
             low                54.838710
             medium             30.791789
16           high               12.295082
             low                57.377049
             medium             30.327869
17           high               18.377088
             low                54.415274
             medium             27.207637
18           high               18.678815
             low                56.719818
             medium             24.601367
19           high               10.485934
             low                61.125320
             medium             28.388747
20           high               19.075145
             low                47.398844
             medium             33.526012
21           high               17.777778
             low                50.000000
             medium             32.222222
22           high               13.483146
             low                51.685393
             medium             34.831461
23           high               19.444444
             low                38.888889
             medium             41.666667
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="1.3-Description">1.3 Description<a class="anchor-link" href="#1.3-Description">&#182;</a></h3><p>A new feature caused description_length (length of the description in characters) was created and used in preliminary analysis.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[258]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;description_length&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;description&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">len</span><span class="p">(),</span> <span class="n">index</span><span class="o">=</span><span class="n">df_raw</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;description_length&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;description_length&#39;</span><span class="p">],</span><span class="mi">40</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2000</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>count    49352.000000
mean       601.975624
std        393.592337
min          0.000000
25%        340.000000
50%        564.000000
75%        809.000000
max       4466.000000
Name: description_length, dtype: float64
</pre>
</div>
</div>

<div class="output_area"><div class="prompt"></div>


<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[261]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">benchmark_dict</span><span class="p">)</span>
<span class="n">g1</span> <span class="o">=</span> <span class="n">df_raw</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;description_length&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">agg</span><span class="p">({</span><span class="s1">&#39;description_length&#39;</span><span class="p">:</span> <span class="s1">&#39;count&#39;</span><span class="p">})</span>
<span class="n">g2</span> <span class="o">=</span> <span class="n">df_raw</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;description_length&#39;</span><span class="p">,</span> <span class="s1">&#39;interest_level&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">agg</span><span class="p">({</span><span class="s1">&#39;description_length&#39;</span><span class="p">:</span> <span class="s1">&#39;count&#39;</span><span class="p">})</span>
<span class="n">g3</span> <span class="o">=</span> <span class="n">g2</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="mi">100</span> <span class="o">*</span> <span class="n">x</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">sum</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">g1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">g3</span><span class="o">.</span><span class="n">to_string</span><span class="p">())</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>{&#39;medium&#39;: 0.22752877289674178, &#39;low&#39;: 0.6946830928837737, &#39;high&#39;: 0.07778813421948452}
                    description_length
description_length                    
0                                 1446
1                                  240
5                                    1
8                                 1647
9                                    4
10                                   1
11                                   5
12                                   2
13                                   7
14                                   6
15                                   5
16                                   5
17                                   5
18                                   2
19                                   6
20                                   5
21                                   6
22                                   3
23                                   6
24                                 335
25                                   7
26                                   5
27                                   3
28                                   4
29                                   5
30                                   6
31                                  10
32                                   7
33                                   4
34                                   1
...                                ...
2633                                 1
2639                                 1
2668                                 1
2669                                 2
2674                                 1
2721                                 1
2804                                 2
2805                                 1
2820                                 1
2829                                 3
2830                                 1
2840                                 1
2857                                 1
2893                                 1
2935                                 1
2941                                 1
2950                                 1
3001                                 1
3010                                 1
3020                                 1
3067                                 1
3123                                 1
3149                                 1
3177                                 1
3252                                 1
3259                                 1
3270                                 1
3367                                 1
3464                                 1
4466                                 1

[2096 rows x 1 columns]
                                   description_length
description_length interest_level                    
0                  high                      2.973721
                   low                      92.047026
                   medium                    4.979253
1                  high                      0.416667
                   low                      97.916667
                   medium                    1.666667
5                  low                     100.000000
8                  high                      1.335762
                   low                      92.106861
                   medium                    6.557377
9                  high                     25.000000
                   low                      75.000000
10                 high                    100.000000
11                 high                     20.000000
                   low                      60.000000
                   medium                   20.000000
12                 low                      50.000000
                   medium                   50.000000
13                 low                      57.142857
                   medium                   42.857143
14                 high                     16.666667
                   low                      33.333333
                   medium                   50.000000
15                 low                      60.000000
                   medium                   40.000000
16                 low                      60.000000
                   medium                   40.000000
17                 low                      20.000000
                   medium                   80.000000
18                 medium                  100.000000
19                 low                      66.666667
                   medium                   33.333333
20                 high                     20.000000
                   low                      80.000000
21                 high                     16.666667
                   low                      66.666667
                   medium                   16.666667
22                 low                      33.333333
                   medium                   66.666667
23                 low                      16.666667
                   medium                   83.333333
24                 high                      4.477612
                   low                      76.716418
                   medium                   18.805970
25                 low                      57.142857
                   medium                   42.857143
26                 low                      80.000000
                   medium                   20.000000
27                 low                      66.666667
                   medium                   33.333333
28                 high                     50.000000
                   low                      25.000000
                   medium                   25.000000
29                 high                     20.000000
                   low                      80.000000
30                 high                     16.666667
                   low                      83.333333
31                 high                     30.000000
                   low                      60.000000
                   medium                   10.000000
32                 high                     28.571429
                   low                      42.857143
                   medium                   28.571429
33                 low                     100.000000
34                 medium                  100.000000
35                 medium                  100.000000
36                 low                      60.000000
                   medium                   40.000000
37                 high                     16.666667
                   low                      16.666667
                   medium                   66.666667
38                 high                     20.000000
                   low                      60.000000
                   medium                   20.000000
39                 high                     23.076923
                   low                      69.230769
                   medium                    7.692308
40                 high                     33.333333
                   low                      66.666667
41                 high                     11.428571
                   low                      72.857143
                   medium                   15.714286
42                 low                      85.714286
                   medium                   14.285714
43                 low                      90.000000
                   medium                   10.000000
44                 low                     100.000000
45                 high                     33.333333
                   low                      33.333333
                   medium                   33.333333
46                 high                     16.666667
                   low                      83.333333
47                 high                     18.181818
                   low                      72.727273
                   medium                    9.090909
48                 high                     27.272727
                   low                      63.636364
                   medium                    9.090909
49                 high                     11.111111
                   low                      66.666667
                   medium                   22.222222
50                 high                     25.000000
                   low                      75.000000
51                 high                     28.571429
                   low                      57.142857
                   medium                   14.285714
52                 high                     30.000000
                   low                      60.000000
                   medium                   10.000000
53                 high                     10.000000
                   low                      70.000000
                   medium                   20.000000
54                 low                      66.666667
                   medium                   33.333333
55                 high                      9.090909
                   low                      72.727273
                   medium                   18.181818
56                 high                      8.333333
                   low                      83.333333
                   medium                    8.333333
57                 high                     15.384615
                   low                      76.923077
                   medium                    7.692308
58                 high                      5.000000
                   low                      95.000000
59                 low                      66.666667
                   medium                   33.333333
60                 high                     18.181818
                   low                      45.454545
                   medium                   36.363636
61                 low                      94.117647
                   medium                    5.882353
62                 high                      5.882353
                   low                      88.235294
                   medium                    5.882353
63                 low                      83.333333
                   medium                   16.666667
64                 high                     18.181818
                   low                      54.545455
                   medium                   27.272727
65                 high                     10.000000
                   low                      90.000000
66                 high                      7.142857
                   low                      78.571429
                   medium                   14.285714
67                 high                     16.666667
                   low                      58.333333
                   medium                   25.000000
68                 high                      4.545455
                   low                      77.272727
                   medium                   18.181818
69                 high                     25.000000
                   low                      50.000000
                   medium                   25.000000
70                 low                      75.000000
                   medium                   25.000000
71                 low                      83.333333
                   medium                   16.666667
72                 high                     14.285714
                   low                      71.428571
                   medium                   14.285714
73                 high                      9.090909
                   low                      90.909091
74                 low                      72.727273
                   medium                   27.272727
75                 high                     12.500000
                   low                      75.000000
                   medium                   12.500000
76                 low                      83.333333
                   medium                   16.666667
77                 high                     12.500000
                   low                      87.500000
78                 high                     14.285714
                   low                      57.142857
                   medium                   28.571429
79                 low                      50.000000
                   medium                   50.000000
80                 high                     37.500000
                   low                      62.500000
81                 high                     44.444444
                   low                      55.555556
82                 high                     14.285714
                   low                      71.428571
                   medium                   14.285714
83                 low                      93.333333
                   medium                    6.666667
84                 high                     11.111111
                   low                      88.888889
85                 high                     11.764706
                   low                      70.588235
                   medium                   17.647059
86                 high                     18.750000
                   low                      68.750000
                   medium                   12.500000
87                 high                     14.285714
                   low                      71.428571
                   medium                   14.285714
88                 high                      5.882353
                   low                      88.235294
                   medium                    5.882353
89                 high                     30.000000
                   low                      50.000000
                   medium                   20.000000
90                 high                     15.384615
                   low                      61.538462
                   medium                   23.076923
91                 high                     16.666667
                   low                      58.333333
                   medium                   25.000000
92                 high                     10.000000
                   low                      70.000000
                   medium                   20.000000
93                 high                      9.090909
                   low                      72.727273
                   medium                   18.181818
94                 high                     16.666667
                   low                      75.000000
                   medium                    8.333333
95                 low                     100.000000
96                 high                     16.666667
                   low                      75.000000
                   medium                    8.333333
97                 high                     22.222222
                   low                      77.777778
98                 high                     16.666667
                   low                      75.000000
                   medium                    8.333333
99                 high                     20.000000
                   low                      50.000000
                   medium                   30.000000
100                low                      90.000000
                   medium                   10.000000
101                high                      6.250000
                   low                      75.000000
                   medium                   18.750000
102                low                      75.000000
                   medium                   25.000000
103                low                      90.000000
                   medium                   10.000000
104                low                     100.000000
105                high                      4.580153
                   low                      84.732824
                   medium                   10.687023
106                high                      6.666667
                   low                      73.333333
                   medium                   20.000000
107                high                      8.333333
                   low                      58.333333
                   medium                   33.333333
108                high                     35.714286
                   low                      50.000000
                   medium                   14.285714
109                low                     100.000000
110                high                      8.000000
                   low                      68.000000
                   medium                   24.000000
111                high                     11.111111
                   low                      77.777778
                   medium                   11.111111
112                high                     18.181818
                   low                      59.090909
                   medium                   22.727273
113                high                     22.222222
                   low                      44.444444
                   medium                   33.333333
114                high                      9.090909
                   low                      54.545455
                   medium                   36.363636
115                high                     12.121212
                   low                      66.666667
                   medium                   21.212121
116                high                      9.090909
                   low                      90.909091
117                high                     12.500000
                   low                      75.000000
                   medium                   12.500000
118                high                     22.222222
                   low                      55.555556
                   medium                   22.222222
119                low                     100.000000
120                high                     20.000000
                   low                      60.000000
                   medium                   20.000000
121                low                      71.428571
                   medium                   28.571429
122                low                      81.818182
                   medium                   18.181818
123                high                      7.142857
                   low                      78.571429
                   medium                   14.285714
124                high                      9.090909
                   low                      81.818182
                   medium                    9.090909
125                high                      9.090909
                   low                      81.818182
                   medium                    9.090909
126                high                     20.000000
                   low                      50.000000
                   medium                   30.000000
127                high                     20.000000
                   low                      55.000000
                   medium                   25.000000
128                high                      5.000000
                   low                      55.000000
                   medium                   40.000000
129                high                     10.526316
                   low                      78.947368
                   medium                   10.526316
130                high                     19.047619
                   low                      57.142857
                   medium                   23.809524
131                high                     21.052632
                   low                      52.631579
                   medium                   26.315789
132                high                     10.000000
                   low                      65.000000
                   medium                   25.000000
133                high                     25.000000
                   low                      62.500000
                   medium                   12.500000
134                high                     13.636364
                   low                      63.636364
                   medium                   22.727273
135                high                     15.384615
                   low                      61.538462
                   medium                   23.076923
136                high                      8.333333
                   low                      83.333333
                   medium                    8.333333
137                high                      6.349206
                   low                      76.190476
                   medium                   17.460317
138                high                     15.789474
                   low                      36.842105
                   medium                   47.368421
139                high                     28.000000
                   low                      56.000000
                   medium                   16.000000
140                high                      4.347826
                   low                      56.521739
                   medium                   39.130435
141                high                     30.555556
                   low                      52.777778
                   medium                   16.666667
142                high                      7.142857
                   low                      71.428571
                   medium                   21.428571
143                high                      8.333333
                   low                      75.000000
                   medium                   16.666667
144                high                      5.555556
                   low                      66.666667
                   medium                   27.777778
145                high                      7.142857
                   low                      71.428571
                   medium                   21.428571
146                high                      5.882353
                   low                      64.705882
                   medium                   29.411765
147                high                     13.888889
                   low                      47.222222
                   medium                   38.888889
148                high                      3.703704
                   low                      74.074074
                   medium                   22.222222
149                high                     13.513514
                   low                      62.162162
                   medium                   24.324324
150                high                      8.333333
                   low                      66.666667
                   medium                   25.000000
151                high                      9.333333
                   low                      69.333333
                   medium                   21.333333
152                high                     22.857143
                   low                      45.714286
                   medium                   31.428571
153                high                     13.333333
                   low                      80.000000
                   medium                    6.666667
154                high                      8.333333
                   low                      66.666667
                   medium                   25.000000
155                high                     19.047619
                   low                      61.904762
                   medium                   19.047619
156                high                     19.047619
                   low                      61.904762
                   medium                   19.047619
157                high                     10.000000
                   low                      65.000000
                   medium                   25.000000
158                low                      73.076923
                   medium                   26.923077
159                low                      72.413793
                   medium                   27.586207
160                high                      8.333333
                   low                      62.500000
                   medium                   29.166667
161                high                      6.666667
                   low                      66.666667
                   medium                   26.666667
162                high                     10.000000
                   low                      55.000000
                   medium                   35.000000
163                high                     12.500000
                   low                      62.500000
                   medium                   25.000000
164                high                     19.230769
                   low                      65.384615
                   medium                   15.384615
165                high                     10.526316
                   low                      73.684211
                   medium                   15.789474
166                high                      6.666667
                   low                      66.666667
                   medium                   26.666667
167                high                     16.666667
                   low                      61.111111
                   medium                   22.222222
168                high                      8.695652
                   low                      78.260870
                   medium                   13.043478
169                high                     10.000000
                   low                      65.000000
                   medium                   25.000000
170                high                      4.761905
                   low                      85.714286
                   medium                    9.523810
171                high                      8.333333
                   low                      54.166667
                   medium                   37.500000
172                high                      3.030303
                   low                      81.818182
                   medium                   15.151515
173                low                      86.363636
                   medium                   13.636364
174                high                     19.230769
                   low                      61.538462
                   medium                   19.230769
175                low                      87.500000
                   medium                   12.500000
176                high                      9.523810
                   low                      71.428571
                   medium                   19.047619
177                high                     12.500000
                   low                      62.500000
                   medium                   25.000000
178                high                      7.142857
                   low                      75.000000
                   medium                   17.857143
179                high                      5.263158
                   low                      63.157895
                   medium                   31.578947
180                high                     14.814815
                   low                      77.777778
                   medium                    7.407407
181                high                     17.241379
                   low                      62.068966
                   medium                   20.689655
182                high                      3.333333
                   low                      93.333333
                   medium                    3.333333
183                high                     12.500000
                   low                      66.666667
                   medium                   20.833333
184                high                      7.407407
                   low                      74.074074
                   medium                   18.518519
185                high                      6.666667
                   low                      76.666667
                   medium                   16.666667
186                high                      5.882353
                   low                      66.666667
                   medium                   27.450980
187                high                     16.666667
                   low                      70.000000
                   medium                   13.333333
188                high                      6.666667
                   low                      73.333333
                   medium                   20.000000
189                high                     17.500000
                   low                      60.000000
                   medium                   22.500000
190                high                      8.333333
                   low                      54.166667
                   medium                   37.500000
191                high                      3.773585
                   low                      88.679245
                   medium                    7.547170
192                high                      4.545455
                   low                      77.272727
                   medium                   18.181818
193                high                     12.500000
                   low                      68.750000
                   medium                   18.750000
194                high                      2.857143
                   low                      85.714286
                   medium                   11.428571
195                high                      8.333333
                   low                      70.833333
                   medium                   20.833333
196                high                     11.904762
                   low                      66.666667
                   medium                   21.428571
197                low                      57.692308
                   medium                   42.307692
198                low                      68.750000
                   medium                   31.250000
199                high                      7.407407
                   low                      81.481481
                   medium                   11.111111
200                high                     20.000000
                   low                      75.000000
                   medium                    5.000000
201                high                      8.000000
                   low                      76.000000
                   medium                   16.000000
202                high                     13.636364
                   low                      77.272727
                   medium                    9.090909
203                high                      3.846154
                   low                      76.923077
                   medium                   19.230769
204                low                      70.833333
                   medium                   29.166667
205                low                      81.481481
                   medium                   18.518519
206                high                     17.241379
                   low                      72.413793
                   medium                   10.344828
207                high                      2.631579
                   low                      76.315789
                   medium                   21.052632
208                high                      4.000000
                   low                      72.000000
                   medium                   24.000000
209                high                      8.823529
                   low                      67.647059
                   medium                   23.529412
210                high                      7.692308
                   low                      57.692308
                   medium                   34.615385
211                low                      82.142857
                   medium                   17.857143
212                high                     16.000000
                   low                      56.000000
                   medium                   28.000000
213                low                      88.888889
                   medium                   11.111111
214                high                     14.285714
                   low                      60.714286
                   medium                   25.000000
215                high                      5.000000
                   low                      62.500000
                   medium                   32.500000
216                high                      5.128205
                   low                      74.358974
                   medium                   20.512821
217                high                      3.703704
                   low                      70.370370
                   medium                   25.925926
218                high                      6.060606
                   low                      69.696970
                   medium                   24.242424
219                high                      7.894737
                   low                      76.315789
                   medium                   15.789474
220                high                     10.344828
                   low                      75.862069
                   medium                   13.793103
221                high                     20.000000
                   low                      70.000000
                   medium                   10.000000
222                high                     18.518519
                   low                      66.666667
                   medium                   14.814815
223                high                      8.333333
                   low                      87.500000
                   medium                    4.166667
224                high                      6.382979
                   low                      74.468085
                   medium                   19.148936
225                high                     17.500000
                   low                      57.500000
                   medium                   25.000000
226                high                      4.761905
                   low                      73.809524
                   medium                   21.428571
227                high                      5.555556
                   low                      58.333333
                   medium                   36.111111
228                high                      5.555556
                   low                      77.777778
                   medium                   16.666667
229                low                      76.315789
                   medium                   23.684211
230                low                      64.285714
                   medium                   35.714286
231                high                      8.510638
                   low                      68.085106
                   medium                   23.404255
232                high                      2.941176
                   low                      73.529412
                   medium                   23.529412
233                high                     13.333333
                   low                      63.333333
                   medium                   23.333333
234                high                      4.255319
                   low                      78.723404
                   medium                   17.021277
235                high                     14.285714
                   low                      57.142857
                   medium                   28.571429
236                high                     14.285714
                   low                      78.571429
                   medium                    7.142857
237                high                      4.166667
                   low                      70.833333
                   medium                   25.000000
238                high                      6.666667
                   low                      70.000000
                   medium                   23.333333
239                high                     10.526316
                   low                      71.052632
                   medium                   18.421053
240                high                     16.666667
                   low                      53.333333
                   medium                   30.000000
241                high                      9.677419
                   low                      70.967742
                   medium                   19.354839
242                high                      2.325581
                   low                      72.093023
                   medium                   25.581395
243                high                      2.857143
                   low                      68.571429
                   medium                   28.571429
244                high                      6.382979
                   low                      70.212766
                   medium                   23.404255
245                high                     24.137931
                   low                      58.620690
                   medium                   17.241379
246                high                     12.500000
                   low                      68.750000
                   medium                   18.750000
247                high                     11.764706
                   low                      73.529412
                   medium                   14.705882
248                high                      8.823529
                   low                      73.529412
                   medium                   17.647059
249                high                     14.285714
                   low                      65.714286
                   medium                   20.000000
250                high                      2.272727
                   low                      79.545455
                   medium                   18.181818
251                high                     14.285714
                   low                      60.714286
                   medium                   25.000000
252                high                     14.285714
                   low                      64.285714
                   medium                   21.428571
253                high                     12.500000
                   low                      67.500000
                   medium                   20.000000
254                high                      3.333333
                   low                      83.333333
                   medium                   13.333333
255                high                     17.647059
                   low                      73.529412
                   medium                    8.823529
256                high                     10.000000
                   low                      66.666667
                   medium                   23.333333
257                high                      3.703704
                   low                      74.074074
                   medium                   22.222222
258                high                     13.157895
                   low                      68.421053
                   medium                   18.421053
259                high                      9.090909
                   low                      60.606061
                   medium                   30.303030
260                high                      4.166667
                   low                      79.166667
                   medium                   16.666667
261                high                     14.285714
                   low                      68.571429
                   medium                   17.142857
262                low                      80.000000
                   medium                   20.000000
263                high                     13.793103
                   low                      65.517241
                   medium                   20.689655
264                high                      2.857143
                   low                      71.428571
                   medium                   25.714286
265                high                     10.000000
                   low                      77.500000
                   medium                   12.500000
266                high                      6.896552
                   low                      65.517241
                   medium                   27.586207
267                high                     12.500000
                   low                      75.000000
                   medium                   12.500000
268                high                     13.157895
                   low                      55.263158
                   medium                   31.578947
269                high                      9.677419
                   low                      64.516129
                   medium                   25.806452
270                high                     13.559322
                   low                      62.711864
                   medium                   23.728814
271                high                     14.705882
                   low                      67.647059
                   medium                   17.647059
272                high                      2.941176
                   low                      70.588235
                   medium                   26.470588
273                high                      8.510638
                   low                      65.957447
                   medium                   25.531915
274                high                      2.702703
                   low                      72.972973
                   medium                   24.324324
275                high                      5.555556
                   low                      66.666667
                   medium                   27.777778
276                high                      2.564103
                   low                      69.230769
                   medium                   28.205128
277                high                      4.761905
                   low                      71.428571
                   medium                   23.809524
278                high                     15.789474
                   low                      65.789474
                   medium                   18.421053
279                high                     17.241379
                   low                      65.517241
                   medium                   17.241379
280                high                     13.953488
                   low                      72.093023
                   medium                   13.953488
281                high                     12.500000
                   low                      62.500000
                   medium                   25.000000
282                high                      3.448276
                   low                      65.517241
                   medium                   31.034483
283                low                      75.609756
                   medium                   24.390244
284                high                      2.941176
                   low                      79.411765
                   medium                   17.647059
285                high                     17.948718
                   low                      53.846154
                   medium                   28.205128
286                high                      8.823529
                   low                      64.705882
                   medium                   26.470588
287                high                     21.621622
                   low                      64.864865
                   medium                   13.513514
288                high                     20.000000
                   low                      52.500000
                   medium                   27.500000
289                high                     10.000000
                   low                      76.666667
                   medium                   13.333333
290                high                     14.000000
                   low                      70.000000
                   medium                   16.000000
291                high                      4.651163
                   low                      72.093023
                   medium                   23.255814
292                high                      2.941176
                   low                      73.529412
                   medium                   23.529412
293                high                      9.803922
                   low                      70.588235
                   medium                   19.607843
294                high                      6.818182
                   low                      70.454545
                   medium                   22.727273
295                high                     11.627907
                   low                      74.418605
                   medium                   13.953488
296                high                     12.820513
                   low                      66.666667
                   medium                   20.512821
297                high                      9.523810
                   low                      69.047619
                   medium                   21.428571
298                low                      82.352941
                   medium                   17.647059
299                high                      8.888889
                   low                      64.444444
                   medium                   26.666667
300                high                     10.526316
                   low                      60.526316
                   medium                   28.947368
301                high                      6.521739
                   low                      71.739130
                   medium                   21.739130
302                high                      3.448276
                   low                      81.034483
                   medium                   15.517241
303                high                      7.692308
                   low                      71.794872
                   medium                   20.512821
304                high                      3.448276
                   low                      82.758621
                   medium                   13.793103
305                high                      2.127660
                   low                      70.212766
                   medium                   27.659574
306                low                      71.428571
                   medium                   28.571429
307                high                     14.285714
                   low                      64.285714
                   medium                   21.428571
308                high                     11.428571
                   low                      68.571429
                   medium                   20.000000
309                high                      8.695652
                   low                      76.086957
                   medium                   15.217391
310                low                      73.913043
                   medium                   26.086957
311                high                      9.677419
                   low                      77.419355
                   medium                   12.903226
312                high                     12.765957
                   low                      61.702128
                   medium                   25.531915
313                high                      4.166667
                   low                      81.250000
                   medium                   14.583333
314                high                      7.500000
                   low                      75.000000
                   medium                   17.500000
315                high                     16.129032
                   low                      61.290323
                   medium                   22.580645
316                high                      9.523810
                   low                      61.904762
                   medium                   28.571429
317                high                      7.692308
                   low                      66.666667
                   medium                   25.641026
318                high                      8.955224
                   low                      67.164179
                   medium                   23.880597
319                high                      6.944444
                   low                      68.055556
                   medium                   25.000000
320                high                     10.000000
                   low                      65.000000
                   medium                   25.000000
321                high                      6.521739
                   low                      73.913043
                   medium                   19.565217
322                high                      9.302326
                   low                      69.767442
                   medium                   20.930233
323                high                      6.896552
                   low                      62.068966
                   medium                   31.034483
324                high                      8.333333
                   low                      64.583333
                   medium                   27.083333
325                high                      7.692308
                   low                      61.538462
                   medium                   30.769231
326                high                     19.047619
                   low                      57.142857
                   medium                   23.809524
327                high                      4.000000
                   low                      82.000000
                   medium                   14.000000
328                high                      2.173913
                   low                      78.260870
                   medium                   19.565217
329                high                      8.695652
                   low                      78.260870
                   medium                   13.043478
330                high                      4.347826
                   low                      76.086957
                   medium                   19.565217
331                high                      6.250000
                   low                      66.666667
                   medium                   27.083333
332                high                      9.259259
                   low                      68.518519
                   medium                   22.222222
333                high                     12.820513
                   low                      69.230769
                   medium                   17.948718
334                high                      9.523810
                   low                      69.047619
                   medium                   21.428571
335                high                     12.068966
                   low                      72.413793
                   medium                   15.517241
336                high                     10.937500
                   low                      78.125000
                   medium                   10.937500
337                high                      6.122449
                   low                      85.714286
                   medium                    8.163265
338                high                      1.851852
                   low                      77.777778
                   medium                   20.370370
339                high                      5.797101
                   low                      82.608696
                   medium                   11.594203
340                high                     10.204082
                   low                      61.224490
                   medium                   28.571429
341                high                      6.000000
                   low                      74.000000
                   medium                   20.000000
342                high                     11.290323
                   low                      69.354839
                   medium                   19.354839
343                high                      9.090909
                   low                      72.727273
                   medium                   18.181818
344                high                     10.000000
                   low                      62.857143
                   medium                   27.142857
345                high                     14.285714
                   low                      59.523810
                   medium                   26.190476
346                high                      8.000000
                   low                      68.000000
                   medium                   24.000000
347                high                      5.454545
                   low                      72.727273
                   medium                   21.818182
348                high                      7.272727
                   low                      74.545455
                   medium                   18.181818
349                high                     10.204082
                   low                      69.387755
                   medium                   20.408163
350                high                     13.559322
                   low                      71.186441
                   medium                   15.254237
351                high                      4.347826
                   low                      60.869565
                   medium                   34.782609
352                high                     10.714286
                   low                      66.071429
                   medium                   23.214286
353                high                     10.416667
                   low                      62.500000
                   medium                   27.083333
354                high                     10.869565
                   low                      71.739130
                   medium                   17.391304
355                high                      8.571429
                   low                      75.714286
                   medium                   15.714286
356                high                      8.433735
                   low                      77.108434
                   medium                   14.457831
357                high                      2.173913
                   low                      69.565217
                   medium                   28.260870
358                high                      1.960784
                   low                      74.509804
                   medium                   23.529412
359                high                      7.692308
                   low                      76.923077
                   medium                   15.384615
360                high                      6.896552
                   low                      77.586207
                   medium                   15.517241
361                high                      5.263158
                   low                      71.929825
                   medium                   22.807018
362                high                     13.043478
                   low                      60.869565
                   medium                   26.086957
363                high                      9.090909
                   low                      77.272727
                   medium                   13.636364
364                low                      75.471698
                   medium                   24.528302
365                high                      7.142857
                   low                      69.642857
                   medium                   23.214286
366                high                     10.416667
                   low                      58.333333
                   medium                   31.250000
367                high                     10.256410
                   low                      61.538462
                   medium                   28.205128
368                high                     10.869565
                   low                      56.521739
                   medium                   32.608696
369                high                      6.153846
                   low                      78.461538
                   medium                   15.384615
370                high                      2.222222
                   low                      71.111111
                   medium                   26.666667
371                high                      5.555556
                   low                      61.111111
                   medium                   33.333333
372                high                      4.444444
                   low                      66.666667
                   medium                   28.888889
373                high                      9.090909
                   low                      68.181818
                   medium                   22.727273
374                high                      1.818182
                   low                      85.454545
                   medium                   12.727273
375                high                      6.250000
                   low                      75.000000
                   medium                   18.750000
376                high                      4.347826
                   low                      69.565217
                   medium                   26.086957
377                high                      1.818182
                   low                      63.636364
                   medium                   34.545455
378                high                      8.641975
                   low                      75.308642
                   medium                   16.049383
379                high                      5.263158
                   low                      66.666667
                   medium                   28.070175
380                high                      5.357143
                   low                      64.285714
                   medium                   30.357143
381                high                     10.169492
                   low                      66.101695
                   medium                   23.728814
382                high                     11.111111
                   low                      62.222222
                   medium                   26.666667
383                high                     12.244898
                   low                      67.346939
                   medium                   20.408163
384                high                      5.555556
                   low                      72.222222
                   medium                   22.222222
385                high                      3.636364
                   low                      80.000000
                   medium                   16.363636
386                high                      7.142857
                   low                      61.904762
                   medium                   30.952381
387                high                     12.500000
                   low                      64.062500
                   medium                   23.437500
388                high                      8.571429
                   low                      71.428571
                   medium                   20.000000
389                high                      3.333333
                   low                      73.333333
                   medium                   23.333333
390                high                      5.952381
                   low                      79.761905
                   medium                   14.285714
391                high                      9.375000
                   low                      67.187500
                   medium                   23.437500
392                high                      8.333333
                   low                      66.666667
                   medium                   25.000000
393                high                      8.928571
                   low                      64.285714
                   medium                   26.785714
394                high                      6.818182
                   low                      75.000000
                   medium                   18.181818
395                high                      6.779661
                   low                      84.745763
                   medium                    8.474576
396                high                      7.142857
                   low                      60.714286
                   medium                   32.142857
397                high                      6.666667
                   low                      65.000000
                   medium                   28.333333
398                high                      5.555556
                   low                      75.925926
                   medium                   18.518519
399                high                     11.290323
                   low                      69.354839
                   medium                   19.354839
400                high                      3.571429
                   low                      64.285714
                   medium                   32.142857
401                high                      6.250000
                   low                      75.000000
                   medium                   18.750000
402                high                      4.347826
                   low                      69.565217
                   medium                   26.086957
403                high                      8.000000
                   low                      64.000000
                   medium                   28.000000
404                high                      5.357143
                   low                      71.428571
                   medium                   23.214286
405                high                      2.272727
                   low                      72.727273
                   medium                   25.000000
406                high                      8.510638
                   low                      70.212766
                   medium                   21.276596
407                high                      7.017544
                   low                      70.175439
                   medium                   22.807018
408                high                      7.692308
                   low                      64.102564
                   medium                   28.205128
409                high                     17.073171
                   low                      63.414634
                   medium                   19.512195
410                high                      9.090909
                   low                      70.454545
                   medium                   20.454545
411                high                     15.686275
                   low                      74.509804
                   medium                    9.803922
412                high                      5.263158
                   low                      70.175439
                   medium                   24.561404
413                high                     10.638298
                   low                      68.085106
                   medium                   21.276596
414                high                      5.263158
                   low                      68.421053
                   medium                   26.315789
415                high                     20.000000
                   low                      64.444444
                   medium                   15.555556
416                high                      2.083333
                   low                      66.666667
                   medium                   31.250000
417                high                     12.068966
                   low                      68.965517
                   medium                   18.965517
418                high                      2.040816
                   low                      75.510204
                   medium                   22.448980
419                high                      9.615385
                   low                      63.461538
                   medium                   26.923077
420                high                      9.836066
                   low                      67.213115
                   medium                   22.950820
421                high                      6.153846
                   low                      78.461538
                   medium                   15.384615
422                high                      5.769231
                   low                      76.923077
                   medium                   17.307692
423                high                      6.666667
                   low                      68.888889
                   medium                   24.444444
424                high                     12.658228
                   low                      62.025316
                   medium                   25.316456
425                high                     13.846154
                   low                      61.538462
                   medium                   24.615385
426                high                     14.000000
                   low                      68.000000
                   medium                   18.000000
427                high                      8.695652
                   low                      67.391304
                   medium                   23.913043
428                high                      7.812500
                   low                      68.750000
                   medium                   23.437500
429                high                     10.937500
                   low                      68.750000
                   medium                   20.312500
430                high                      9.615385
                   low                      69.230769
                   medium                   21.153846
431                high                     16.666667
                   low                      72.727273
                   medium                   10.606061
432                high                     11.111111
                   low                      68.888889
                   medium                   20.000000
433                high                      6.250000
                   low                      66.666667
                   medium                   27.083333
434                high                      7.692308
                   low                      76.923077
                   medium                   15.384615
435                high                      5.970149
                   low                      76.119403
                   medium                   17.910448
436                high                      5.405405
                   low                      77.027027
                   medium                   17.567568
437                high                      8.823529
                   low                      63.235294
                   medium                   27.941176
438                high                     11.538462
                   low                      65.384615
                   medium                   23.076923
439                high                     11.290323
                   low                      66.129032
                   medium                   22.580645
440                high                     10.000000
                   low                      64.000000
                   medium                   26.000000
441                high                      7.272727
                   low                      67.272727
                   medium                   25.454545
442                high                      7.272727
                   low                      70.909091
                   medium                   21.818182
443                high                      3.846154
                   low                      71.153846
                   medium                   25.000000
444                high                      7.017544
                   low                      68.421053
                   medium                   24.561404
445                high                     12.820513
                   low                      69.230769
                   medium                   17.948718
446                high                     21.052632
                   low                      63.157895
                   medium                   15.789474
447                high                     13.846154
                   low                      61.538462
                   medium                   24.615385
448                high                      5.882353
                   low                      66.666667
                   medium                   27.450980
449                high                      5.769231
                   low                      75.000000
                   medium                   19.230769
450                high                      2.040816
                   low                      75.510204
                   medium                   22.448980
451                high                      9.433962
                   low                      64.150943
                   medium                   26.415094
452                high                      2.272727
                   low                      72.727273
                   medium                   25.000000
453                high                     14.545455
                   low                      74.545455
                   medium                   10.909091
454                high                      1.724138
                   low                      65.517241
                   medium                   32.758621
455                high                      3.846154
                   low                      84.615385
                   medium                   11.538462
456                high                      7.547170
                   low                      79.245283
                   medium                   13.207547
457                high                      6.976744
                   low                      72.093023
                   medium                   20.930233
458                high                     11.111111
                   low                      71.111111
                   medium                   17.777778
459                high                      4.255319
                   low                      68.085106
                   medium                   27.659574
460                high                      8.695652
                   low                      80.434783
                   medium                   10.869565
461                high                     11.111111
                   low                      74.603175
                   medium                   14.285714
462                high                      5.000000
                   low                      65.000000
                   medium                   30.000000
463                high                      9.756098
                   low                      58.536585
                   medium                   31.707317
464                high                     12.500000
                   low                      70.833333
                   medium                   16.666667
465                high                     12.962963
                   low                      61.111111
                   medium                   25.925926
466                high                      7.812500
                   low                      71.875000
                   medium                   20.312500
467                high                      7.894737
                   low                      71.052632
                   medium                   21.052632
468                high                      7.017544
                   low                      66.666667
                   medium                   26.315789
469                high                     15.789474
                   low                      57.894737
                   medium                   26.315789
470                high                      8.163265
                   low                      73.469388
                   medium                   18.367347
471                high                      4.166667
                   low                      68.750000
                   medium                   27.083333
472                high                      2.127660
                   low                      78.723404
                   medium                   19.148936
473                high                      4.081633
                   low                      69.387755
                   medium                   26.530612
474                high                     10.526316
                   low                      70.175439
                   medium                   19.298246
475                high                      9.090909
                   low                      67.272727
                   medium                   23.636364
476                high                     11.666667
                   low                      63.333333
                   medium                   25.000000
477                high                     14.457831
                   low                      68.674699
                   medium                   16.867470
478                high                      8.695652
                   low                      80.434783
                   medium                   10.869565
479                high                      4.651163
                   low                      72.093023
                   medium                   23.255814
480                high                      7.142857
                   low                      77.142857
                   medium                   15.714286
481                high                     10.169492
                   low                      61.016949
                   medium                   28.813559
482                high                     15.000000
                   low                      60.000000
                   medium                   25.000000
483                high                      9.859155
                   low                      66.197183
                   medium                   23.943662
484                high                     10.638298
                   low                      59.574468
                   medium                   29.787234
485                high                     11.290323
                   low                      56.451613
                   medium                   32.258065
486                high                      6.818182
                   low                      65.909091
                   medium                   27.272727
487                high                     12.500000
                   low                      62.500000
                   medium                   25.000000
488                high                      9.615385
                   low                      71.153846
                   medium                   19.230769
489                high                      8.571429
                   low                      68.571429
                   medium                   22.857143
490                high                     14.705882
                   low                      54.411765
                   medium                   30.882353
491                high                      7.017544
                   low                      70.175439
                   medium                   22.807018
492                high                      9.803922
                   low                      70.588235
                   medium                   19.607843
493                high                     10.447761
                   low                      65.671642
                   medium                   23.880597
494                high                      7.547170
                   low                      69.811321
                   medium                   22.641509
495                high                      6.557377
                   low                      72.131148
                   medium                   21.311475
496                high                      9.523810
                   low                      64.285714
                   medium                   26.190476
497                high                      8.771930
                   low                      45.614035
                   medium                   45.614035
498                high                     10.389610
                   low                      70.129870
                   medium                   19.480519
499                high                     18.604651
                   low                      67.441860
                   medium                   13.953488
500                high                      7.142857
                   low                      64.285714
                   medium                   28.571429
501                high                      9.090909
                   low                      71.212121
                   medium                   19.696970
502                high                     15.384615
                   low                      55.769231
                   medium                   28.846154
503                high                      9.302326
                   low                      74.418605
                   medium                   16.279070
504                high                      6.250000
                   low                      81.250000
                   medium                   12.500000
505                high                      1.851852
                   low                      85.185185
                   medium                   12.962963
506                high                      6.944444
                   low                      59.722222
                   medium                   33.333333
507                high                      9.333333
                   low                      68.000000
                   medium                   22.666667
508                high                      8.219178
                   low                      73.972603
                   medium                   17.808219
509                high                      4.166667
                   low                      85.416667
                   medium                   10.416667
510                high                      3.508772
                   low                      68.421053
                   medium                   28.070175
511                high                     11.320755
                   low                      56.603774
                   medium                   32.075472
512                high                     10.937500
                   low                      53.125000
                   medium                   35.937500
513                high                      8.474576
                   low                      61.016949
                   medium                   30.508475
514                high                      5.128205
                   low                      62.820513
                   medium                   32.051282
515                high                      3.703704
                   low                      70.370370
                   medium                   25.925926
516                high                      5.263158
                   low                      63.157895
                   medium                   31.578947
517                high                      4.651163
                   low                      74.418605
                   medium                   20.930233
518                high                      8.333333
                   low                      72.916667
                   medium                   18.750000
519                high                      4.838710
                   low                      80.645161
                   medium                   14.516129
520                high                      7.936508
                   low                      71.428571
                   medium                   20.634921
521                high                      4.918033
                   low                      77.049180
                   medium                   18.032787
522                high                      7.692308
                   low                      66.153846
                   medium                   26.153846
523                high                     12.698413
                   low                      69.841270
                   medium                   17.460317
524                high                      2.173913
                   low                      80.434783
                   medium                   17.391304
525                high                      8.219178
                   low                      76.712329
                   medium                   15.068493
526                high                      6.250000
                   low                      67.187500
                   medium                   26.562500
527                high                     10.000000
                   low                      61.666667
                   medium                   28.333333
528                high                     10.909091
                   low                      72.727273
                   medium                   16.363636
529                high                     12.987013
                   low                      57.142857
                   medium                   29.870130
530                high                     15.384615
                   low                      65.384615
                   medium                   19.230769
531                high                      4.761905
                   low                      61.904762
                   medium                   33.333333
532                high                      6.557377
                   low                      70.491803
                   medium                   22.950820
533                high                      6.382979
                   low                      65.957447
                   medium                   27.659574
534                high                      7.142857
                   low                      76.190476
                   medium                   16.666667
535                high                      2.380952
                   low                      78.571429
                   medium                   19.047619
536                high                      8.474576
                   low                      57.627119
                   medium                   33.898305
537                high                      6.000000
                   low                      70.000000
                   medium                   24.000000
538                high                      8.000000
                   low                      76.000000
                   medium                   16.000000
539                high                      7.547170
                   low                      62.264151
                   medium                   30.188679
540                high                      3.571429
                   low                      75.000000
                   medium                   21.428571
541                high                      7.462687
                   low                      61.194030
                   medium                   31.343284
542                high                      9.803922
                   low                      66.666667
                   medium                   23.529412
543                high                      5.454545
                   low                      83.636364
                   medium                   10.909091
544                high                      7.142857
                   low                      66.666667
                   medium                   26.190476
545                high                      6.349206
                   low                      76.190476
                   medium                   17.460317
546                high                      9.433962
                   low                      58.490566
                   medium                   32.075472
547                high                     13.513514
                   low                      54.054054
                   medium                   32.432432
548                high                      6.666667
                   low                      68.000000
                   medium                   25.333333
549                high                     10.714286
                   low                      64.285714
                   medium                   25.000000
550                high                     10.869565
                   low                      50.000000
                   medium                   39.130435
551                high                      6.451613
                   low                      69.354839
                   medium                   24.193548
552                high                     10.000000
                   low                      68.333333
                   medium                   21.666667
553                high                      7.692308
                   low                      65.384615
                   medium                   26.923077
554                high                     11.111111
                   low                      53.968254
                   medium                   34.920635
555                high                      6.779661
                   low                      64.406780
                   medium                   28.813559
556                high                      8.163265
                   low                      67.346939
                   medium                   24.489796
557                high                      6.250000
                   low                      75.000000
                   medium                   18.750000
558                high                      6.779661
                   low                      61.016949
                   medium                   32.203390
559                high                      6.153846
                   low                      67.692308
                   medium                   26.153846
560                high                     11.111111
                   low                      58.730159
                   medium                   30.158730
561                high                      4.651163
                   low                      79.069767
                   medium                   16.279070
562                high                      4.651163
                   low                      72.093023
                   medium                   23.255814
563                high                      8.333333
                   low                      56.666667
                   medium                   35.000000
564                high                     10.169492
                   low                      66.101695
                   medium                   23.728814
565                high                      7.692308
                   low                      69.230769
                   medium                   23.076923
566                high                      8.955224
                   low                      73.134328
                   medium                   17.910448
567                high                     12.500000
                   low                      56.250000
                   medium                   31.250000
568                high                     10.909091
                   low                      69.090909
                   medium                   20.000000
569                high                     10.975610
                   low                      70.731707
                   medium                   18.292683
570                high                      6.849315
                   low                      65.753425
                   medium                   27.397260
571                high                     11.320755
                   low                      60.377358
                   medium                   28.301887
572                high                      2.325581
                   low                      68.604651
                   medium                   29.069767
573                high                      3.174603
                   low                      76.190476
                   medium                   20.634921
574                high                     16.393443
                   low                      65.573770
                   medium                   18.032787
575                high                      6.896552
                   low                      75.862069
                   medium                   17.241379
576                high                      9.803922
                   low                      72.549020
                   medium                   17.647059
577                high                      4.166667
                   low                      77.083333
                   medium                   18.750000
578                high                      7.142857
                   low                      64.285714
                   medium                   28.571429
579                high                      7.936508
                   low                      60.317460
                   medium                   31.746032
580                high                     13.114754
                   low                      59.016393
                   medium                   27.868852
581                high                     10.000000
                   low                      76.000000
                   medium                   14.000000
582                low                      72.222222
                   medium                   27.777778
583                high                      4.918033
                   low                      65.573770
                   medium                   29.508197
584                high                      1.923077
                   low                      75.000000
                   medium                   23.076923
585                high                      3.333333
                   low                      75.000000
                   medium                   21.666667
586                high                      7.575758
                   low                      74.242424
                   medium                   18.181818
587                high                     11.363636
                   low                      72.727273
                   medium                   15.909091
588                high                      9.836066
                   low                      57.377049
                   medium                   32.786885
589                high                      3.797468
                   low                      67.088608
                   medium                   29.113924
590                high                      5.263158
                   low                      52.631579
                   medium                   42.105263
591                high                      7.692308
                   low                      71.153846
                   medium                   21.153846
592                high                     12.500000
                   low                      57.142857
                   medium                   30.357143
593                high                      1.785714
                   low                      62.500000
                   medium                   35.714286
594                high                      8.695652
                   low                      65.217391
                   medium                   26.086957
595                high                      5.769231
                   low                      67.307692
                   medium                   26.923077
596                high                     16.393443
                   low                      57.377049
                   medium                   26.229508
597                high                      9.302326
                   low                      62.790698
                   medium                   27.906977
598                high                      8.510638
                   low                      57.446809
                   medium                   34.042553
599                high                      6.849315
                   low                      69.863014
                   medium                   23.287671
600                high                     17.187500
                   low                      54.687500
                   medium                   28.125000
601                high                      5.714286
                   low                      74.285714
                   medium                   20.000000
602                high                      7.894737
                   low                      52.631579
                   medium                   39.473684
603                high                     12.328767
                   low                      61.643836
                   medium                   26.027397
604                high                      7.407407
                   low                      81.481481
                   medium                   11.111111
605                high                     13.253012
                   low                      69.879518
                   medium                   16.867470
606                high                      9.803922
                   low                      56.862745
                   medium                   33.333333
607                low                      73.214286
                   medium                   26.785714
608                high                     10.526316
                   low                      71.929825
                   medium                   17.543860
609                high                     12.820513
                   low                      61.538462
                   medium                   25.641026
610                high                      7.936508
                   low                      58.730159
                   medium                   33.333333
611                high                      5.128205
                   low                      76.923077
                   medium                   17.948718
612                high                      2.898551
                   low                      62.318841
                   medium                   34.782609
613                high                      1.754386
                   low                      73.684211
                   medium                   24.561404
614                high                      5.882353
                   low                      66.666667
                   medium                   27.450980
615                high                      9.523810
                   low                      68.253968
                   medium                   22.222222
616                high                     11.764706
                   low                      45.098039
                   medium                   43.137255
617                high                     12.280702
                   low                      56.140351
                   medium                   31.578947
618                high                     10.294118
                   low                      54.411765
                   medium                   35.294118
619                high                     12.676056
                   low                      69.014085
                   medium                   18.309859
620                high                     10.294118
                   low                      55.882353
                   medium                   33.823529
621                high                      2.083333
                   low                      50.000000
                   medium                   47.916667
622                high                      8.510638
                   low                      63.829787
                   medium                   27.659574
623                high                      6.153846
                   low                      70.769231
                   medium                   23.076923
624                high                      1.785714
                   low                      80.357143
                   medium                   17.857143
625                high                      9.090909
                   low                      65.454545
                   medium                   25.454545
626                high                      5.405405
                   low                      63.513514
                   medium                   31.081081
627                high                      7.407407
                   low                      77.777778
                   medium                   14.814815
628                high                      7.272727
                   low                      70.909091
                   medium                   21.818182
629                high                      7.272727
                   low                      56.363636
                   medium                   36.363636
630                high                      8.163265
                   low                      79.591837
                   medium                   12.244898
631                high                      6.250000
                   low                      76.562500
                   medium                   17.187500
632                high                      8.823529
                   low                      67.647059
                   medium                   23.529412
633                high                      4.838710
                   low                      77.419355
                   medium                   17.741935
634                high                     10.169492
                   low                      62.711864
                   medium                   27.118644
635                high                     10.666667
                   low                      61.333333
                   medium                   28.000000
636                high                     10.810811
                   low                      62.162162
                   medium                   27.027027
637                high                     16.129032
                   low                      58.064516
                   medium                   25.806452
638                high                      6.122449
                   low                      59.183673
                   medium                   34.693878
639                high                      2.898551
                   low                      81.159420
                   medium                   15.942029
640                high                      2.127660
                   low                      68.085106
                   medium                   29.787234
641                high                      8.888889
                   low                      55.555556
                   medium                   35.555556
642                high                      7.894737
                   low                      63.157895
                   medium                   28.947368
643                high                      9.433962
                   low                      77.358491
                   medium                   13.207547
644                high                      8.333333
                   low                      72.916667
                   medium                   18.750000
645                high                      6.557377
                   low                      65.573770
                   medium                   27.868852
646                high                     10.638298
                   low                      65.957447
                   medium                   23.404255
647                high                      9.803922
                   low                      64.705882
                   medium                   25.490196
648                high                      4.545455
                   low                      77.272727
                   medium                   18.181818
649                high                     10.000000
                   low                      72.000000
                   medium                   18.000000
650                high                     10.869565
                   low                      54.347826
                   medium                   34.782609
651                high                      2.000000
                   low                      80.000000
                   medium                   18.000000
652                high                     19.607843
                   low                      54.901961
                   medium                   25.490196
653                high                      2.777778
                   low                      75.000000
                   medium                   22.222222
654                high                      5.882353
                   low                      67.647059
                   medium                   26.470588
655                high                      8.219178
                   low                      71.232877
                   medium                   20.547945
656                high                      5.172414
                   low                      72.413793
                   medium                   22.413793
657                high                     11.267606
                   low                      49.295775
                   medium                   39.436620
658                high                      6.349206
                   low                      61.904762
                   medium                   31.746032
659                high                     13.559322
                   low                      67.796610
                   medium                   18.644068
660                high                     11.594203
                   low                      68.115942
                   medium                   20.289855
661                high                      9.615385
                   low                      67.307692
                   medium                   23.076923
662                high                      7.272727
                   low                      70.909091
                   medium                   21.818182
663                high                      7.142857
                   low                      75.000000
                   medium                   17.857143
664                high                      7.272727
                   low                      67.272727
                   medium                   25.454545
665                high                      9.523810
                   low                      57.142857
                   medium                   33.333333
666                high                     12.500000
                   low                      55.000000
                   medium                   32.500000
667                high                      9.803922
                   low                      66.666667
                   medium                   23.529412
668                high                      4.000000
                   low                      70.000000
                   medium                   26.000000
669                high                      5.714286
                   low                      80.000000
                   medium                   14.285714
670                high                      4.687500
                   low                      71.875000
                   medium                   23.437500
671                high                      7.547170
                   low                      58.490566
                   medium                   33.962264
672                high                      2.222222
                   low                      77.777778
                   medium                   20.000000
673                high                     12.765957
                   low                      65.957447
                   medium                   21.276596
674                high                     21.951220
                   low                      58.536585
                   medium                   19.512195
675                high                      5.454545
                   low                      67.272727
                   medium                   27.272727
676                high                      8.333333
                   low                      61.666667
                   medium                   30.000000
677                high                      4.545455
                   low                      79.545455
                   medium                   15.909091
678                high                     16.000000
                   low                      66.000000
                   medium                   18.000000
679                high                     18.181818
                   low                      52.272727
                   medium                   29.545455
680                high                      4.878049
                   low                      73.170732
                   medium                   21.951220
681                high                      6.382979
                   low                      72.340426
                   medium                   21.276596
682                high                     12.500000
                   low                      60.416667
                   medium                   27.083333
683                high                      2.325581
                   low                      79.069767
                   medium                   18.604651
684                high                     14.000000
                   low                      62.000000
                   medium                   24.000000
685                high                      8.620690
                   low                      68.965517
                   medium                   22.413793
686                high                     10.810811
                   low                      54.054054
                   medium                   35.135135
687                high                      5.084746
                   low                      55.932203
                   medium                   38.983051
688                high                     10.256410
                   low                      69.230769
                   medium                   20.512821
689                high                      6.250000
                   low                      72.916667
                   medium                   20.833333
690                high                     11.363636
                   low                      77.272727
                   medium                   11.363636
691                high                      8.163265
                   low                      77.551020
                   medium                   14.285714
692                high                     10.606061
                   low                      48.484848
                   medium                   40.909091
693                high                      9.090909
                   low                      75.000000
                   medium                   15.909091
694                high                     17.777778
                   low                      66.666667
                   medium                   15.555556
695                high                      2.325581
                   low                      76.744186
                   medium                   20.930233
696                high                      6.666667
                   low                      63.333333
                   medium                   30.000000
697                high                      6.666667
                   low                      64.444444
                   medium                   28.888889
698                high                     10.909091
                   low                      63.636364
                   medium                   25.454545
699                high                      5.555556
                   low                      63.888889
                   medium                   30.555556
700                high                     12.765957
                   low                      68.085106
                   medium                   19.148936
701                high                      5.263158
                   low                      63.157895
                   medium                   31.578947
702                high                      2.500000
                   low                      65.000000
                   medium                   32.500000
703                high                     17.307692
                   low                      53.846154
                   medium                   28.846154
704                high                      6.382979
                   low                      57.446809
                   medium                   36.170213
705                high                      3.389831
                   low                      57.627119
                   medium                   38.983051
706                high                      3.846154
                   low                      67.307692
                   medium                   28.846154
707                high                      5.128205
                   low                      71.794872
                   medium                   23.076923
708                high                     14.285714
                   low                      48.571429
                   medium                   37.142857
709                high                      9.302326
                   low                      60.465116
                   medium                   30.232558
710                high                      1.639344
                   low                      81.967213
                   medium                   16.393443
711                high                     12.000000
                   low                      62.000000
                   medium                   26.000000
712                high                      4.347826
                   low                      63.043478
                   medium                   32.608696
713                high                      6.250000
                   low                      64.583333
                   medium                   29.166667
714                high                     15.384615
                   low                      48.717949
                   medium                   35.897436
715                high                      2.083333
                   low                      72.916667
                   medium                   25.000000
716                high                      9.090909
                   low                      77.272727
                   medium                   13.636364
717                high                     13.725490
                   low                      64.705882
                   medium                   21.568627
718                high                      2.631579
                   low                      89.473684
                   medium                    7.894737
719                high                      3.389831
                   low                      69.491525
                   medium                   27.118644
720                high                     10.344828
                   low                      55.172414
                   medium                   34.482759
721                high                     14.583333
                   low                      45.833333
                   medium                   39.583333
722                high                      2.222222
                   low                      80.000000
                   medium                   17.777778
723                high                      8.510638
                   low                      63.829787
                   medium                   27.659574
724                high                      3.846154
                   low                      65.384615
                   medium                   30.769231
725                high                     10.204082
                   low                      63.265306
                   medium                   26.530612
726                high                      9.677419
                   low                      64.516129
                   medium                   25.806452
727                high                      8.510638
                   low                      57.446809
                   medium                   34.042553
728                high                     10.204082
                   low                      63.265306
                   medium                   26.530612
729                high                      7.692308
                   low                      65.384615
                   medium                   26.923077
730                high                      6.557377
                   low                      63.934426
                   medium                   29.508197
731                high                     16.666667
                   low                      56.250000
                   medium                   27.083333
732                high                     10.909091
                   low                      69.090909
                   medium                   20.000000
733                high                      9.615385
                   low                      51.923077
                   medium                   38.461538
734                high                      7.142857
                   low                      78.571429
                   medium                   14.285714
735                high                     13.461538
                   low                      71.153846
                   medium                   15.384615
736                high                      2.702703
                   low                      72.972973
                   medium                   24.324324
737                high                      5.714286
                   low                      60.000000
                   medium                   34.285714
738                high                     10.256410
                   low                      69.230769
                   medium                   20.512821
739                high                      6.382979
                   low                      63.829787
                   medium                   29.787234
740                high                      7.142857
                   low                      64.285714
                   medium                   28.571429
741                low                      65.517241
                   medium                   34.482759
742                high                      4.444444
                   low                      66.666667
                   medium                   28.888889
743                high                      2.857143
                   low                      77.142857
                   medium                   20.000000
744                high                     15.384615
                   low                      43.589744
                   medium                   41.025641
745                high                      7.317073
                   low                      75.609756
                   medium                   17.073171
746                high                      8.000000
                   low                      58.000000
                   medium                   34.000000
747                high                      5.128205
                   low                      64.102564
                   medium                   30.769231
748                high                      5.172414
                   low                      65.517241
                   medium                   29.310345
749                high                     12.500000
                   low                      52.500000
                   medium                   35.000000
750                high                      2.439024
                   low                      58.536585
                   medium                   39.024390
751                high                      2.500000
                   low                      67.500000
                   medium                   30.000000
752                high                     11.904762
                   low                      38.095238
                   medium                   50.000000
753                high                      5.405405
                   low                      70.270270
                   medium                   24.324324
754                high                      4.878049
                   low                      78.048780
                   medium                   17.073171
755                high                     11.627907
                   low                      58.139535
                   medium                   30.232558
756                high                      3.448276
                   low                      96.551724
757                high                      4.761905
                   low                      66.666667
                   medium                   28.571429
758                high                      6.122449
                   low                      63.265306
                   medium                   30.612245
759                high                     15.909091
                   low                      54.545455
                   medium                   29.545455
760                high                      4.545455
                   low                      77.272727
                   medium                   18.181818
761                high                     14.285714
                   low                      74.285714
                   medium                   11.428571
762                high                      5.128205
                   low                      64.102564
                   medium                   30.769231
763                high                      7.272727
                   low                      67.272727
                   medium                   25.454545
764                high                      5.263158
                   low                      73.684211
                   medium                   21.052632
765                high                     10.204082
                   low                      69.387755
                   medium                   20.408163
766                high                      5.555556
                   low                      72.222222
                   medium                   22.222222
767                high                      5.128205
                   low                      64.102564
                   medium                   30.769231
768                high                     12.244898
                   low                      53.061224
                   medium                   34.693878
769                high                     11.428571
                   low                      57.142857
                   medium                   31.428571
770                high                      5.882353
                   low                      70.588235
                   medium                   23.529412
771                high                     17.647059
                   low                      42.647059
                   medium                   39.705882
772                low                      74.358974
                   medium                   25.641026
773                high                      5.882353
                   low                      73.529412
                   medium                   20.588235
774                high                      9.375000
                   low                      62.500000
                   medium                   28.125000
775                high                     14.583333
                   low                      77.083333
                   medium                    8.333333
776                high                     10.869565
                   low                      60.869565
                   medium                   28.260870
777                high                      6.382979
                   low                      78.723404
                   medium                   14.893617
778                high                     15.094340
                   low                      52.830189
                   medium                   32.075472
779                high                      8.333333
                   low                      66.666667
                   medium                   25.000000
780                high                      4.166667
                   low                      75.000000
                   medium                   20.833333
781                high                      7.142857
                   low                      71.428571
                   medium                   21.428571
782                high                      7.500000
                   low                      67.500000
                   medium                   25.000000
783                high                     11.363636
                   low                      50.000000
                   medium                   38.636364
784                high                     10.000000
                   low                      57.500000
                   medium                   32.500000
785                high                      8.108108
                   low                      78.378378
                   medium                   13.513514
786                high                      5.128205
                   low                      51.282051
                   medium                   43.589744
787                high                      6.521739
                   low                      60.869565
                   medium                   32.608696
788                high                      9.803922
                   low                      43.137255
                   medium                   47.058824
789                high                     12.500000
                   low                      42.857143
                   medium                   44.642857
790                high                     12.000000
                   low                      76.000000
                   medium                   12.000000
791                high                      7.500000
                   low                      60.000000
                   medium                   32.500000
792                high                      5.454545
                   low                      60.000000
                   medium                   34.545455
793                high                      8.333333
                   low                      69.444444
                   medium                   22.222222
794                high                      6.666667
                   low                      66.666667
                   medium                   26.666667
795                high                     16.666667
                   low                      47.916667
                   medium                   35.416667
796                high                      2.941176
                   low                      79.411765
                   medium                   17.647059
797                high                      4.347826
                   low                      69.565217
                   medium                   26.086957
798                high                     17.647059
                   low                      58.823529
                   medium                   23.529412
799                high                     13.333333
                   low                      60.000000
                   medium                   26.666667
800                high                      9.375000
                   low                      65.625000
                   medium                   25.000000
801                high                      5.000000
                   low                      70.000000
                   medium                   25.000000
802                low                      75.757576
                   medium                   24.242424
803                high                      9.375000
                   low                      53.125000
                   medium                   37.500000
804                high                      4.166667
                   low                      70.833333
                   medium                   25.000000
805                high                      8.888889
                   low                      62.222222
                   medium                   28.888889
806                low                      73.684211
                   medium                   26.315789
807                high                      5.555556
                   low                      80.555556
                   medium                   13.888889
808                high                     11.764706
                   low                      52.941176
                   medium                   35.294118
809                high                      5.555556
                   low                      69.444444
                   medium                   25.000000
810                high                      2.127660
                   low                      74.468085
                   medium                   23.404255
811                high                     21.621622
                   low                      43.243243
                   medium                   35.135135
812                high                     16.129032
                   low                      67.741935
                   medium                   16.129032
813                high                     23.333333
                   low                      70.000000
                   medium                    6.666667
814                high                     10.000000
                   low                      67.500000
                   medium                   22.500000
815                high                     15.625000
                   low                      71.875000
                   medium                   12.500000
816                high                     11.428571
                   low                      57.142857
                   medium                   31.428571
817                high                      6.818182
                   low                      56.818182
                   medium                   36.363636
818                high                     11.538462
                   low                      57.692308
                   medium                   30.769231
819                high                      7.692308
                   low                      71.794872
                   medium                   20.512821
820                high                     11.627907
                   low                      53.488372
                   medium                   34.883721
821                high                      5.555556
                   low                      58.333333
                   medium                   36.111111
822                high                      7.317073
                   low                      60.975610
                   medium                   31.707317
823                high                      3.125000
                   low                      75.000000
                   medium                   21.875000
824                low                      69.696970
                   medium                   30.303030
825                high                      6.060606
                   low                      63.636364
                   medium                   30.303030
826                high                     10.526316
                   low                      60.526316
                   medium                   28.947368
827                high                     10.000000
                   low                      67.500000
                   medium                   22.500000
828                high                      6.451613
                   low                      74.193548
                   medium                   19.354839
829                high                      3.333333
                   low                      83.333333
                   medium                   13.333333
830                high                      5.128205
                   low                      66.666667
                   medium                   28.205128
831                high                      6.976744
                   low                      79.069767
                   medium                   13.953488
832                high                      5.263158
                   low                      65.789474
                   medium                   28.947368
833                high                      7.142857
                   low                      57.142857
                   medium                   35.714286
834                high                      7.692308
                   low                      56.410256
                   medium                   35.897436
835                high                      2.040816
                   low                      61.224490
                   medium                   36.734694
836                high                     13.513514
                   low                      64.864865
                   medium                   21.621622
837                high                     14.814815
                   low                      62.962963
                   medium                   22.222222
838                high                      5.769231
                   low                      69.230769
                   medium                   25.000000
839                high                      2.564103
                   low                      69.230769
                   medium                   28.205128
840                high                      6.818182
                   low                      54.545455
                   medium                   38.636364
841                high                     12.500000
                   low                      68.750000
                   medium                   18.750000
842                high                      2.857143
                   low                      80.000000
                   medium                   17.142857
843                high                      7.407407
                   low                      85.185185
                   medium                    7.407407
844                high                      3.448276
                   low                      75.862069
                   medium                   20.689655
845                low                      59.523810
                   medium                   40.476190
846                high                      7.317073
                   low                      60.975610
                   medium                   31.707317
847                high                      4.878049
                   low                      63.414634
                   medium                   31.707317
848                high                     11.111111
                   low                      66.666667
                   medium                   22.222222
849                high                      6.060606
                   low                      78.787879
                   medium                   15.151515
850                high                      5.555556
                   low                      58.333333
                   medium                   36.111111
851                high                      5.660377
                   low                      79.245283
                   medium                   15.094340
852                high                      8.108108
                   low                      70.270270
                   medium                   21.621622
853                high                      5.882353
                   low                      58.823529
                   medium                   35.294118
854                high                      8.571429
                   low                      65.714286
                   medium                   25.714286
855                high                      7.692308
                   low                      50.000000
                   medium                   42.307692
856                high                      7.407407
                   low                      62.962963
                   medium                   29.629630
857                high                     12.500000
                   low                      71.875000
                   medium                   15.625000
858                high                      6.896552
                   low                      75.862069
                   medium                   17.241379
859                high                      6.250000
                   low                      59.375000
                   medium                   34.375000
860                high                      6.250000
                   low                      59.375000
                   medium                   34.375000
861                low                      72.916667
                   medium                   27.083333
862                high                      6.250000
                   low                      78.125000
                   medium                   15.625000
863                high                      2.564103
                   low                      74.358974
                   medium                   23.076923
864                high                     12.820513
                   low                      53.846154
                   medium                   33.333333
865                high                      8.571429
                   low                      57.142857
                   medium                   34.285714
866                low                      73.913043
                   medium                   26.086957
867                high                      6.666667
                   low                      53.333333
                   medium                   40.000000
868                high                      8.333333
                   low                      75.000000
                   medium                   16.666667
869                high                      8.823529
                   low                      64.705882
                   medium                   26.470588
870                high                      2.702703
                   low                      56.756757
                   medium                   40.540541
871                high                      7.407407
                   low                      62.962963
                   medium                   29.629630
872                high                     14.705882
                   low                      47.058824
                   medium                   38.235294
873                high                     10.000000
                   low                      65.000000
                   medium                   25.000000
874                high                      9.756098
                   low                      70.731707
                   medium                   19.512195
875                high                      9.375000
                   low                      62.500000
                   medium                   28.125000
876                high                     10.526316
                   low                      60.526316
                   medium                   28.947368
877                high                      3.125000
                   low                      75.000000
                   medium                   21.875000
878                low                      77.272727
                   medium                   22.727273
879                high                      5.714286
                   low                      74.285714
                   medium                   20.000000
880                high                     14.705882
                   low                      70.588235
                   medium                   14.705882
881                high                      4.347826
                   low                      73.913043
                   medium                   21.739130
882                high                     14.285714
                   low                      57.142857
                   medium                   28.571429
883                high                     14.814815
                   low                      55.555556
                   medium                   29.629630
884                high                      4.166667
                   low                      70.833333
                   medium                   25.000000
885                high                      8.823529
                   low                      70.588235
                   medium                   20.588235
886                high                     23.404255
                   low                      53.191489
                   medium                   23.404255
887                high                      9.090909
                   low                      77.272727
                   medium                   13.636364
888                high                      9.090909
                   low                      63.636364
                   medium                   27.272727
889                high                     16.216216
                   low                      62.162162
                   medium                   21.621622
890                high                      5.128205
                   low                      53.846154
                   medium                   41.025641
891                high                      3.846154
                   low                      69.230769
                   medium                   26.923077
892                high                      9.090909
                   low                      72.727273
                   medium                   18.181818
893                high                     15.686275
                   low                      62.745098
                   medium                   21.568627
894                high                      5.555556
                   low                      63.888889
                   medium                   30.555556
895                high                      7.142857
                   low                      71.428571
                   medium                   21.428571
896                high                      4.000000
                   low                      64.000000
                   medium                   32.000000
897                high                      6.250000
                   low                      81.250000
                   medium                   12.500000
898                high                      5.714286
                   low                      68.571429
                   medium                   25.714286
899                high                      5.000000
                   low                      67.500000
                   medium                   27.500000
900                high                     11.538462
                   low                      61.538462
                   medium                   26.923077
901                high                      2.857143
                   low                      60.000000
                   medium                   37.142857
902                high                      8.333333
                   low                      58.333333
                   medium                   33.333333
903                low                      71.052632
                   medium                   28.947368
904                high                      7.692308
                   low                      88.461538
                   medium                    3.846154
905                high                      9.523810
                   low                      69.047619
                   medium                   21.428571
906                high                      6.666667
                   low                      76.666667
                   medium                   16.666667
907                high                      7.142857
                   low                      82.142857
                   medium                   10.714286
908                high                      4.166667
                   low                      75.000000
                   medium                   20.833333
909                high                      8.333333
                   low                      66.666667
                   medium                   25.000000
910                high                      7.692308
                   low                      53.846154
                   medium                   38.461538
911                high                      5.405405
                   low                      56.756757
                   medium                   37.837838
912                high                      3.333333
                   low                      70.000000
                   medium                   26.666667
913                high                     11.111111
                   low                      55.555556
                   medium                   33.333333
914                high                     17.948718
                   low                      46.153846
                   medium                   35.897436
915                high                     11.111111
                   low                      61.111111
                   medium                   27.777778
916                high                     12.903226
                   low                      64.516129
                   medium                   22.580645
917                high                      8.000000
                   low                      56.000000
                   medium                   36.000000
918                high                      5.882353
                   low                      61.764706
                   medium                   32.352941
919                high                     10.000000
                   low                      55.000000
                   medium                   35.000000
920                high                      4.000000
                   low                      88.000000
                   medium                    8.000000
921                high                      6.896552
                   low                      65.517241
                   medium                   27.586207
922                high                      4.545455
                   low                      59.090909
                   medium                   36.363636
923                high                     10.714286
                   low                      78.571429
                   medium                   10.714286
924                high                     12.500000
                   low                      62.500000
                   medium                   25.000000
925                high                      5.000000
                   low                      75.000000
                   medium                   20.000000
926                high                      3.333333
                   low                      83.333333
                   medium                   13.333333
927                high                      9.523810
                   low                      61.904762
                   medium                   28.571429
928                high                     22.857143
                   low                      51.428571
                   medium                   25.714286
929                high                      8.333333
                   low                      66.666667
                   medium                   25.000000
930                high                      8.695652
                   low                      73.913043
                   medium                   17.391304
931                high                      8.571429
                   low                      65.714286
                   medium                   25.714286
932                high                      7.142857
                   low                      78.571429
                   medium                   14.285714
933                high                      2.702703
                   low                      81.081081
                   medium                   16.216216
934                low                      79.545455
                   medium                   20.454545
935                high                      3.333333
                   low                      73.333333
                   medium                   23.333333
936                high                      5.555556
                   low                      66.666667
                   medium                   27.777778
937                high                     17.857143
                   low                      46.428571
                   medium                   35.714286
938                high                     11.538462
                   low                      65.384615
                   medium                   23.076923
939                high                      4.000000
                   low                      84.000000
                   medium                   12.000000
940                high                      7.407407
                   low                      48.148148
                   medium                   44.444444
941                high                     18.518519
                   low                      70.370370
                   medium                   11.111111
942                high                     11.111111
                   low                      72.222222
                   medium                   16.666667
943                high                     16.666667
                   low                      66.666667
                   medium                   16.666667
944                low                      75.862069
                   medium                   24.137931
945                high                     19.230769
                   low                      61.538462
                   medium                   19.230769
946                high                      5.405405
                   low                      67.567568
                   medium                   27.027027
947                high                      9.375000
                   low                      71.875000
                   medium                   18.750000
948                high                     20.000000
                   low                      55.000000
                   medium                   25.000000
949                high                     16.666667
                   low                      56.666667
                   medium                   26.666667
950                high                      2.941176
                   low                      73.529412
                   medium                   23.529412
951                high                     14.285714
                   low                      64.285714
                   medium                   21.428571
952                low                      84.615385
                   medium                   15.384615
953                high                     10.526316
                   low                      52.631579
                   medium                   36.842105
954                high                      5.263158
                   low                      68.421053
                   medium                   26.315789
955                high                      3.125000
                   low                      65.625000
                   medium                   31.250000
956                high                      5.000000
                   low                      85.000000
                   medium                   10.000000
957                low                      79.166667
                   medium                   20.833333
958                high                      8.333333
                   low                      75.000000
                   medium                   16.666667
959                low                      75.000000
                   medium                   25.000000
960                high                     10.256410
                   low                      51.282051
                   medium                   38.461538
961                high                     10.000000
                   low                      56.666667
                   medium                   33.333333
962                high                      3.571429
                   low                      67.857143
                   medium                   28.571429
963                high                      5.555556
                   low                      66.666667
                   medium                   27.777778
964                high                      3.125000
                   low                      75.000000
                   medium                   21.875000
965                high                     11.538462
                   low                      50.000000
                   medium                   38.461538
966                high                     10.344828
                   low                      72.413793
                   medium                   17.241379
967                high                      4.545455
                   low                      68.181818
                   medium                   27.272727
968                high                      5.882353
                   low                      76.470588
                   medium                   17.647059
969                high                      6.250000
                   low                      75.000000
                   medium                   18.750000
970                high                      4.166667
                   low                      50.000000
                   medium                   45.833333
971                low                      52.941176
                   medium                   47.058824
972                low                      38.888889
                   medium                   61.111111
973                high                     10.000000
                   low                      65.000000
                   medium                   25.000000
974                high                     10.526316
                   low                      73.684211
                   medium                   15.789474
975                high                      6.666667
                   low                      53.333333
                   medium                   40.000000
976                high                      4.000000
                   low                      76.000000
                   medium                   20.000000
977                high                      3.846154
                   low                      84.615385
                   medium                   11.538462
978                high                      4.347826
                   low                      56.521739
                   medium                   39.130435
979                low                      64.285714
                   medium                   35.714286
980                high                      8.000000
                   low                      68.000000
                   medium                   24.000000
981                high                     11.764706
                   low                      76.470588
                   medium                   11.764706
982                high                     10.344828
                   low                      58.620690
                   medium                   31.034483
983                high                      3.333333
                   low                      73.333333
                   medium                   23.333333
984                high                      4.347826
                   low                      60.869565
                   medium                   34.782609
985                high                      9.375000
                   low                      53.125000
                   medium                   37.500000
986                high                     14.814815
                   low                      59.259259
                   medium                   25.925926
987                high                     11.764706
                   low                      70.588235
                   medium                   17.647059
988                high                     10.000000
                   low                      65.000000
                   medium                   25.000000
989                high                      5.000000
                   low                      65.000000
                   medium                   30.000000
990                high                      5.555556
                   low                      61.111111
                   medium                   33.333333
991                high                     11.764706
                   low                      58.823529
                   medium                   29.411765
992                low                      68.181818
                   medium                   31.818182
993                high                      4.761905
                   low                      90.476190
                   medium                    4.761905
994                high                      7.142857
                   low                      85.714286
                   medium                    7.142857
995                high                      7.142857
                   low                      64.285714
                   medium                   28.571429
996                high                      5.555556
                   low                      83.333333
                   medium                   11.111111
997                high                     10.000000
                   low                      45.000000
                   medium                   45.000000
998                high                     10.000000
                   low                      80.000000
                   medium                   10.000000
999                low                      66.666667
                   medium                   33.333333
1000               low                      54.545455
                   medium                   45.454545
1001               high                     15.384615
                   low                      57.692308
                   medium                   26.923077
1002               low                      65.000000
                   medium                   35.000000
1003               high                      4.545455
                   low                      81.818182
                   medium                   13.636364
1004               high                      5.263158
                   low                      57.894737
                   medium                   36.842105
1005               high                      3.448276
                   low                      62.068966
                   medium                   34.482759
1006               high                      4.347826
                   low                      69.565217
                   medium                   26.086957
1007               high                      3.225806
                   low                      77.419355
                   medium                   19.354839
1008               high                      5.882353
                   low                      58.823529
                   medium                   35.294118
1009               low                      70.000000
                   medium                   30.000000
1010               low                      90.909091
                   medium                    9.090909
1011               low                      78.260870
                   medium                   21.739130
1012               high                     17.647059
                   low                      58.823529
                   medium                   23.529412
1013               high                      6.250000
                   low                      62.500000
                   medium                   31.250000
1014               low                      88.888889
                   medium                   11.111111
1015               low                      76.923077
                   medium                   23.076923
1016               high                     14.285714
                   low                      50.000000
                   medium                   35.714286
1017               high                      4.166667
                   low                      70.833333
                   medium                   25.000000
1018               high                      5.882353
                   low                      88.235294
                   medium                    5.882353
1019               high                     15.384615
                   low                      61.538462
                   medium                   23.076923
1020               high                      5.555556
                   low                      55.555556
                   medium                   38.888889
1021               high                      5.263158
                   low                      63.157895
                   medium                   31.578947
1022               high                      8.823529
                   low                      70.588235
                   medium                   20.588235
1023               high                     20.000000
                   low                      40.000000
                   medium                   40.000000
1024               high                     11.764706
                   low                      61.764706
                   medium                   26.470588
1025               high                      5.000000
                   low                      55.000000
                   medium                   40.000000
1026               low                      43.750000
                   medium                   56.250000
1027               low                      83.333333
                   medium                   16.666667
1028               high                      6.250000
                   low                      75.000000
                   medium                   18.750000
1029               high                      8.000000
                   low                      80.000000
                   medium                   12.000000
1030               high                     22.222222
                   low                      33.333333
                   medium                   44.444444
1031               high                      5.263158
                   low                      63.157895
                   medium                   31.578947
1032               high                      3.846154
                   low                      73.076923
                   medium                   23.076923
1033               high                     15.789474
                   low                      50.000000
                   medium                   34.210526
1034               high                     20.000000
                   low                      50.000000
                   medium                   30.000000
1035               high                     17.647059
                   low                      64.705882
                   medium                   17.647059
1036               low                      76.923077
                   medium                   23.076923
1037               high                     22.222222
                   low                      50.000000
                   medium                   27.777778
1038               high                      6.250000
                   low                      68.750000
                   medium                   25.000000
1039               high                      9.677419
                   low                      51.612903
                   medium                   38.709677
1040               low                      82.352941
                   medium                   17.647059
1041               high                      9.677419
                   low                      51.612903
                   medium                   38.709677
1042               high                     11.764706
                   low                      88.235294
1043               high                      4.761905
                   low                      61.904762
                   medium                   33.333333
1044               high                      5.555556
                   low                      88.888889
                   medium                    5.555556
1045               high                      4.545455
                   low                      59.090909
                   medium                   36.363636
1046               high                      7.142857
                   low                      50.000000
                   medium                   42.857143
1047               low                      55.000000
                   medium                   45.000000
1048               high                     10.000000
                   low                      65.000000
                   medium                   25.000000
1049               high                     28.000000
                   low                      40.000000
                   medium                   32.000000
1050               high                      8.823529
                   low                      64.705882
                   medium                   26.470588
1051               high                     43.750000
                   low                      43.750000
                   medium                   12.500000
1052               high                     22.222222
                   low                      50.000000
                   medium                   27.777778
1053               high                     12.000000
                   low                      64.000000
                   medium                   24.000000
1054               high                      6.666667
                   low                      66.666667
                   medium                   26.666667
1055               high                     14.285714
                   low                      57.142857
                   medium                   28.571429
1056               high                      3.571429
                   low                      71.428571
                   medium                   25.000000
1057               high                     11.111111
                   low                      50.000000
                   medium                   38.888889
1058               high                     10.344828
                   low                      65.517241
                   medium                   24.137931
1059               high                     25.000000
                   low                      62.500000
                   medium                   12.500000
1060               high                      6.666667
                   low                      46.666667
                   medium                   46.666667
1061               high                     21.739130
                   low                      65.217391
                   medium                   13.043478
1062               high                      8.333333
                   low                      58.333333
                   medium                   33.333333
1063               low                      66.666667
                   medium                   33.333333
1064               low                      81.250000
                   medium                   18.750000
1065               low                      91.666667
                   medium                    8.333333
1066               high                     13.333333
                   low                      53.333333
                   medium                   33.333333
1067               high                     11.111111
                   low                      66.666667
                   medium                   22.222222
1068               low                      88.888889
                   medium                   11.111111
1069               low                      53.846154
                   medium                   46.153846
1070               low                      82.352941
                   medium                   17.647059
1071               low                      64.705882
                   medium                   35.294118
1072               high                      4.761905
                   low                      76.190476
                   medium                   19.047619
1073               high                      5.263158
                   low                      57.894737
                   medium                   36.842105
1074               high                     20.000000
                   low                      60.000000
                   medium                   20.000000
1075               high                      5.263158
                   low                      68.421053
                   medium                   26.315789
1076               high                     18.181818
                   low                      63.636364
                   medium                   18.181818
1077               low                      77.777778
                   medium                   22.222222
1078               low                      70.000000
                   medium                   30.000000
1079               high                      7.142857
                   low                      71.428571
                   medium                   21.428571
1080               high                     28.571429
                   low                      42.857143
                   medium                   28.571429
1081               low                      72.727273
                   medium                   27.272727
1082               high                      9.523810
                   low                      57.142857
                   medium                   33.333333
1083               high                      7.142857
                   low                      78.571429
                   medium                   14.285714
1084               high                     10.000000
                   low                      70.000000
                   medium                   20.000000
1085               high                     13.333333
                   low                      66.666667
                   medium                   20.000000
1086               high                     11.111111
                   low                      77.777778
                   medium                   11.111111
1087               low                      77.777778
                   medium                   22.222222
1088               high                      8.695652
                   low                      47.826087
                   medium                   43.478261
1089               low                      85.714286
                   medium                   14.285714
1090               high                      3.333333
                   low                      63.333333
                   medium                   33.333333
1091               high                     27.777778
                   low                      66.666667
                   medium                    5.555556
1092               high                      5.555556
                   low                      77.777778
                   medium                   16.666667
1093               high                     18.181818
                   low                      54.545455
                   medium                   27.272727
1094               low                      70.000000
                   medium                   30.000000
1095               low                      75.000000
                   medium                   25.000000
1096               high                     13.333333
                   low                      66.666667
                   medium                   20.000000
1097               high                      7.142857
                   low                      57.142857
                   medium                   35.714286
1098               high                      5.263158
                   low                      63.157895
                   medium                   31.578947
1099               high                     13.043478
                   low                      52.173913
                   medium                   34.782609
1100               high                     10.000000
                   low                      80.000000
                   medium                   10.000000
1101               low                      75.000000
                   medium                   25.000000
1102               high                      5.263158
                   low                      73.684211
                   medium                   21.052632
1103               low                      55.555556
                   medium                   44.444444
1104               high                      6.250000
                   low                      75.000000
                   medium                   18.750000
1105               low                      77.777778
                   medium                   22.222222
1106               low                      68.750000
                   medium                   31.250000
1107               high                     11.764706
                   low                      70.588235
                   medium                   17.647059
1108               low                      91.666667
                   medium                    8.333333
1109               low                      80.000000
                   medium                   20.000000
1110               high                      9.090909
                   low                      72.727273
                   medium                   18.181818
1111               low                      71.428571
                   medium                   28.571429
1112               high                      8.333333
                   low                      91.666667
1113               high                      9.090909
                   low                      63.636364
                   medium                   27.272727
1114               high                     10.000000
                   low                      60.000000
                   medium                   30.000000
1115               low                      70.000000
                   medium                   30.000000
1116               low                      76.923077
                   medium                   23.076923
1117               high                      6.666667
                   low                      73.333333
                   medium                   20.000000
1118               high                     15.000000
                   low                      55.000000
                   medium                   30.000000
1119               high                      5.882353
                   low                      70.588235
                   medium                   23.529412
1120               high                      6.666667
                   low                      86.666667
                   medium                    6.666667
1121               high                     18.181818
                   low                      63.636364
                   medium                   18.181818
1122               low                      85.714286
                   medium                   14.285714
1123               low                      87.500000
                   medium                   12.500000
1124               high                     11.111111
                   low                      77.777778
                   medium                   11.111111
1125               high                      6.250000
                   low                      81.250000
                   medium                   12.500000
1126               high                     23.076923
                   low                      46.153846
                   medium                   30.769231
1127               low                      84.615385
                   medium                   15.384615
1128               high                      5.555556
                   low                      72.222222
                   medium                   22.222222
1129               high                     10.526316
                   low                      57.894737
                   medium                   31.578947
1130               high                      7.142857
                   low                      64.285714
                   medium                   28.571429
1131               high                     10.000000
                   low                      50.000000
                   medium                   40.000000
1132               high                     14.285714
                   low                      64.285714
                   medium                   21.428571
1133               high                      5.263158
                   low                      57.894737
                   medium                   36.842105
1134               low                      70.000000
                   medium                   30.000000
1135               high                     16.666667
                   low                      50.000000
                   medium                   33.333333
1136               high                      8.333333
                   low                      58.333333
                   medium                   33.333333
1137               low                      66.666667
                   medium                   33.333333
1138               low                      88.888889
                   medium                   11.111111
1139               low                      70.833333
                   medium                   29.166667
1140               high                     10.000000
                   low                      40.000000
                   medium                   50.000000
1141               high                     14.285714
                   low                      64.285714
                   medium                   21.428571
1142               low                      66.666667
                   medium                   33.333333
1143               low                      64.285714
                   medium                   35.714286
1144               high                     12.500000
                   low                      50.000000
                   medium                   37.500000
1145               low                      70.000000
                   medium                   30.000000
1146               high                      9.090909
                   low                      63.636364
                   medium                   27.272727
1147               high                      7.692308
                   low                      69.230769
                   medium                   23.076923
1148               high                      7.692308
                   low                      53.846154
                   medium                   38.461538
1149               high                     33.333333
                   low                      66.666667
1150               high                      5.882353
                   low                      47.058824
                   medium                   47.058824
1151               low                      90.909091
                   medium                    9.090909
1152               high                      9.090909
                   low                      81.818182
                   medium                    9.090909
1153               low                      63.157895
                   medium                   36.842105
1154               low                      83.333333
                   medium                   16.666667
1155               low                      72.727273
                   medium                   27.272727
1156               high                      7.142857
                   low                      50.000000
                   medium                   42.857143
1157               low                     100.000000
1158               high                      5.000000
                   low                      65.000000
                   medium                   30.000000
1159               low                      76.923077
                   medium                   23.076923
1160               low                      80.000000
                   medium                   20.000000
1161               high                     10.000000
                   low                      70.000000
                   medium                   20.000000
1162               high                      5.882353
                   low                      70.588235
                   medium                   23.529412
1163               low                      77.777778
                   medium                   22.222222
1164               high                     10.000000
                   low                      70.000000
                   medium                   20.000000
1165               low                      75.000000
                   medium                   25.000000
1166               low                     100.000000
1167               low                     100.000000
1168               high                     12.500000
                   low                      62.500000
                   medium                   25.000000
1169               high                      7.142857
                   low                      71.428571
                   medium                   21.428571
1170               low                      77.777778
                   medium                   22.222222
1171               low                      80.000000
                   medium                   20.000000
1172               high                     12.500000
                   low                      62.500000
                   medium                   25.000000
1173               low                      66.666667
                   medium                   33.333333
1174               high                      7.142857
                   low                      78.571429
                   medium                   14.285714
1175               low                      83.333333
                   medium                   16.666667
1176               low                      42.857143
                   medium                   57.142857
1177               high                      9.090909
                   low                      63.636364
                   medium                   27.272727
1178               high                      9.090909
                   low                      81.818182
                   medium                    9.090909
1179               low                      75.000000
                   medium                   25.000000
1180               low                      76.923077
                   medium                   23.076923
1181               high                     16.666667
                   low                      50.000000
                   medium                   33.333333
1182               high                     33.333333
                   low                      16.666667
                   medium                   50.000000
1183               high                     12.500000
                   low                      75.000000
                   medium                   12.500000
1184               low                     100.000000
1185               low                      41.666667
                   medium                   58.333333
1186               high                      8.333333
                   low                      58.333333
                   medium                   33.333333
1187               high                     25.000000
                   low                      50.000000
                   medium                   25.000000
1188               low                      90.000000
                   medium                   10.000000
1189               low                      62.500000
                   medium                   37.500000
1190               low                      16.666667
                   medium                   83.333333
1191               high                     16.666667
                   low                      66.666667
                   medium                   16.666667
1192               high                     10.000000
                   low                      80.000000
                   medium                   10.000000
1193               high                      8.333333
                   low                      83.333333
                   medium                    8.333333
1194               low                      75.000000
                   medium                   25.000000
1195               high                     12.500000
                   low                      75.000000
                   medium                   12.500000
1196               low                      63.636364
                   medium                   36.363636
1197               low                      60.000000
                   medium                   40.000000
1198               low                      66.666667
                   medium                   33.333333
1199               high                     25.000000
                   low                      50.000000
                   medium                   25.000000
1200               high                     33.333333
                   low                      66.666667
1201               high                     11.111111
                   low                      66.666667
                   medium                   22.222222
1202               low                      60.000000
                   medium                   40.000000
1203               low                      37.500000
                   medium                   62.500000
1204               low                      70.000000
                   medium                   30.000000
1205               low                      62.500000
                   medium                   37.500000
1206               low                     100.000000
1207               high                     10.000000
                   low                      60.000000
                   medium                   30.000000
1208               low                      70.000000
                   medium                   30.000000
1209               high                     30.769231
                   low                      38.461538
                   medium                   30.769231
1210               low                      50.000000
                   medium                   50.000000
1211               high                      9.090909
                   low                      72.727273
                   medium                   18.181818
1212               low                      75.000000
                   medium                   25.000000
1213               low                      60.000000
                   medium                   40.000000
1214               high                     16.666667
                   low                      50.000000
                   medium                   33.333333
1215               high                      7.142857
                   low                      85.714286
                   medium                    7.142857
1216               low                      57.142857
                   medium                   42.857143
1217               low                      66.666667
                   medium                   33.333333
1218               low                      55.555556
                   medium                   44.444444
1219               high                      7.692308
                   low                      76.923077
                   medium                   15.384615
1220               high                     16.666667
                   low                      41.666667
                   medium                   41.666667
1221               high                     12.500000
                   low                      75.000000
                   medium                   12.500000
1222               high                     10.000000
                   low                      50.000000
                   medium                   40.000000
1223               high                      6.666667
                   low                      73.333333
                   medium                   20.000000
1224               low                      90.909091
                   medium                    9.090909
1225               high                     16.666667
                   low                      55.555556
                   medium                   27.777778
1226               high                     10.000000
                   low                      50.000000
                   medium                   40.000000
1227               low                      75.000000
                   medium                   25.000000
1228               low                      62.500000
                   medium                   37.500000
1229               low                      92.857143
                   medium                    7.142857
1230               low                      75.000000
                   medium                   25.000000
1231               low                      80.000000
                   medium                   20.000000
1232               high                     14.285714
                   low                      42.857143
                   medium                   42.857143
1233               high                     11.111111
                   low                      66.666667
                   medium                   22.222222
1234               low                      83.333333
                   medium                   16.666667
1235               high                      9.090909
                   low                      63.636364
                   medium                   27.272727
1236               low                      66.666667
                   medium                   33.333333
1237               high                      5.000000
                   low                      60.000000
                   medium                   35.000000
1238               high                     21.428571
                   low                      57.142857
                   medium                   21.428571
1239               high                     20.000000
                   low                      60.000000
                   medium                   20.000000
1240               high                     25.000000
                   low                      50.000000
                   medium                   25.000000
1241               high                     12.500000
                   low                      62.500000
                   medium                   25.000000
1242               low                      50.000000
                   medium                   50.000000
1243               low                      66.666667
                   medium                   33.333333
1244               high                     25.000000
                   low                      50.000000
                   medium                   25.000000
1245               high                     12.500000
                   low                      62.500000
                   medium                   25.000000
1246               high                     36.363636
                   low                      45.454545
                   medium                   18.181818
1247               low                      88.888889
                   medium                   11.111111
1248               low                      81.818182
                   medium                   18.181818
1249               high                     10.000000
                   low                      60.000000
                   medium                   30.000000
1250               high                     10.000000
                   low                      70.000000
                   medium                   20.000000
1251               low                      50.000000
                   medium                   50.000000
1252               low                      75.000000
                   medium                   25.000000
1253               high                     11.111111
                   low                      77.777778
                   medium                   11.111111
1254               low                      50.000000
                   medium                   50.000000
1255               high                     14.285714
                   low                      85.714286
1256               high                     28.571429
                   low                      57.142857
                   medium                   14.285714
1257               high                     20.000000
                   low                      60.000000
                   medium                   20.000000
1258               high                     10.000000
                   low                      70.000000
                   medium                   20.000000
1259               low                      66.666667
                   medium                   33.333333
1260               low                      81.818182
                   medium                   18.181818
1261               low                      85.714286
                   medium                   14.285714
1262               low                     100.000000
1263               low                      71.428571
                   medium                   28.571429
1264               low                      50.000000
                   medium                   50.000000
1265               low                      60.000000
                   medium                   40.000000
1266               low                      77.777778
                   medium                   22.222222
1267               high                      9.090909
                   low                      45.454545
                   medium                   45.454545
1268               low                      66.666667
                   medium                   33.333333
1269               low                     100.000000
1270               low                     100.000000
1271               low                      66.666667
                   medium                   33.333333
1272               low                      88.888889
                   medium                   11.111111
1273               low                      50.000000
                   medium                   50.000000
1274               low                      66.666667
                   medium                   33.333333
1275               high                     16.666667
                   low                      83.333333
1276               low                     100.000000
1277               high                     10.526316
                   low                      63.157895
                   medium                   26.315789
1278               high                     14.285714
                   low                      57.142857
                   medium                   28.571429
1279               high                     12.500000
                   low                      62.500000
                   medium                   25.000000
1280               low                      71.428571
                   medium                   28.571429
1281               low                      66.666667
                   medium                   33.333333
1282               low                      83.333333
                   medium                   16.666667
1283               low                      53.846154
                   medium                   46.153846
1284               low                      81.818182
                   medium                   18.181818
1285               low                      66.666667
                   medium                   33.333333
1286               low                      80.000000
                   medium                   20.000000
1287               low                     100.000000
1288               low                     100.000000
1289               low                     100.000000
1290               high                     20.000000
                   low                      60.000000
                   medium                   20.000000
1291               high                     15.384615
                   low                      69.230769
                   medium                   15.384615
1292               low                     100.000000
1293               low                      85.714286
                   medium                   14.285714
1294               low                      80.000000
                   medium                   20.000000
1295               low                      70.000000
                   medium                   30.000000
1296               low                      70.588235
                   medium                   29.411765
1297               high                     12.500000
                   low                      75.000000
                   medium                   12.500000
1298               low                      60.000000
                   medium                   40.000000
1299               high                     20.000000
                   low                      30.000000
                   medium                   50.000000
1300               low                      66.666667
                   medium                   33.333333
1301               low                      66.666667
                   medium                   33.333333
1302               high                     25.000000
                   low                      75.000000
1303               high                      9.090909
                   low                      90.909091
1304               low                      80.000000
                   medium                   20.000000
1305               low                      63.636364
                   medium                   36.363636
1306               high                     40.000000
                   low                      20.000000
                   medium                   40.000000
1307               low                      54.545455
                   medium                   45.454545
1308               high                     16.666667
                   low                      50.000000
                   medium                   33.333333
1309               high                     18.181818
                   low                      45.454545
                   medium                   36.363636
1310               low                      50.000000
                   medium                   50.000000
1311               high                      8.333333
                   low                      58.333333
                   medium                   33.333333
1312               low                      60.000000
                   medium                   40.000000
1313               low                      83.333333
                   medium                   16.666667
1314               high                     16.666667
                   low                      66.666667
                   medium                   16.666667
1315               low                      87.500000
                   medium                   12.500000
1316               high                      8.333333
                   low                      58.333333
                   medium                   33.333333
1317               high                     11.111111
                   low                      44.444444
                   medium                   44.444444
1318               high                     10.000000
                   low                      80.000000
                   medium                   10.000000
1319               low                      50.000000
                   medium                   50.000000
1320               low                     100.000000
1321               high                     25.000000
                   low                      41.666667
                   medium                   33.333333
1322               low                      72.727273
                   medium                   27.272727
1323               low                      72.727273
                   medium                   27.272727
1324               high                     16.666667
                   low                      50.000000
                   medium                   33.333333
1325               high                     16.666667
                   low                      50.000000
                   medium                   33.333333
1326               low                      66.666667
                   medium                   33.333333
1327               low                      84.615385
                   medium                   15.384615
1328               high                     16.666667
                   low                      66.666667
                   medium                   16.666667
1329               low                     100.000000
1330               high                     16.666667
                   low                      41.666667
                   medium                   41.666667
1331               high                     25.000000
                   low                      75.000000
1332               low                     100.000000
1333               high                     12.500000
                   low                      25.000000
                   medium                   62.500000
1334               low                      60.000000
                   medium                   40.000000
1335               low                      66.666667
                   medium                   33.333333
1336               low                      85.714286
                   medium                   14.285714
1337               low                      80.000000
                   medium                   20.000000
1338               low                      71.428571
                   medium                   28.571429
1339               low                      60.000000
                   medium                   40.000000
1340               low                      57.142857
                   medium                   42.857143
1341               high                     25.000000
                   low                      50.000000
                   medium                   25.000000
1342               low                      25.000000
                   medium                   75.000000
1343               low                      62.500000
                   medium                   37.500000
1344               high                     12.500000
                   low                      75.000000
                   medium                   12.500000
1345               high                     14.285714
                   low                      57.142857
                   medium                   28.571429
1346               high                     16.666667
                   low                      66.666667
                   medium                   16.666667
1347               high                      6.666667
                   low                      73.333333
                   medium                   20.000000
1348               low                     100.000000
1349               high                      8.333333
                   low                      58.333333
                   medium                   33.333333
1350               low                      60.000000
                   medium                   40.000000
1351               high                      9.090909
                   low                      63.636364
                   medium                   27.272727
1352               high                     11.111111
                   low                      77.777778
                   medium                   11.111111
1353               high                     27.272727
                   low                      54.545455
                   medium                   18.181818
1354               high                     21.428571
                   low                      57.142857
                   medium                   21.428571
1355               low                      62.500000
                   medium                   37.500000
1356               low                      50.000000
                   medium                   50.000000
1357               low                     100.000000
1358               low                     100.000000
1359               low                      87.500000
                   medium                   12.500000
1360               low                     100.000000
1361               high                     16.666667
                   low                      33.333333
                   medium                   50.000000
1362               high                     14.285714
                   low                      57.142857
                   medium                   28.571429
1363               high                     17.647059
                   low                      58.823529
                   medium                   23.529412
1364               high                     28.571429
                   low                      42.857143
                   medium                   28.571429
1365               low                      76.470588
                   medium                   23.529412
1366               high                     20.000000
                   low                      80.000000
1367               high                     11.111111
                   low                      77.777778
                   medium                   11.111111
1368               high                     14.285714
                   low                      71.428571
                   medium                   14.285714
1369               high                     33.333333
                   low                      44.444444
                   medium                   22.222222
1370               low                      65.217391
                   medium                   34.782609
1371               low                      83.333333
                   medium                   16.666667
1372               low                     100.000000
1373               low                      25.000000
                   medium                   75.000000
1374               high                     25.000000
                   low                      25.000000
                   medium                   50.000000
1375               low                     100.000000
1376               low                     100.000000
1377               low                      71.428571
                   medium                   28.571429
1378               low                      71.428571
                   medium                   28.571429
1379               high                     25.000000
                   low                      75.000000
1380               low                     100.000000
1381               low                     100.000000
1382               low                     100.000000
1383               low                      50.000000
                   medium                   50.000000
1384               low                      75.000000
                   medium                   25.000000
1385               low                      50.000000
                   medium                   50.000000
1386               low                     100.000000
1387               high                     11.111111
                   low                      88.888889
1388               low                      85.714286
                   medium                   14.285714
1389               low                     100.000000
1390               high                     18.181818
                   low                      54.545455
                   medium                   27.272727
1391               low                      60.000000
                   medium                   40.000000
1392               low                      57.142857
                   medium                   42.857143
1393               high                     28.571429
                   low                      57.142857
                   medium                   14.285714
1394               high                     33.333333
                   low                      66.666667
1395               high                     25.000000
                   low                      75.000000
1396               high                     20.000000
                   low                      40.000000
                   medium                   40.000000
1397               low                      80.000000
                   medium                   20.000000
1398               high                     10.000000
                   low                      70.000000
                   medium                   20.000000
1399               low                      70.000000
                   medium                   30.000000
1400               low                      71.428571
                   medium                   28.571429
1401               low                     100.000000
1402               low                     100.000000
1404               low                      50.000000
                   medium                   50.000000
1405               medium                  100.000000
1406               low                      60.000000
                   medium                   40.000000
1407               low                     100.000000
1408               low                      66.666667
                   medium                   33.333333
1409               low                      66.666667
                   medium                   33.333333
1410               low                      50.000000
                   medium                   50.000000
1411               low                     100.000000
1412               high                     25.000000
                   low                      75.000000
1413               high                     40.000000
                   low                      40.000000
                   medium                   20.000000
1414               low                      66.666667
                   medium                   33.333333
1415               low                      75.000000
                   medium                   25.000000
1416               low                     100.000000
1417               low                      40.000000
                   medium                   60.000000
1418               high                     33.333333
                   low                      66.666667
1419               low                      20.000000
                   medium                   80.000000
1420               low                      66.666667
                   medium                   33.333333
1421               low                     100.000000
1422               high                     33.333333
                   low                      33.333333
                   medium                   33.333333
1423               low                     100.000000
1424               low                      85.714286
                   medium                   14.285714
1425               low                      33.333333
                   medium                   66.666667
1426               low                      85.714286
                   medium                   14.285714
1427               low                     100.000000
1428               low                      50.000000
                   medium                   50.000000
1429               high                     16.666667
                   low                      83.333333
1430               low                      88.888889
                   medium                   11.111111
1431               high                     11.111111
                   low                      88.888889
1432               high                     33.333333
                   low                      33.333333
                   medium                   33.333333
1433               low                     100.000000
1434               low                     100.000000
1435               high                     25.000000
                   low                      75.000000
1436               low                      80.000000
                   medium                   20.000000
1437               low                      66.666667
                   medium                   33.333333
1438               low                     100.000000
1439               low                      83.333333
                   medium                   16.666667
1440               low                     100.000000
1441               low                      85.714286
                   medium                   14.285714
1442               medium                  100.000000
1443               high                     40.000000
                   low                      20.000000
                   medium                   40.000000
1444               high                     33.333333
                   low                      33.333333
                   medium                   33.333333
1445               high                     33.333333
                   low                      66.666667
1446               high                     11.111111
                   low                      55.555556
                   medium                   33.333333
1447               high                      9.090909
                   low                      63.636364
                   medium                   27.272727
1448               high                     16.666667
                   low                      83.333333
1449               low                      66.666667
                   medium                   33.333333
1450               low                      25.000000
                   medium                   75.000000
1451               low                      50.000000
                   medium                   50.000000
1452               low                      86.666667
                   medium                   13.333333
1453               low                      75.000000
                   medium                   25.000000
1454               low                      75.000000
                   medium                   25.000000
1455               high                     20.000000
                   low                      60.000000
                   medium                   20.000000
1456               high                     33.333333
                   low                      66.666667
1457               low                      40.000000
                   medium                   60.000000
1458               high                     57.142857
                   low                      28.571429
                   medium                   14.285714
1459               high                     25.000000
                   low                      75.000000
1460               high                     10.000000
                   low                      60.000000
                   medium                   30.000000
1461               low                      75.000000
                   medium                   25.000000
1462               high                     23.076923
                   low                      53.846154
                   medium                   23.076923
1463               low                      66.666667
                   medium                   33.333333
1464               low                      40.000000
                   medium                   60.000000
1465               high                     33.333333
                   low                      33.333333
                   medium                   33.333333
1466               high                     22.222222
                   low                      77.777778
1467               low                      75.000000
                   medium                   25.000000
1468               low                     100.000000
1469               low                      75.000000
                   medium                   25.000000
1470               low                      71.428571
                   medium                   28.571429
1471               high                     16.666667
                   low                      33.333333
                   medium                   50.000000
1472               medium                  100.000000
1473               medium                  100.000000
1474               high                     25.000000
                   low                      50.000000
                   medium                   25.000000
1475               low                      83.333333
                   medium                   16.666667
1476               high                     20.000000
                   low                      40.000000
                   medium                   40.000000
1477               high                     16.666667
                   low                      66.666667
                   medium                   16.666667
1478               low                      55.555556
                   medium                   44.444444
1479               low                      60.000000
                   medium                   40.000000
1480               high                     14.285714
                   low                      71.428571
                   medium                   14.285714
1481               low                      80.000000
                   medium                   20.000000
1482               high                      9.090909
                   low                      81.818182
                   medium                    9.090909
1483               low                      75.000000
                   medium                   25.000000
1484               high                     50.000000
                   low                      50.000000
1485               low                      83.333333
                   medium                   16.666667
1486               low                      83.333333
                   medium                   16.666667
1487               high                     33.333333
                   low                      33.333333
                   medium                   33.333333
1488               low                      75.000000
                   medium                   25.000000
1489               high                     25.000000
                   low                      50.000000
                   medium                   25.000000
1490               low                      66.666667
                   medium                   33.333333
1491               low                     100.000000
1492               low                     100.000000
1493               high                     12.500000
                   low                      75.000000
                   medium                   12.500000
1494               high                     37.500000
                   low                      50.000000
                   medium                   12.500000
1495               high                     25.000000
                   low                      75.000000
1496               low                      85.714286
                   medium                   14.285714
1497               high                     20.000000
                   low                      60.000000
                   medium                   20.000000
1498               high                     42.857143
                   low                      57.142857
1499               medium                  100.000000
1500               low                      80.000000
                   medium                   20.000000
1501               low                      50.000000
                   medium                   50.000000
1502               high                     33.333333
                   low                      66.666667
1503               low                     100.000000
1504               low                     100.000000
1505               low                     100.000000
1507               low                     100.000000
1508               low                      60.000000
                   medium                   40.000000
1509               low                     100.000000
1510               high                     33.333333
                   medium                   66.666667
1511               low                      66.666667
                   medium                   33.333333
1512               low                      66.666667
                   medium                   33.333333
1513               high                     25.000000
                   low                      75.000000
1514               low                     100.000000
1515               low                      66.666667
                   medium                   33.333333
1516               low                      83.333333
                   medium                   16.666667
1517               high                     20.000000
                   low                      50.000000
                   medium                   30.000000
1518               high                      9.090909
                   low                      54.545455
                   medium                   36.363636
1519               high                     33.333333
                   low                      33.333333
                   medium                   33.333333
1520               low                      75.000000
                   medium                   25.000000
1521               low                     100.000000
1523               high                     12.500000
                   low                      62.500000
                   medium                   25.000000
1524               low                      80.000000
                   medium                   20.000000
1525               high                     50.000000
                   low                      50.000000
1526               low                     100.000000
1527               high                     14.285714
                   low                      42.857143
                   medium                   42.857143
1528               low                      33.333333
                   medium                   66.666667
1529               low                      85.714286
                   medium                   14.285714
1530               low                      66.666667
                   medium                   33.333333
1531               low                     100.000000
1532               medium                  100.000000
1533               high                     25.000000
                   low                      50.000000
                   medium                   25.000000
1534               low                      66.666667
                   medium                   33.333333
1535               low                     100.000000
1536               low                      66.666667
                   medium                   33.333333
1537               low                     100.000000
1538               low                     100.000000
1539               high                     20.000000
                   low                      40.000000
                   medium                   40.000000
1540               high                     33.333333
                   low                      66.666667
1541               low                      75.000000
                   medium                   25.000000
1542               low                     100.000000
1543               low                     100.000000
1544               low                      83.333333
                   medium                   16.666667
1545               high                     20.000000
                   low                      40.000000
                   medium                   40.000000
1546               low                      66.666667
                   medium                   33.333333
1547               low                     100.000000
1548               low                     100.000000
1549               low                      66.666667
                   medium                   33.333333
1550               high                    100.000000
1551               high                     20.000000
                   low                      80.000000
1552               low                     100.000000
1553               high                     25.000000
                   low                      75.000000
1554               low                     100.000000
1555               low                      40.000000
                   medium                   60.000000
1556               low                      60.000000
                   medium                   40.000000
1557               low                      80.000000
                   medium                   20.000000
1558               low                     100.000000
1559               low                     100.000000
1560               high                    100.000000
1561               low                     100.000000
1562               low                      50.000000
                   medium                   50.000000
1563               low                     100.000000
1564               high                     33.333333
                   low                      66.666667
1565               high                     16.666667
                   low                      83.333333
1566               low                     100.000000
1567               high                     80.000000
                   low                      20.000000
1568               low                     100.000000
1569               low                     100.000000
1570               low                     100.000000
1571               high                     25.000000
                   low                      50.000000
                   medium                   25.000000
1572               high                      9.090909
                   low                      54.545455
                   medium                   36.363636
1573               low                     100.000000
1574               high                     66.666667
                   low                      33.333333
1575               low                     100.000000
1576               low                      33.333333
                   medium                   66.666667
1577               low                      50.000000
                   medium                   50.000000
1578               high                     16.666667
                   low                      50.000000
                   medium                   33.333333
1579               low                      50.000000
                   medium                   50.000000
1580               high                     20.000000
                   low                      80.000000
1581               low                     100.000000
1582               low                      85.714286
                   medium                   14.285714
1583               low                     100.000000
1584               low                      50.000000
                   medium                   50.000000
1585               low                     100.000000
1586               high                     33.333333
                   medium                   66.666667
1587               low                      66.666667
                   medium                   33.333333
1588               low                     100.000000
1589               low                     100.000000
1591               low                      50.000000
                   medium                   50.000000
1592               medium                  100.000000
1593               low                     100.000000
1594               high                     28.571429
                   low                      57.142857
                   medium                   14.285714
1595               low                     100.000000
1596               low                     100.000000
1597               low                     100.000000
1598               low                     100.000000
1599               low                      40.000000
                   medium                   60.000000
1600               low                      66.666667
                   medium                   33.333333
1601               high                     25.000000
                   low                      75.000000
1602               low                     100.000000
1604               low                      66.666667
                   medium                   33.333333
1605               low                     100.000000
1606               low                     100.000000
1607               low                     100.000000
1609               high                     33.333333
                   medium                   66.666667
1611               low                      66.666667
                   medium                   33.333333
1612               low                     100.000000
1613               low                      33.333333
                   medium                   66.666667
1614               medium                  100.000000
1615               low                      75.000000
                   medium                   25.000000
1616               low                      80.000000
                   medium                   20.000000
1617               low                      83.333333
                   medium                   16.666667
1618               low                     100.000000
1619               low                     100.000000
1620               low                      55.555556
                   medium                   44.444444
1621               low                     100.000000
1622               low                      60.000000
                   medium                   40.000000
1623               low                     100.000000
1624               low                     100.000000
1625               low                     100.000000
1626               low                     100.000000
1627               low                     100.000000
1628               low                      50.000000
                   medium                   50.000000
1629               low                      50.000000
                   medium                   50.000000
1630               high                     12.500000
                   low                      62.500000
                   medium                   25.000000
1631               low                     100.000000
1632               low                      83.333333
                   medium                   16.666667
1633               low                     100.000000
1634               low                     100.000000
1635               low                      50.000000
                   medium                   50.000000
1636               low                      66.666667
                   medium                   33.333333
1637               low                      66.666667
                   medium                   33.333333
1638               low                      75.000000
                   medium                   25.000000
1640               medium                  100.000000
1641               high                     25.000000
                   low                      50.000000
                   medium                   25.000000
1642               low                     100.000000
1643               low                     100.000000
1644               low                      50.000000
                   medium                   50.000000
1645               low                     100.000000
1646               high                     33.333333
                   low                      33.333333
                   medium                   33.333333
1647               high                     25.000000
                   low                      50.000000
                   medium                   25.000000
1648               low                     100.000000
1649               low                      66.666667
                   medium                   33.333333
1650               medium                  100.000000
1651               low                      66.666667
                   medium                   33.333333
1652               medium                  100.000000
1653               low                     100.000000
1654               high                     25.000000
                   low                      50.000000
                   medium                   25.000000
1655               low                     100.000000
1656               low                     100.000000
1658               high                     33.333333
                   low                      66.666667
1659               medium                  100.000000
1661               low                      80.000000
                   medium                   20.000000
1662               low                     100.000000
1663               low                      50.000000
                   medium                   50.000000
1664               low                     100.000000
1667               high                     22.222222
                   low                      44.444444
                   medium                   33.333333
1668               low                     100.000000
1669               low                     100.000000
1670               low                     100.000000
1671               medium                  100.000000
1672               low                     100.000000
1673               low                      50.000000
                   medium                   50.000000
1674               low                     100.000000
1675               low                     100.000000
1676               low                     100.000000
1677               low                     100.000000
1678               low                     100.000000
1679               medium                  100.000000
1680               low                     100.000000
1681               low                      50.000000
                   medium                   50.000000
1682               low                      50.000000
                   medium                   50.000000
1683               low                     100.000000
1684               low                     100.000000
1685               high                    100.000000
1686               low                     100.000000
1687               low                     100.000000
1688               low                     100.000000
1689               low                     100.000000
1690               low                      50.000000
                   medium                   50.000000
1691               low                      83.333333
                   medium                   16.666667
1692               low                      66.666667
                   medium                   33.333333
1693               low                      50.000000
                   medium                   50.000000
1694               low                     100.000000
1695               low                      50.000000
                   medium                   50.000000
1696               low                      50.000000
                   medium                   50.000000
1697               high                     33.333333
                   low                      66.666667
1698               low                     100.000000
1699               low                      50.000000
                   medium                   50.000000
1701               low                     100.000000
1702               low                      50.000000
                   medium                   50.000000
1703               low                     100.000000
1704               low                     100.000000
1705               low                      50.000000
                   medium                   50.000000
1707               medium                  100.000000
1708               low                     100.000000
1709               low                     100.000000
1710               low                     100.000000
1711               low                     100.000000
1712               low                      66.666667
                   medium                   33.333333
1713               high                     20.000000
                   low                      60.000000
                   medium                   20.000000
1714               medium                  100.000000
1715               low                     100.000000
1716               medium                  100.000000
1717               low                     100.000000
1719               low                     100.000000
1720               low                     100.000000
1721               medium                  100.000000
1722               low                      66.666667
                   medium                   33.333333
1723               low                     100.000000
1724               low                     100.000000
1725               low                     100.000000
1726               low                      66.666667
                   medium                   33.333333
1727               low                     100.000000
1728               low                      71.428571
                   medium                   28.571429
1729               high                     25.000000
                   low                      50.000000
                   medium                   25.000000
1730               low                     100.000000
1731               high                     33.333333
                   low                      33.333333
                   medium                   33.333333
1732               low                     100.000000
1733               low                     100.000000
1734               low                     100.000000
1735               low                     100.000000
1736               low                     100.000000
1737               low                     100.000000
1738               low                      75.000000
                   medium                   25.000000
1739               low                     100.000000
1740               low                      50.000000
                   medium                   50.000000
1741               low                      66.666667
                   medium                   33.333333
1742               low                     100.000000
1743               low                     100.000000
1745               high                     20.000000
                   low                      80.000000
1747               low                      66.666667
                   medium                   33.333333
1748               low                     100.000000
1749               low                     100.000000
1750               low                     100.000000
1751               low                      66.666667
                   medium                   33.333333
1752               low                     100.000000
1753               medium                  100.000000
1755               high                    100.000000
1756               low                      60.000000
                   medium                   40.000000
1757               low                     100.000000
1758               medium                  100.000000
1759               low                     100.000000
1761               low                      50.000000
                   medium                   50.000000
1763               medium                  100.000000
1764               medium                  100.000000
1766               high                     14.285714
                   low                      57.142857
                   medium                   28.571429
1767               low                     100.000000
1768               low                      50.000000
                   medium                   50.000000
1769               high                     50.000000
                   low                      50.000000
1770               low                      87.500000
                   medium                   12.500000
1771               medium                  100.000000
1773               low                     100.000000
1774               high                     25.000000
                   low                      25.000000
                   medium                   50.000000
1775               low                     100.000000
1776               low                     100.000000
1777               low                     100.000000
1778               high                     28.571429
                   low                      42.857143
                   medium                   28.571429
1783               low                      50.000000
                   medium                   50.000000
1784               low                     100.000000
1785               low                      50.000000
                   medium                   50.000000
1786               low                      50.000000
                   medium                   50.000000
1787               low                      66.666667
                   medium                   33.333333
1788               low                      66.666667
                   medium                   33.333333
1789               high                     33.333333
                   low                      33.333333
                   medium                   33.333333
1790               low                     100.000000
1791               medium                  100.000000
1793               low                     100.000000
1794               low                     100.000000
1795               low                      75.000000
                   medium                   25.000000
1796               low                     100.000000
1798               high                     33.333333
                   medium                   66.666667
1799               medium                  100.000000
1800               low                     100.000000
1801               low                      66.666667
                   medium                   33.333333
1802               low                     100.000000
1803               low                     100.000000
1804               low                     100.000000
1805               low                     100.000000
1806               low                     100.000000
1811               medium                  100.000000
1812               low                     100.000000
1813               low                     100.000000
1814               low                     100.000000
1816               high                     50.000000
                   low                      50.000000
1817               low                      66.666667
                   medium                   33.333333
1818               low                      50.000000
                   medium                   50.000000
1819               low                     100.000000
1820               low                      50.000000
                   medium                   50.000000
1821               low                     100.000000
1823               low                     100.000000
1824               low                     100.000000
1825               low                     100.000000
1826               low                     100.000000
1828               low                     100.000000
1829               low                     100.000000
1830               high                     25.000000
                   low                      25.000000
                   medium                   50.000000
1831               low                     100.000000
1832               low                     100.000000
1833               low                      75.000000
                   medium                   25.000000
1834               low                     100.000000
1835               medium                  100.000000
1836               low                     100.000000
1838               high                     50.000000
                   medium                   50.000000
1839               low                      50.000000
                   medium                   50.000000
1841               low                      50.000000
                   medium                   50.000000
1842               low                      66.666667
                   medium                   33.333333
1843               medium                  100.000000
1844               low                     100.000000
1845               medium                  100.000000
1848               low                     100.000000
1851               low                     100.000000
1852               low                     100.000000
1853               low                     100.000000
1854               low                     100.000000
1855               low                     100.000000
1856               low                     100.000000
1857               low                      50.000000
                   medium                   50.000000
1858               low                     100.000000
1859               low                     100.000000
1860               low                     100.000000
1861               medium                  100.000000
1863               low                     100.000000
1864               low                      50.000000
                   medium                   50.000000
1866               low                     100.000000
1867               medium                  100.000000
1869               low                     100.000000
1870               low                     100.000000
1871               medium                  100.000000
1872               low                      50.000000
                   medium                   50.000000
1873               low                      75.000000
                   medium                   25.000000
1876               high                     33.333333
                   low                      66.666667
1877               medium                  100.000000
1878               low                     100.000000
1880               high                     33.333333
                   low                      33.333333
                   medium                   33.333333
1882               low                     100.000000
1883               low                     100.000000
1884               low                     100.000000
1885               low                     100.000000
1890               low                     100.000000
1892               low                     100.000000
1894               medium                  100.000000
1895               low                     100.000000
1896               low                     100.000000
1899               low                     100.000000
1900               high                     33.333333
                   medium                   66.666667
1901               high                     50.000000
                   medium                   50.000000
1902               low                     100.000000
1903               low                     100.000000
1904               medium                  100.000000
1905               low                     100.000000
1908               low                      50.000000
                   medium                   50.000000
1909               low                     100.000000
1911               low                      50.000000
                   medium                   50.000000
1912               low                     100.000000
1916               high                     40.000000
                   low                      40.000000
                   medium                   20.000000
1917               low                     100.000000
1918               low                     100.000000
1919               low                     100.000000
1920               low                     100.000000
1921               low                     100.000000
1922               high                     50.000000
                   low                      50.000000
1923               low                     100.000000
1924               low                     100.000000
1925               high                     50.000000
                   low                      50.000000
1926               high                     33.333333
                   low                      66.666667
1927               low                     100.000000
1929               low                     100.000000
1930               low                      50.000000
                   medium                   50.000000
1931               low                     100.000000
1932               low                      50.000000
                   medium                   50.000000
1935               low                      80.000000
                   medium                   20.000000
1936               low                      66.666667
                   medium                   33.333333
1938               low                     100.000000
1939               low                      50.000000
                   medium                   50.000000
1941               high                     50.000000
                   low                      50.000000
1942               low                      66.666667
                   medium                   33.333333
1947               low                     100.000000
1948               medium                  100.000000
1954               low                     100.000000
1955               low                     100.000000
1958               low                     100.000000
1959               high                     50.000000
                   low                      50.000000
1960               low                     100.000000
1961               low                     100.000000
1962               low                     100.000000
1964               medium                  100.000000
1967               low                     100.000000
1968               low                     100.000000
1969               low                      50.000000
                   medium                   50.000000
1970               medium                  100.000000
1972               low                     100.000000
1973               medium                  100.000000
1976               low                     100.000000
1977               low                      75.000000
                   medium                   25.000000
1978               low                     100.000000
1979               low                     100.000000
1983               low                      66.666667
                   medium                   33.333333
1985               low                     100.000000
1986               high                    100.000000
1988               low                     100.000000
1990               low                      50.000000
                   medium                   50.000000
1991               low                      66.666667
                   medium                   33.333333
1992               low                     100.000000
1995               medium                  100.000000
1999               low                     100.000000
2000               low                     100.000000
2001               low                     100.000000
2003               low                     100.000000
2004               low                     100.000000
2005               low                     100.000000
2006               low                     100.000000
2007               low                     100.000000
2009               low                     100.000000
2012               low                     100.000000
2013               low                     100.000000
2014               medium                  100.000000
2016               low                     100.000000
2018               low                     100.000000
2019               low                     100.000000
2021               low                     100.000000
2023               low                     100.000000
2024               low                     100.000000
2028               high                    100.000000
2031               high                    100.000000
2032               low                     100.000000
2033               low                     100.000000
2034               low                     100.000000
2041               low                      50.000000
                   medium                   50.000000
2042               low                     100.000000
2044               low                     100.000000
2047               low                      50.000000
                   medium                   50.000000
2050               high                    100.000000
2052               low                      80.000000
                   medium                   20.000000
2054               low                     100.000000
2055               low                     100.000000
2056               low                     100.000000
2057               low                     100.000000
2058               low                      50.000000
                   medium                   50.000000
2059               low                     100.000000
2062               low                     100.000000
2069               low                     100.000000
2070               medium                  100.000000
2073               low                     100.000000
2074               low                     100.000000
2078               low                     100.000000
2080               low                     100.000000
2081               low                     100.000000
2088               low                     100.000000
2089               medium                  100.000000
2090               medium                  100.000000
2092               low                     100.000000
2096               low                     100.000000
2099               low                     100.000000
2100               medium                  100.000000
2101               low                     100.000000
2103               low                     100.000000
2107               low                     100.000000
2109               low                     100.000000
2110               low                     100.000000
2113               high                    100.000000
2114               low                     100.000000
2117               low                     100.000000
2118               medium                  100.000000
2119               medium                  100.000000
2123               low                     100.000000
2124               medium                  100.000000
2125               low                      50.000000
                   medium                   50.000000
2135               low                     100.000000
2141               low                     100.000000
2147               medium                  100.000000
2148               low                     100.000000
2150               low                     100.000000
2153               low                     100.000000
2155               low                     100.000000
2160               low                      66.666667
                   medium                   33.333333
2162               low                     100.000000
2163               high                    100.000000
2164               high                     50.000000
                   medium                   50.000000
2166               low                     100.000000
2170               low                     100.000000
2172               low                     100.000000
2183               low                      66.666667
                   medium                   33.333333
2186               low                     100.000000
2188               low                     100.000000
2190               low                     100.000000
2198               low                     100.000000
2200               low                     100.000000
2202               low                     100.000000
2203               low                     100.000000
2207               low                     100.000000
2215               low                     100.000000
2219               low                      50.000000
                   medium                   50.000000
2220               low                     100.000000
2222               low                     100.000000
2224               medium                  100.000000
2227               low                     100.000000
2228               high                    100.000000
2231               low                     100.000000
2238               low                     100.000000
2242               medium                  100.000000
2243               low                     100.000000
2247               low                     100.000000
2248               medium                  100.000000
2260               low                     100.000000
2267               low                     100.000000
2270               low                     100.000000
2271               low                     100.000000
2272               low                     100.000000
2278               medium                  100.000000
2281               low                     100.000000
2282               low                     100.000000
2285               low                     100.000000
2289               high                     20.000000
                   low                      40.000000
                   medium                   40.000000
2290               low                     100.000000
2291               low                     100.000000
2292               low                     100.000000
2294               low                     100.000000
2296               low                     100.000000
2300               low                     100.000000
2305               low                     100.000000
2310               low                     100.000000
2311               low                     100.000000
2315               low                     100.000000
2324               low                     100.000000
2327               medium                  100.000000
2342               low                      50.000000
                   medium                   50.000000
2348               low                     100.000000
2350               low                      50.000000
                   medium                   50.000000
2352               medium                  100.000000
2354               medium                  100.000000
2365               low                      66.666667
                   medium                   33.333333
2376               low                     100.000000
2377               low                      25.000000
                   medium                   75.000000
2378               low                     100.000000
2382               low                     100.000000
2388               low                     100.000000
2392               low                     100.000000
2395               low                     100.000000
2404               low                     100.000000
2405               low                     100.000000
2407               low                      75.000000
                   medium                   25.000000
2410               low                     100.000000
2419               medium                  100.000000
2422               low                     100.000000
2423               low                     100.000000
2426               medium                  100.000000
2433               low                     100.000000
2443               medium                  100.000000
2453               low                     100.000000
2455               low                     100.000000
2460               medium                  100.000000
2466               low                     100.000000
2469               low                     100.000000
2470               low                     100.000000
2472               low                     100.000000
2473               low                     100.000000
2481               low                     100.000000
2490               low                     100.000000
2503               low                      50.000000
                   medium                   50.000000
2508               medium                  100.000000
2509               low                     100.000000
2512               low                     100.000000
2513               high                    100.000000
2514               low                     100.000000
2522               low                     100.000000
2535               low                     100.000000
2537               low                     100.000000
2544               low                     100.000000
2570               low                     100.000000
2583               low                     100.000000
2605               medium                  100.000000
2633               low                     100.000000
2639               medium                  100.000000
2668               high                    100.000000
2669               low                     100.000000
2674               low                     100.000000
2721               low                     100.000000
2804               low                     100.000000
2805               medium                  100.000000
2820               low                     100.000000
2829               low                     100.000000
2830               medium                  100.000000
2840               low                     100.000000
2857               medium                  100.000000
2893               low                     100.000000
2935               low                     100.000000
2941               medium                  100.000000
2950               low                     100.000000
3001               low                     100.000000
3010               medium                  100.000000
3020               medium                  100.000000
3067               low                     100.000000
3123               low                     100.000000
3149               low                     100.000000
3177               low                     100.000000
3252               low                     100.000000
3259               low                     100.000000
3270               medium                  100.000000
3367               low                     100.000000
3464               low                     100.000000
4466               low                     100.000000
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[81]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#df_raw.head()</span>
<span class="n">df_raw</span><span class="o">.</span><span class="n">to_pickle</span><span class="p">(</span><span class="s2">&quot;train_checkpoint_13&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="1.4-Display-Address-and-Street-Address">1.4 Display Address and Street Address<a class="anchor-link" href="#1.4-Display-Address-and-Street-Address">&#182;</a></h3><p>Both features are ignored. I use the latitude and longitude for the location. Display address and Street address filled in for every entry. I considered creating a feature using the count of the number of times each entry appeared but decided against it as what I do with building_id more accuratly captures that information.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="1.5-Apartment-Features">1.5 Apartment Features<a class="anchor-link" href="#1.5-Apartment-Features">&#182;</a></h3><p>Each apartment feature entry contains a list of all features submitted for that apartment. There is no standardization to the features thus some features try to convey the same information with different spellings ("Pre-war","pre war", etc). There are 1556 different features. The top 10 features show up 9,000 or more times. Keywords can be used in an attempt to consolidate similar features. I created 11 new input features based on the apartment features: 1 that has the total number of features in the listing and 10 binary features for the presence/absence of one of the 10 most listed features.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[82]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_features</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span> <span class="p">{</span><span class="s1">&#39;listing_id&#39;</span><span class="p">:</span> <span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;listing_id&#39;</span><span class="p">],</span><span class="s1">&#39;features&#39;</span><span class="p">:</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;features&#39;</span><span class="p">]})</span>
<span class="n">df_features</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt output_prompt">Out[82]:</div>

<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>features</th>
      <th>listing_id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>10</th>
      <td>[]</td>
      <td>7211212</td>
    </tr>
    <tr>
      <th>10000</th>
      <td>[Doorman, Elevator, Fitness Center, Cats Allow...</td>
      <td>7150865</td>
    </tr>
    <tr>
      <th>100004</th>
      <td>[Laundry In Building, Dishwasher, Hardwood Flo...</td>
      <td>6887163</td>
    </tr>
    <tr>
      <th>100007</th>
      <td>[Hardwood Floors, No Fee]</td>
      <td>6888711</td>
    </tr>
    <tr>
      <th>100013</th>
      <td>[Pre-War]</td>
      <td>6934781</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[83]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">feature_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">feature_list_count</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">df_features</span><span class="p">[</span><span class="s1">&#39;features&#39;</span><span class="p">]:</span>
    <span class="n">feature_list_count</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">y</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">feature_list</span><span class="p">:</span>
            <span class="n">feature_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
            
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of different features: &quot;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">feature_list</span><span class="p">))</span>

<span class="c1">#add count of features to df_raw</span>
<span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;features_count&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">feature_list_count</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">df_raw</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="c1">#print(len(feature_count))</span>
<span class="c1">#print(len(df_features[&#39;features&#39;]))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Number of different features:  1556
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[107]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">benchmark_dict</span><span class="p">)</span>
<span class="n">g1</span> <span class="o">=</span> <span class="n">df_raw</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;features_count&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">agg</span><span class="p">({</span><span class="s1">&#39;features_count&#39;</span><span class="p">:</span> <span class="s1">&#39;count&#39;</span><span class="p">})</span>
<span class="n">g2</span> <span class="o">=</span> <span class="n">df_raw</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;features_count&#39;</span><span class="p">,</span> <span class="s1">&#39;interest_level&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">agg</span><span class="p">({</span><span class="s1">&#39;features_count&#39;</span><span class="p">:</span> <span class="s1">&#39;count&#39;</span><span class="p">})</span>
<span class="n">g3</span> <span class="o">=</span> <span class="n">g2</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="mi">100</span> <span class="o">*</span> <span class="n">x</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">sum</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">g1</span><span class="o">.</span><span class="n">to_string</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">g3</span><span class="o">.</span><span class="n">to_string</span><span class="p">())</span>
<span class="c1">#print(g2.to_string())</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>{&#39;medium&#39;: 0.22752877289674178, &#39;high&#39;: 0.07778813421948452, &#39;low&#39;: 0.6946830928837737}
                features_count
features_count                
0                         3218
1                         4340
2                         4938
3                         6211
4                         5459
5                         4547
6                         3835
7                         3374
8                         2840
9                         2453
10                        2217
11                        1681
12                        1377
13                        1009
14                         737
15                         456
16                         283
17                         161
18                          89
19                          45
20                          24
21                          14
22                          13
23                           6
24                           5
25                           2
26                           8
27                           3
28                           3
31                           1
32                           1
36                           1
39                           1
                               features_count
features_count interest_level                
0              high                 12.057178
               low                  65.195774
               medium               22.747048
1              high                  8.456221
               low                  71.290323
               medium               20.253456
2              high                  9.113001
               low                  69.866343
               medium               21.020656
3              high                  7.454516
               low                  73.643536
               medium               18.901948
4              high                  7.125847
               low                  73.017036
               medium               19.857117
5              high                  6.663734
               low                  72.641302
               medium               20.694964
6              high                  7.431551
               low                  69.152542
               medium               23.415906
7              high                  6.105513
               low                  69.146414
               medium               24.748074
8              high                  6.690141
               low                  66.830986
               medium               26.478873
9              high                  6.807990
               low                  68.406033
               medium               24.785976
10             high                  5.908886
               low                  66.576455
               medium               27.514659
11             high                  7.436050
               low                  64.485425
               medium               28.078525
12             high                  7.697894
               low                  64.560639
               medium               27.741467
13             high                  8.325074
               low                  62.239841
               medium               29.435084
14             high                  9.905020
               low                  61.872456
               medium               28.222524
15             high                 12.280702
               low                  56.359649
               medium               31.359649
16             high                  8.833922
               low                  66.784452
               medium               24.381625
17             high                  8.695652
               low                  60.869565
               medium               30.434783
18             high                  8.988764
               low                  62.921348
               medium               28.089888
19             high                  6.666667
               low                  66.666667
               medium               26.666667
20             low                  58.333333
               medium               41.666667
21             high                  7.142857
               low                  64.285714
               medium               28.571429
22             low                  84.615385
               medium               15.384615
23             high                 16.666667
               low                  50.000000
               medium               33.333333
24             high                 20.000000
               low                  80.000000
25             low                 100.000000
26             high                 25.000000
               low                  75.000000
27             low                  66.666667
               medium               33.333333
28             low                 100.000000
31             low                 100.000000
32             high                100.000000
36             medium              100.000000
39             medium              100.000000
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>1556 features. Creating a Counter object shows that the 10 most common show up at least 9,000 times. Also saved the features to a csv to check some of the keywords.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[108]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">Counter</span>
<span class="n">feature_flat</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">df_features</span><span class="p">[</span><span class="s1">&#39;features&#39;</span><span class="p">]:</span>
    <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>
        <span class="n">feature_flat</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
            
<span class="n">feature_count</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">feature_flat</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">feature_count</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Counter({&#39;Elevator&#39;: 25915, &#39;Cats Allowed&#39;: 23540, &#39;Hardwood Floors&#39;: 23527, &#39;Dogs Allowed&#39;: 22035, &#39;Doorman&#39;: 20898, &#39;Dishwasher&#39;: 20426, &#39;No Fee&#39;: 18062, &#39;Laundry in Building&#39;: 16344, &#39;Fitness Center&#39;: 13252, &#39;Pre-War&#39;: 9148, &#39;Laundry in Unit&#39;: 8738, &#39;Roof Deck&#39;: 6542, &#39;Outdoor Space&#39;: 5268, &#39;Dining Room&#39;: 5136, &#39;High Speed Internet&#39;: 4299, &#39;Balcony&#39;: 2992, &#39;Swimming Pool&#39;: 2730, &#39;Laundry In Building&#39;: 2593, &#39;New Construction&#39;: 2559, &#39;Terrace&#39;: 2283, &#39;Exclusive&#39;: 2167, &#39;Loft&#39;: 2100, &#39;Garden/Patio&#39;: 1943, &#39;Wheelchair Access&#39;: 1358, &#39;Common Outdoor Space&#39;: 1293, &#39;HARDWOOD&#39;: 914, &#39;Fireplace&#39;: 912, &#39;SIMPLEX&#39;: 908, &#39;prewar&#39;: 855, &#39;LOWRISE&#39;: 789, &#39;Garage&#39;: 745, &#39;Laundry Room&#39;: 719, &#39;Reduced Fee&#39;: 699, &#39;Laundry In Unit&#39;: 697, &#39;Furnished&#39;: 689, &#39;Multi-Level&#39;: 622, &#39;Private Outdoor Space&#39;: 508, &#39;Prewar&#39;: 494, &#39;PublicOutdoor&#39;: 423, &#39;Parking Space&#39;: 418, &#39;Roof-deck&#39;: 397, &#39;dishwasher&#39;: 378, &#39;High Ceilings&#39;: 362, &#39;elevator&#39;: 357, &#39;Renovated&#39;: 323, &#39;Pool&#39;: 282, &#39;LAUNDRY&#39;: 256, &#39;Green Building&#39;: 246, &#39;HIGH CEILINGS&#39;: 235, &#39;LIVE IN SUPER&#39;: 217, &#39;High Ceiling&#39;: 200, &#39;Washer in Unit&#39;: 186, &#39;Dryer in Unit&#39;: 186, &#39;Storage&#39;: 170, &#39;Stainless Steel Appliances&#39;: 170, &#39;On-site laundry&#39;: 168, &#39;Concierge&#39;: 166, &#39;Newly renovated&#39;: 154, &#39;On-site Laundry&#39;: 148, &#39;Live In Super&#39;: 144, &#39;Light&#39;: 144, &#39;Hardwood&#39;: 144, &#39;On-site Garage&#39;: 142, &#39;Washer/Dryer&#39;: 133, &#39;Granite Kitchen&#39;: 116, &#39;Gym/Fitness&#39;: 115, &#39;Pets on approval&#39;: 107, &#39;Marble Bath&#39;: 106, &#39;Walk in Closet(s)&#39;: 105, &#39;Subway&#39;: 100, &#39;Residents Lounge&#39;: 98, &#39;Patio&#39;: 98, &#39;Valet&#39;: 94, &#39;Common parking/Garage&#39;: 91, &#39;Live-in superintendent&#39;: 90, &#39;Full-time doorman&#39;: 84, &#39;Parking&#39;: 83, &#39;Live-in Super&#39;: 82, &#39;EAT IN KITCHEN&#39;: 82, &#39;WiFi Access&#39;: 81, &#39;HIGHRISE&#39;: 80, &#39;Lounge&#39;: 77, &#39;Short Term Allowed&#39;: 76, &#39;EXPOSED BRICK&#39;: 75, &#39;Childrens Playroom&#39;: 74, &#39;doorman&#39;: 69, &#39;Garden&#39;: 69, &#39;Bike room&#39;: 67, &#39;No pets&#39;: 67, &#39;Central A/C&#39;: 63, &#39;Duplex&#39;: 60, &#39;Luxury building&#39;: 58, &#39;balcony&#39;: 56, &#39;Residents Garden&#39;: 56, &#39;ROOFDECK&#39;: 55, &#39;ACTUAL APT. PHOTOS&#39;: 55, &#39;Common roof deck&#39;: 53, &#39;Outdoor Areas&#39;: 52, &#39;Indoor Pool&#39;: 48, &#39;New construction&#39;: 48, &#39;View&#39;: 47, &#39;storage&#39;: 47, &#39;Bike Room&#39;: 44, &#39;Lounge room&#39;: 44, &#39;Virtual Doorman&#39;: 42, &#39;pool&#39;: 41, &#39;building-common-outdoor-space&#39;: 39, &#39;patio&#39;: 38, &#39;Air conditioning&#39;: 37, &#39;Washer &amp; Dryer&#39;: 36, &#39;Valet Parking&#39;: 36, &#34;Children&#39;s Playroom&#34;: 36, &#39;Courtyard&#39;: 34, &#39;Live/Work&#39;: 33, &#39;Shares OK&#39;: 33, &#39;Wheelchair Ramp&#39;: 32, &#39;Sauna&#39;: 32, &#39;Private balcony&#39;: 31, &#39;private-balcony&#39;: 31, &#39;Gym&#39;: 31, &#39;terrace&#39;: 30, &#39;Health Club&#39;: 29, &#39;Washer/Dryer in building&#39;: 28, &#39;Full Service Garage&#39;: 28, &#39;FT Doorman&#39;: 28, &#39;Microwave&#39;: 28, &#39;Live-In Superintendent&#39;: 28, &#39;Outdoor Entertainment Space&#39;: 28, &#39;gym&#39;: 27, &#39;On-site Parking Lot&#39;: 27, &#39;Laundry&#39;: 27, &#39;Exposed Brick&#39;: 26, &#39;garden&#39;: 26, &#39;Post-War&#39;: 25, &#39;Basement Storage&#39;: 25, &#39;Private outdoor space&#39;: 25, &#39;BROWNSTONE&#39;: 25, &#39;Hi Rise&#39;: 23, &#39;In-Unit Washer/Dryer&#39;: 23, &#39;private-outdoor-space&#39;: 22, &#39;MIDRISE&#39;: 21, &#39;Post War&#39;: 21, &#39;on-site super&#39;: 21, &#39;Common terrace&#39;: 21, &#39;Sublet&#39;: 21, &#39;Concierge Service&#39;: 20, &#39;Hardwood floors&#39;: 19, &#39;WALK IN CLOSET&#39;: 19, &#39;Pet Friendly&#39;: 18, &#39;Private backyard&#39;: 17, &#39;On-Site Parking&#39;: 17, &#39;DECORATIVE FIREPLACE&#39;: 17, &#39;Common garden&#39;: 16, &#39;Attended Lobby&#39;: 16, &#39;High-speed Internet&#39;: 16, &#39;Rooftop Terrace&#39;: 16, &#39;Business Center&#39;: 16, &#39;Private parking&#39;: 16, &#39;assigned-parking-space&#39;: 16, &#39;Guarantors Accepted&#39;: 16, &#39;Private terrace&#39;: 16, &#39;storage room&#39;: 16, &#39;NO FEE&#39;: 15, &#39;Deck&#39;: 15, &#39;Common backyard&#39;: 15, &#39;Terraces / Balconies&#39;: 14, &#39;playroom/nursery&#39;: 14, &#39;view&#39;: 13, &#39;Flex-2&#39;: 13, &#39;Package Room&#39;: 13, &#39;Cable/Satellite TV&#39;: 12, &#39;Actual Apt. Photos&#39;: 12, &#39;Skylight&#39;: 12, &#39;Eat In Kitchen&#39;: 12, &#39;Community Recreation Facilities&#39;: 12, &#39;Outdoor Pool&#39;: 12, &#39;DINING ROOM&#39;: 11, &#39;Mail Room&#39;: 11, &#39;Live/work&#39;: 11, &#39;Shared backyard&#39;: 11, &#39;Laundry On Floor&#39;: 11, &#39;garage&#39;: 11, &#39;Central AC&#39;: 10, &#39;BALCONY&#39;: 10, &#39;Eat-in Kitchen&#39;: 10, &#39;Gym In Building&#39;: 10, &#39;Multi-level&#39;: 10, &#39;Washer/Dryer in Unit&#39;: 10, &#39;BACKYARD&#39;: 9, &#39;Tenant Lounge&#39;: 9, &#39;Central Air&#39;: 9, &#39;Rooftop Deck&#39;: 9, &#39;Marble Bathroom&#39;: 9, &#39;Bike Storage&#39;: 9, &#39;Private Deck&#39;: 9, &#39;Decorative Fireplace&#39;: 9, &#39;Playroom&#39;: 9, &#39;renovated&#39;: 9, &#39;Fireplaces&#39;: 9, &#39;Screening Room&#39;: 8, &#39;valet&#39;: 8, &#39;24/7 Concierge&#39;: 8, &#39;All utilities included&#39;: 8, &#39;laundry &amp; housekeeping&#39;: 8, &#39;Valet services including dry cleaning&#39;: 8, &#39;Media Room&#39;: 8, &#39;High ceilings&#39;: 8, &#39;Sundeck&#39;: 8, &#39;hardwood floors&#39;: 8, &#39;Roof deck&#39;: 8, &#39;high ceilings&#39;: 8, &#39;Private laundry room on every floor&#39;: 8, &#39;Valet Services&#39;: 8, &#39;Video Intercom&#39;: 8, &#39;CLOSETS GALORE!&#39;: 7, &#39;DUPLEX&#39;: 7, &#39;TONS OF NATURAL LIGHT&#39;: 7, &#39;Garbage Disposal&#39;: 7, &#39;Jacuzzi&#39;: 7, &#39;Washer/Dryer Hookup&#39;: 7, &#39;WiFi&#39;: 7, &#39;Gut Renovated&#39;: 7, &#39;Billiards Room&#39;: 7, &#39;exposed brick&#39;: 7, &#39;CHEFS KITCHEN&#39;: 7, &#39;Parking Available&#39;: 7, &#39;24/7 Doorman&#39;: 7, &#39;QUEEN SIZED ROOMS&#39;: 7, &#39;CONDO FINISHES&#39;: 7, &#39;fireplace&#39;: 7, &#39;City view&#39;: 7, &#39;pets&#39;: 7, &#39;central ac&#39;: 7, &#39;pets allowed&#39;: 7, &#39;Wood-burning Fireplace&#39;: 6, &#39;Laundry in building&#39;: 6, &#39;Pets Allowed&#39;: 6, &#39;Backyard&#39;: 6, &#39;Storage Available&#39;: 6, &#39;Walk-In Closet&#39;: 6, &#39;Roof access&#39;: 6, &#39;Crown Moldings&#39;: 6, &#39;Flex-3&#39;: 6, &#39;On-site super&#39;: 6, &#39;Private garden&#39;: 6, &#39;Housekeeping service&#39;: 5, &#39;Cinema Room&#39;: 5, &#39;parking&#39;: 5, &#39;Cold Storage&#39;: 5, &#39;Fitness Room&#39;: 5, &#39;state-of-the-art fitness center&#39;: 5, &#39;lounge&#39;: 5, &#39;S/S appliances&#39;: 5, &#39;RENOVATED&#39;: 5, &#39;Exposed brick&#39;: 5, &#39;roof deck&#39;: 5, &#39;video intercom&#39;: 5, &#39;Party Room&#39;: 5, &#39;On-site ATM Machine&#39;: 5, &#39;Breakfast Bar&#39;: 5, &#39;Penthouse&#39;: 5, &#39;Private Terrace&#39;: 5, &#39;Virtual Tour&#39;: 5, &#39;Outdoor roof deck overlooking New York Harbor and Battery Park&#39;: 5, &#39;Fully  equipped&#39;: 5, &#39;Spa Services&#39;: 5, &#39;New Renovation&#39;: 5, &#39;Part-time doorman&#39;: 5, &#39;Magnificent Venetian-Style&#39;: 5, &#39;Actual Photos!&#39;: 5, &#39;deck&#39;: 5, &#39;Private roofdeck&#39;: 5, &#39;Park view&#39;: 5, &#39;Storage Facilities available&#39;: 5, &#39;Large Living Room&#39;: 5, &#39;24/7 Doorman Concierge&#39;: 5, &#39;On-site Parking available&#39;: 5, &#39;Yoga Classes&#39;: 4, &#39;Valet Service&#39;: 4, &#39;business center&#39;: 4, &#39;Live-In Super&#39;: 4, &#39;Call/Text Abraham Caro @ 917-373-0862&#39;: 4, &#39;Pets: Cats/Small Dogs&#39;: 4, &#39;On-site parking&#39;: 4, &#39;GARDEN&#39;: 4, &#39;walk-up&#39;: 4, &#39;HARDWOOD FLOORS&#39;: 4, &#39;Yard&#39;: 4, &#39;Close to subway&#39;: 4, &#39;Washer/Dryer In-Unit&#39;: 4, &#39;Home Office&#39;: 4, &#39;Roof Deck with Grills&#39;: 4, &#39;microwave&#39;: 4, &#39;Granite Counter Tops&#39;: 4, &#39;Renovated Kitchen&#39;: 4, &#39;Cable ready&#39;: 4, &#39;Screening room&#39;: 4, &#39;laundry room&#39;: 4, &#39;rooftop deck&#39;: 4, &#39;Exercise/Yoga Studio&#39;: 4, &#39;common storage&#39;: 4, &#39;Private Roof Deck&#39;: 4, &#39;One Month Free&#39;: 4, &#39;Newly Renovated&#39;: 4, &#39;Bright&#39;: 4, &#39;sauna&#39;: 4, &#39;Spacious&#39;: 4, &#39;Live in Super&#39;: 4, &#39;Media Screening Room&#39;: 4, &#39;Free WiFi in Club lounge&#39;: 3, &#39;Gardening area with rentable plots&#39;: 3, &#39;Roof grilling area&#39;: 3, &#39;Queen Sized Bedrooms&#39;: 3, &#39;Free Wifi&#39;: 3, &#39;Childrens Playroom&#39;: 3, &#39;steam room&#39;: 3, &#39;Storage Space&#39;: 3, &#39;Party room&#39;: 3, &#39;Outdoor Basketball Court&#39;: 3, &#39;Children playroom&#39;: 3, &#39;Private roof access&#39;: 3, &#39;Original Details&#39;: 3, &#39;exercise studio&#39;: 3, &#39;24 hr doorman&#39;: 3, &#39;Low Fee&#39;: 3, &#39;Recessed Lighting&#39;: 3, &#39;Full size gym&#39;: 3, &#39;Stainless Steel&#39;: 3, &#39;Granite countertops&#39;: 3, &#39;billiards room&#39;: 3, &#39;Elegant glass-enclosed private lounge with magnificent river views&#39;: 3, &#39;Wi-Fi Access&#39;: 3, &#39;DW&#39;: 3, &#39;Convinient to all major transportation&#39;: 3, &#39;separate kitchen&#39;: 3, &#34;children&#39;s playroom&#34;: 3, &#39;Deco Brick Wall&#39;: 3, &#39;Bike storage&#39;: 3, &#39;water filtration system&#39;: 3, &#39;Package &amp; grocery delivery storage&#39;: 3, &#39;French Doors&#39;: 3, &#39;Skylights&#39;: 3, &#39;bike room&#39;: 3, &#39;fitness center&#39;: 3, &#39;Laundry on every floor&#39;: 3, &#39;Bike &amp; stroller storage&#39;: 3, &#39;Yoga / dance studio&#39;: 3, &#39;Fully-equipped Club fitness center&#39;: 3, &#39;townhouse&#39;: 3, &#39;Dry cleaning service&#39;: 3, &#39;Washer/Dryer in Bldg&#39;: 3, &#39;All pets ok&#39;: 3, &#39;Rentable&#39;: 3, &#39;Multi Level&#39;: 3, &#39;Billiards Lounge&#39;: 3, &#39;Bluetooth&#39;: 3, &#39;Window Bath&#39;: 3, &#39;Diplomats OK&#39;: 3, &#39;Gas Included&#39;: 3, &#39;Short term&#39;: 3, &#39;Yoga Room&#39;: 3, &#39;On-site Super&#39;: 3, &#39;Utilities Included&#39;: 3, &#39;Bright &amp; Sunny&#39;: 3, &#39;Skylight Atrium&#39;: 3, &#39;Billiards table and wet bar&#39;: 3, &#39;fully equipped chefs kitchen with private roof deck&#39;: 3, &#39;walk in closet&#39;: 3, &#39;Valet Laundry&#39;: 3, &#39;deco fireplace&#39;: 3, &#39;Leed Certified&#39;: 3, &#39;Movie theater&#39;: 3, &#39;Package service&#39;: 3, &#39;Dry Cleaning Service&#39;: 3, &#39;Oak Floors&#39;: 3, &#39;Roof Deck with real grass&#39;: 3, &#39;Rent Stabalized&#39;: 3, &#39;On-Site Attended Garage&#39;: 3, &#39;On-site parking available&#39;: 3, &#39;Shared garden&#39;: 3, &#39;Granite Counters&#39;: 3, &#39;Pre War&#39;: 3, &#39;Duplex Lounge&#39;: 3, &#39;Underground Parking&#39;: 3, &#39;On-site lifestyle concierge by Luxury Attach&#39;: 3, &#39;Live Work&#39;: 3, &#39;Brand New&#39;: 3, &#39;private storage&#39;: 3, &#39;Large Windows with Lots of Natural Light&#39;: 3, &#39;Outstanding Shopping&#39;: 3, &#39;fitness facility&#39;: 3, &#39;Roofdeck&#39;: 3, &#39;Complimentary Sunday brunch&#39;: 3, &#39;Pet grooming room&#39;: 3, &#39;Outdoor BBQs&#39;: 3, &#39;Game room&#39;: 3, &#39;Large Living-room&#39;: 3, &#39;Close to Subway&#39;: 3, &#39;Club sun deck has spectacular city and river views&#39;: 3, &#39;Stunning roof deck with breathtaking views&#39;: 3, &#39;Dining room&#39;: 3, &#39;24HR Doorman&#39;: 3, &#39;Unassigned Paid parking available nearby&#39;: 3, &#39;High Speed Internet Available&#39;: 3, &#39;24-hour doorman&#39;: 3, &#39;stainless steel appliances&#39;: 3, &#39;lounge area&#39;: 2, &#39;&lt;null&gt;&#39;: 2, &#39;Deco Fireplace&#39;: 2, &#39;Granite Counter&#39;: 2, &#39;Dish Washer&#39;: 2, &#39;A Full service Luxury Highrise&#39;: 2, &#39;Large windows&#39;: 2, &#39;indoor swimming pool&#39;: 2, &#39;Renovated Bathroom&#39;: 2, &#39;Queen Sized Bedroom&#39;: 2, &#39;Laundry in Some Units&#39;: 2, &#39;rooftop&#39;: 2, &#39;Lounge spaces&#39;: 2, &#34;Children&#39;s playroom&#34;: 2, &#39;Finished Basement&#39;: 2, &#39;Hardwood Floor&#39;: 2, &#39;Common Storage&#39;: 2, &#39;DISHWASHER&#39;: 2, &#39;Large Windows w/ lots of Natural Light&#39;: 2, &#39;Corner Unit&#39;: 2, &#39;NO PETS&#39;: 2, &#39;private backyard&#39;: 2, &#39;heat hot water included&#39;: 2, &#39;PRIVATE BALCONY&#39;: 2, &#39;Stainless Appliances&#39;: 2, &#39;Working Fireplace&#39;: 2, &#39;Union Square&#39;: 2, &#39;housekeeping&#39;: 2, &#39;Breakfast bar&#39;: 2, &#39;Hardwood Flooring&#39;: 2, &#39;stainless steel&#39;: 2, &#39;Full-service condominium&#39;: 2, &#39;Expansive Sundeck&#39;: 2, &#39;No Fee!&#39;: 2, &#39;King Bedrooms&#39;: 2, &#39;Exposed Brick Wall&#39;: 2, &#39;SSA Kitchen&#39;: 2, &#39;Water view&#39;: 2, &#39;Southern Exposure&#39;: 2, &#34;children&#39;s room&#34;: 2, &#39;Natural Light&#39;: 2, &#39;Pets - case by case.&#39;: 2, &#39;Granite Countertops&#39;: 2, &#39;24hr doorman&#39;: 2, &#39;Eat-in kitchen&#39;: 2, &#39;elevator &amp; Laundry&#39;: 2, &#39;2 Full Baths&#39;: 2, &#39;Great Closet Space&#39;: 2, &#39;24 Hour Doorman&#39;: 2, &#39;Recessed Lighting.&#39;: 2, &#39;Business center&#39;: 2, &#39;kitchen island&#39;: 2, &#39;24/7 Full-Time Doorman Concierge&#39;: 2, &#39;One small dog ok on approval&#39;: 2, &#39;Grand Central&#39;: 2, &#39;SPACE&#39;: 2, &#39;Built in microwave&#39;: 2, &#39;walk-in closet&#39;: 2, &#39;Manhattan Views&#39;: 2, &#39;valet parking&#39;: 2, &#39;Heat Included&#39;: 2, &#39;Huge&#39;: 2, &#39;Wifi in Resident Lounge&#39;: 2, &#39;Extra Storage&#39;: 2, &#39;Intercom&#39;: 2, &#39;in unit washer and dryer&#39;: 2, &#39;BUILT-IN SPEAKER SYSTEM&#39;: 2, &#39;misting shower and resident lounge available.&#39;: 2, &#39;floor to ceiling windows&#39;: 2, &#39;On site super&#39;: 2, &#39;River view&#39;: 2, &#39;Foyer&#39;: 2, &#39;Rent Stabilized&#39;: 2, &#39;closet space&#39;: 2, &#39;Mint&#39;: 2, &#39;Window Kitchen&#39;: 2, &#39;Eat in Kitchen&#39;: 2, &#39;Flex-1&#39;: 2, &#39;newly renovated&#39;: 2, &#39;Tenant Storage&#39;: 2, &#39;SS appliances&#39;: 2, &#39;Triplex&#39;: 2, &#39;Unassigned Paid parking available&#39;: 2, &#34;Chef&#39;s kitchen&#34;: 2, &#39;Yoga and Spin Studios&#39;: 2, &#39;Closets&#39;: 2, &#39;A Full Service luxury Highrise&#39;: 2, &#39;King Size Bedrooms&#39;: 2, &#39;Available 05/01/16&#39;: 2, &#39;Twenty-four hour concierge and doorman&#39;: 2, &#39;Water Views&#39;: 2, &#39;Close to Transit&#39;: 2, &#39;Storage space&#39;: 2, &#39;Laundry room on every floor. Health club&#39;: 2, &#39;Extra Room&#39;: 2, &#39;LIGHT&#39;: 2, &#39;Stainless Steel Kitchen&#39;: 2, &#39;Health club with pool on the top floor&#39;: 2, &#39;Pets allowed&#39;: 2, &#39;Stainless steel appliances&#39;: 2, &#39;Electronic Rent Payment&#39;: 2, &#39;Skyline view&#39;: 2, &#39;Complimentary Continental Breakfast&#39;: 2, &#39;Stainless Steel appliances&#39;: 2, &#39;Sunny&#39;: 2, &#39;sundeck with BBQ grills&#39;: 2, &#39;Southern exposure&#39;: 2, &#39;King Size Bedroom&#39;: 2, &#39;Free Gym&#39;: 2, &#39;In unit washer and dryer&#39;: 2, &#39;Balconies in both bedrooms&#39;: 2, &#39;On-site Resident Manager&#39;: 2, &#39;Poker Table&#39;: 2, &#39;MW&#39;: 2, &#39;Sunny Southern Exposure&#39;: 2, &#39;Storage room&#39;: 2, &#39;ALL UTILITIES INCLUDED&#39;: 2, &#39;State-of-the-Art Cardio and Fitness Club&#39;: 2, &#39;Gramercy Park&#39;: 2, &#39;Extra Closet Space&#39;: 2, &#39;Garage.&#39;: 2, &#39;Marble bath&#39;: 2, &#39;1 Month Free&#39;: 2, &#39;Live-in super&#39;: 2, &#39;HEAT/HOT WATER INCLUDED&#39;: 2, &#39;share ok&#39;: 2, &#39;Central Heat&#39;: 2, &#39;Extra room&#39;: 2, &#39;King Sized Bedroom&#39;: 2, &#39;Garage attached&#39;: 2, &#39;Open Layout&#39;: 2, &#39;huge room&#39;: 2, &#39;Super On-Site&#39;: 2, &#39;On-Site Super&#39;: 2, &#39;Stainless Steal Appliances&#39;: 2, &#39;near transportation&#39;: 2, &#39;Fitness center&#39;: 2, &#39;Full service Luxury Highrise&#39;: 2, &#39;Pre-war Charm&#39;: 2, &#39;one month free rent&#39;: 2, &#39;Call Timur for instant Access 646 847 8588&#39;: 1, &#39;** EXTREME E50s EXCELLENCE * ALL MODERN &amp; NEW * MASSIVE 1BR HOME * GOURMET KITCHEN * LNDRY BLDG * REAL PIX **&#39;: 1, &#39;RENT-STABILIZED - ** RARE **&#39;: 1, &#39;The friendliest doormen in all of Manhattan&#39;: 1, &#39;open concept kitchen&#39;: 1, &#39;** MULTI-LEVEL MANSION * HUGE 4BR DUPLEX * MR CLEAN APPROVED * OVERSIZED WINDOWS GALORE * 2 BLKS TO BEDFORD L STOP **&#39;: 1, &#39;Outdoor space&#39;: 1, &#39;Huge Walk In Closet&#39;: 1, &#39;small pets allowed&#39;: 1, &#39;$1000. Move-in Visa Giftcard will be handed to new tenants upon rental lease signing&#39;: 1, &#39;Parking Garage&#39;: 1, &#39;Outdoor areas&#39;: 1, &#39;** NO FEE MULTI-LEVEL MANSION! * MASSIVE 3BR TRIPLEX * HUGE PRIVATE TERRACE * E50s &amp; PARK AVE * ELEV/LNDRY BLDG **&#39;: 1, &#39;24 hour doorman&#39;: 1, &#34;** EXTRA SWEET EAST VILLAGE! * MASSIVE 2BR HOME * ORNATE PREWAR DETAILS * EXPOSED BRICK * COOK&#39;S KITCHEN * PETS OK **&#34;: 1, &#39;65th/2nd Ave&#39;: 1, &#39;Vacation home&#39;: 1, &#39;NO FEE!!&#39;: 1, &#39;exclusive residential lounge &amp; Caf  Spacious and breathtaking fully landscaped 10&#39;: 1, &#39;Jr.1 Bed&#39;: 1, &#39;Eat in kitchen&#39;: 1, &#39;Spacious Layout&#39;: 1, &#39;Large&#39;: 1, &#39;** MASTERFUL 3BR MANSION * THE PERFECT SHARE * BACKYARD * EAT-IN KITCHEN * 1 BLK TO BEDFORD L **&#39;: 1, &#39;heat and hot water included&#39;: 1, &#39;Washer/Dryer in-Unit&#39;: 1, &#39;Near PRATT&#39;: 1, &#39;** PRISTINE MODERN TOWNHOUSE! * MASSIVE 2BR HOME * CHEF INSPIRED KITCHEN * HUGE WINDOWS GALORE * CATS OK **&#39;: 1, &#39;All Utilities Included&#39;: 1, &#39;Separate kitchen&#39;: 1, &#39;FURNISHED price. Central Air Conditioning. High Ceilings. Stainless Steel Appliances. Fully Equipped Stainless Steel Appliances Kitchen.&#39;: 1, &#39;state of the art fitness center&#39;: 1, &#39;Offering  1 month free OR 1 month OP&#39;: 1, &#39;washer and dryer in the unit&#39;: 1, &#39;Top Floor Unit&#39;: 1, &#39;** COURT SQUARE GEM! * LIC LUXURY 2BR HOME * SS KITCHEN ~ DISHWASHER * BAY WINDOWS * FIREPLACE * ALL NEW! **&#39;: 1, &#39;** OVERSIZED 3BR HOME * SPARKLING CLEAN * TONS OF NATURAL LIGHT * 2 BLKS TO THE WATERFRONT &amp; BEDFORD L STOP **&#39;: 1, &#39;two tennis courts&#39;: 1, &#39;original molding details&#39;: 1, &#39;NO FEE!&#39;: 1, &#39;specific dog breeds up to 40lbs&#39;: 1, &#39;** CLASSY CLINTON HOME * MASSIVE 1BR * GOURMET KITCHEN * EXPOSED BRICK * ROOMY CLOSETS **&#39;: 1, &#39;and breathtaking views of New York City from our rooftop terrace&#39;: 1, &#39;** ENTIRE FLOOR! * SPRAWLING 2BR HOME * IMMACULATE RENOVATIONS * FIREPLACE * 2 BLKS TO BEDFORD L STOP **&#39;: 1, &#39;Huge Rooms&#39;: 1, &#34;Children&#39;s room&#34;: 1, &#39;club room w billiards tables&#39;: 1, &#39;Large Living Area&#39;: 1, &#39;** ELEGANT E50s!! * SPRAWLING SUNDRENCHED 2BR HOME * FRENCH DRS * BREAKFAST BAR * DISHWASHER * EAT-IN KITCHEN * WALK-IN CLOSETS! **&#39;: 1, &#34;** SPRAWLING 3BR SUPER SHARE * WALLS OF WINDOWS * CHEF&#39;S KITCHEN w/DISHWASHER * WASHER/DRYER * STEPS TO THE PARK &amp; COLUMBIA * REAL PIX **&#34;: 1, &#39;HUGE Living Room&#39;: 1, &#39;Postwar&#39;: 1, &#39;featuring a sophisticated Precor online profile system that tracks your personal fitness goals&#39;: 1, &#39;** THE PERFECT SHARE! * HUGE TRUE 3BR HOME * GOURMET KITCHEN * TONS OF NATURAL LIGHT * 2 BLKS TO WATERFRONT &amp; BEDFORD L STOP **&#39;: 1, &#39;built-in wine cooler&#39;: 1, &#39;MICROWAVE&#39;: 1, &#39;NO FEE Specialist! Harry Ego 718.413.8270 hego@citihabitats.com&#39;: 1, &#39;premier resident services offered by our friendly and helpful staff&#39;: 1, &#39;Spacious Living Room&#39;: 1, &#39;Concierge Services&#39;: 1, &#39;Custom painted murals&#39;: 1, &#39;Great View&#39;: 1, &#39;Gas Stove&#39;: 1, &#39;Rooftop deck&#39;: 1, &#39;great river views&#39;: 1, &#39;Alcove&#39;: 1, &#39;water feature&#39;: 1, &#39;Pre-War brand new renovations&#39;: 1, &#39;attached garage&#39;: 1, &#39;** EAST VILLAGE BABY! * OVERSIZED 2BR HOME * 1.5 BATHS * EAT-IN KITCHEN * FIREPLACE * EXPOSED BRICK * SCENIC ROOF DECK * LNDRY BLDG **&#39;: 1, &#39;Lots of Light&#39;: 1, &#39;Time Warner&#39;: 1, &#39;3 AC&#39;: 1, &#39;LARGE Living Room&#39;: 1, &#39;000 SF Fitness Center&#39;: 1, &#39;Telephonic intercom system/multiple phone lines per residence&#39;: 1, &#39;Granite counter tops&#39;: 1, &#39;** SUPER SWEET NO FEE! * XL 3BR MANSION * ALL BRAND NEW * EAT-IN KITCHEN * 2 BLKS TO TRAIN **&#39;: 1, &#39;Landlord is offering month of April Free&#39;: 1, &#34;Resident&#39;s Courtyard&#34;: 1, &#39;direct bus line to ferry&#39;: 1, &#39;at an additional cost.&#39;: 1, &#34;1 mo broker&#39;s fee 18 mo lease&#34;: 1, &#39;BIG OPEN SPACES&#39;: 1, &#39;Attended garage&#39;: 1, &#39;Partially Furnished with two (2) air conditioners and microwave unit.&#39;: 1, &#39;storage unit&#39;: 1, &#39;Decorative Wooden Fireplace&#39;: 1, &#39;and stainless steel appliances with a dishwasher well maintained hardwood floors add to the warmth and modern feel of the space.&#39;: 1, &#39;Sorry no pets&#39;: 1, &#39;30&#39;: 1, &#39;Double Panned Sound-Proof windows /Renovated open kitchen marble and stainless steel countertops&#39;: 1, &#34;No Broker&#39;s Fees&#34;: 1, &#39;3&#39;: 1, &#39;surveillance cameras. and much more!&#39;: 1, &#39;Comprehensive valet services including maid service&#39;: 1, &#39;live-in super&#39;: 1, &#39;Gatehouse security&#39;: 1, &#39;Transport right outside&#39;: 1, &#34;** UPTOWN&#39;S FINEST! * MASSIVE 1BR HOME * ORNATE PREWAR DETAILS * GOURMET CHEF&#39;S KITCHEN * PETS OK **&#34;: 1, &#39;brand new stainless steel appliances&#39;: 1, &#39;in-unit washer-dryer&#39;: 1, &#39;Madison Square Park&#39;: 1, &#39;** W70s WINNER! * OVERSIZED 3BR DUPLEX MANSION * 2 FULL BATHS * PRIVATE ROOF DECK * DISHWASHER * STEPS TO THE PARK **&#39;: 1, &#39;Condo Grade Finishes&#39;: 1, &#39;** ELEGANT E50s &amp; PARK BABY! * MASSIVE 4BR MANSION * NO BROKER FEE * DISHWASHER * WALLS OF WINDOWS * ELEV BLDG **&#39;: 1, &#39;Guest Suite For Residents Only&#39;: 1, &#39;24/7 DOORMAN&#39;: 1, &#39;Kitchen Pantry&#39;: 1, &#39;Kids playroom&#39;: 1, &#39;Garage Parking!&#39;: 1, &#39;Electronic Rent Payment (Ach)&#39;: 1, &#39;Rent is net effective-Gross price is $3250&#39;: 1, &#34;** HUGE TRUE 3BR SUPER SHARE * STUNNING RENOVATIONS * WALLS OF WINDOWS * COOK&#39;S KITCHEN * GORGEOUS GREENWICH VILLAGE **&#34;: 1, &#39;Arguably the most well-Maintained Luxury Highrise in the City&#39;: 1, &#39;Elevator &amp; Laundry&#39;: 1, &#39;** WICKED W50s FIND! * SPRAWLING STUDIO HOME * GOURMET KITCHEN * UNIQUE RENOVATIONS * STEPS TO CENTRAL PARK! **&#39;: 1, &#39;open views&#39;: 1, &#39;Recently renovated&#39;: 1, &#39;Great Area&#39;: 1, &#39;Dogs OK&#39;: 1, &#39;Available  07/01/16&#39;: 1, &#39;co-op&#39;: 1, &#39;AC Central&#39;: 1, &#39;reduced fee while it lasts!&#39;: 1, &#39;Queen Bedrooms&#39;: 1, &#39;Tenant pays for only electric!&#39;: 1, &#39;Window treatments&#39;: 1, &#39;24-hour concierge and doorman&#39;: 1, &#39;Laundry in Building!&#39;: 1, &#39;dry-cleaning service&#39;: 1, &#39;NO alternate side parking rules in neighborhood&#39;: 1, &#39;Housekeeeping&#39;: 1, &#39;** GREENPOINT GIANT * HUGE TRUE 2BR MEGA-SHARE * SPARKLING CLEAN &amp; BRITE * STEPS TO THE PARK &amp; BEDFORD L STOP **&#39;: 1, &#39;Large private terrace&#39;: 1, &#39;Half floor through&#39;: 1, &#39;Stainless Steet Appliances&#39;: 1, &#39;Flat screen TV and sound system&#39;: 1, &#39;Bicycle and tenant st...orage available for rent&#39;: 1, &#39;Outdoor play area&#39;: 1, &#39;Sun deck&#39;: 1, &#39;amazing detail&#39;: 1, &#39;BBQs!&#39;: 1, &#39;Green building&#39;: 1, &#39;Gas&amp;Electric included&#39;: 1, &#39;Pets Allowed Case by Case&#39;: 1, &#39;Semi-private Backyard&#39;: 1, &#39;must see&#39;: 1, &#39;ACT FAST WONT LAST&#39;: 1, &#39;free gym&#39;: 1, &#39;laundry hookup&#39;: 1, &#39;24hr white-gloved doorman&#39;: 1, &#39;2 bathrooms&#39;: 1, &#39;over sized apartment&#39;: 1, &#39;Island Kitchen&#39;: 1, &#39;Stone countertops&#39;: 1, &#39;Private Patio!&#39;: 1, &#39;** HUGE TRUE 3BR HOME * MR CLEAN APPROVED * MASSIVE WINDOWS GALORE * STEPS TO THE PARK &amp; BEDFORD L STOP **&#39;: 1, &#39;4th off Charles&#39;: 1, &#39;**Laundry room code is 3401&#39;: 1, &#39;granite kitchen&#39;: 1, &#39;1 BR or Conv 2&#39;: 1, &#39;&amp; ATM machine on-site&#39;: 1, &#39;A true top luxury Hi-Rise&#39;: 1, &#39;Parking spot with additional fee&#39;: 1, &#39;Private Roof-Deck&#39;: 1, &#39;hardwood  floors&#39;: 1, &#34;** UPTOWN&#39;S BEST KEPT SECRET * SPRAWLING 2BR HOME * COURTYARD * CHEF INSPIRED KITCHEN * LNDRY BLDG **&#34;: 1, &#39;Citi Bike Station&#39;: 1, &#39;close to NYC&#39;: 1, &#39;Decorative fireplace&#39;: 1, &#39;Security ******Available June 1st***&#39;: 1, &#39;over sized windows&#39;: 1, &#39;IN-UNIT WASHER &amp; DRYER&#39;: 1, &#39;Sun decks&#39;: 1, &#39;wash/dryer&#39;: 1, &#39;super bright&#39;: 1, &#39;furnished&#39;: 1, &#39;two full bathrooms&#39;: 1, &#39;East Village&#39;: 1, &#39;king size bedrooms&#39;: 1, &#39;PRIVATE ENTRANCE&#39;: 1, &#39;78th &amp; LEXINGTON Ave&#39;: 1, &#34;** BRING UR BBQ! * SPRAWLING 2BR HOME * HUGE REAR TERRACE * MODERN EVERYTHING * CHEF&#39;S KITCHEN * ALL NEW **&#34;: 1, &#39;GREAT SHARE&#39;: 1, &#39;Large patio&#39;: 1, &#39;two month free rent&#39;: 1, &#39;well-maintained&#39;: 1, &#39;** SUPER SEXY 2BR * SPACIOUS SUNSPANKED LAYOUT * ALL MODERN &amp; NEW * 2 BLKS TO BEDFORD L STOP **&#39;: 1, &#39;on site dog park and pet spa&#39;: 1, &#39;HIGHHHHHH CEILINGS&#39;: 1, &#39;heat and water included in rent&#39;: 1, &#39;Garage parking&#39;: 1, &#39;Heat/Hot Water/Gas Included&#39;: 1, &#39;Air Condition&#39;: 1, &#39;Luxury Building&#39;: 1, &#39;** OVERSIZED 3BR SUPER SHARE * EQUAL SIZED BRS! * WALL OF WINDOWS * WASHER/DRYER * STEPS TO BEDFORD L STOP **&#39;: 1, &#39;** GIGANTIC GREENPOINT 2BR HOME * ROOM TO ENTERTAIN * EXTRA STORAGE * DINING ROOM * ALL BRAND NEW! **&#39;: 1, &#39;High floor&#39;: 1, &#39;Total Reno. Heart of West Village&#39;: 1, &#39;Housekeeping&#39;: 1, &#39;air conditioned laundry facility&#39;: 1, &#39;granite bathroom&#39;: 1, &#39;NMW&#39;: 1, &#39;Video intercom&#39;: 1, &#39;bay windows&#39;: 1, &#39;modern kitchen&#39;: 1, &#39;2 Months Free&#39;: 1, &#39;Executive conference room with large-screen HDTV&#39;: 1, &#39;Onsite dry cleaner&#39;: 1, &#39;Lighting upgrades&#39;: 1, &#39;Lease Term (Flexible) 3 Months - 1 Year / Furnished or Unfurnished&#39;: 1, &#39;Hot Water Inc. HUGE Walk-In Closet or Extra Room!&#39;: 1, &#39;real sand beach volleyball courts&#39;: 1, &#39;2 beautifully furnished outside sundecks&#39;: 1, &#39;Soaking Neptune bathtub&#39;: 1, &#39;Large Livingroom&#39;: 1, &#39;DW  DUPLEX   PENTHOUSE&#39;: 1, &#39;Pre-War Details&#39;: 1, &#39;3-12 MONTH LEASES ALLOWED&#39;: 1, &#39;** SPRAWLING SUNFILLED 3BR HOME * NO FEE * EAT-IN KITCHEN * WALLS OF WINDOWS * MODERN RENOVATIONS * 2 BLKS TO TRAIN **&#39;: 1, &#39;Laundry on floor&#39;: 1, &#39;** W60s WONDER ~ NEAR THE PARK! * OVERSZED STUDIO STEAL * COURTYARD * FREE GYM * ELEV/LNDRY BLDG * CATS OK **&#39;: 1, &#39;Oversized Shower Tub&#39;: 1, &#39;Living/dining room&#39;: 1, &#39;laundry in basement&#39;: 1, &#39;** OVERSIZED &amp; UNDERPRICED * CLASSY CORNER STUDIO * ALL MODERN &amp; NEW * PERFECT SUNLIGHT * PETS OK **&#39;: 1, &#39;FREE HEALTH CLUB&#39;: 1, &#39;Private Patio&#39;: 1, &#39;duplex&#39;: 1, &#39;Steps to Prospect Park&#39;: 1, &#39;Guarantors okay&#39;: 1, &#39;30th &amp; 3rd ave&#39;: 1, &#39;FIRE PLACE&#39;: 1, &#39;Rent stabilized&#39;: 1, &#39;spacious&#39;: 1, &#39;Brand New SS Kitchen&#39;: 1, &#39;Arched Doorways&#39;: 1, &#39;9th floor manhattan views&#39;: 1, &#39;mid-rise&#39;: 1, &#39;Satellite TV&#39;: 1, &#39;built in storage&#39;: 1, &#39;LIMITED TIME - NO FEE&#39;: 1, &#39;** SPRAWLING TRUE 2BR SUPER SHARE * EXPOSED BRICK * SCENIC ROOF DECK * PETS OK **&#39;: 1, &#39;** MODERN MARVEL! * HEART OF THE VILLAGE * OVERSIZED 2BR HOME * EXPOSED BRICK * LNDRY BLDG **&#39;: 1, &#39;** MASTERFUL BKLYN FIND! * SPRAWLING 3BR MEGA-SHARE * GOURMET KITCHEN * MR CLEAN APPROVED * 2 BLKS TO BEDFORD L **&#39;: 1, &#39;state-of-the-art fitness center and even an on-site dog run&#39;: 1, &#39;In Unit Washer &amp; Dryer&#39;: 1, &#39;New Electric&#39;: 1, &#39;pet friendly&#39;: 1, &#39;High Ceil&#39;: 1, &#39;** SPACIOUS STUDIO SUPREME * AMAZING CORNER LAYOUT * TONS OF SUNLIGHT * PETS OK **&#39;: 1, &#39;2&#39;: 1, &#39;Community recreation facilities&#39;: 1, &#39;Outdoor grilling terrace&#39;: 1, &#39;june 1st occupancy&#39;: 1, &#39;walking distances to restaurants&#39;: 1, &#39;Dishwasher/Microwave&#39;: 1, &#39;** MIDTOWN MIRACLE * SPRAWLING 2BR SUPER SHARE * SS EAT-IN KITCHEN * FRENCH DOORS * ORNATE PREWAR DETAILS **&#39;: 1, &#39;Nearby Medical Centers&#39;: 1, &#39; On-site lifestyle concierge by Luxury Attach 24/7 Doorman  State of the art cardiovascular and weight training equipment  24-hour valet parking garage  Valet services including dry cleaning&#39;: 1, &#39;** SPRAWLING STUDIO HOME * DISHWASHER * EXPOSED BRICK * GUT RENOVATED * PETS OK * STEPS TO THE PARK **&#39;: 1, &#39;Mullion Pane Windows&#39;: 1, &#39;New reno&#39;: 1, &#39;Restaurant&#39;: 1, &#39;Common balcony&#39;: 1, &#39;Washer / Dryer&#39;: 1, &#39;24th St &amp; 3rd Ave&#39;: 1, &#39;Refrigerated storage in lobby for grocery deliveries&#39;: 1, &#39;Expansive Living-room&#39;: 1, &#39;Standard on-site parking&#39;: 1, &#34;residents&#39; lounge&#34;: 1, &#39;** HOLY NO FEE DEAL BATMAN! * OVERSIZED 2BR HOME * SPARKLING CLEAN &amp; BRITE * HEART OF GREENPOINT * NEAR THE PARK &amp; TRAINS **&#39;: 1, &#39;near NQRMG Trains&#39;: 1, &#39;Just Listed&#39;: 1, &#39;SUNDECK&#39;: 1, &#39;Mins From Train&#39;: 1, &#39;000-square foot sun deck Free WiFi in Marc Club&#39;: 1, &#39;1.5 Baths&#39;: 1, &#39;** CHIC CHELSEA FIND! * MASSIVE 4BR HOME * 2 FULL BATHS * CHEF INSPIRED KITCHEN * ELEV THAT OPENS INTO APT * CATS OK **&#39;: 1, &#39;Pets: Cats Only&#39;: 1, &#39;Landlord paying for all utilities! Tenant pays for cable / tv / internet.&#39;: 1, &#39;laundry &amp; housekeeping  Marc Club includes a cinema room&#39;: 1, &#39;The Most Sought after Location&#39;: 1, &#39;Fireplace Storage&#39;: 1, &#39;package room&#39;: 1, &#39;Free Storage&#39;: 1, &#39;Gut Renovated.&#39;: 1, &#39;Spin Room&#39;: 1, &#39;Wood burning fireplace&#39;: 1, &#39;Open Kitchen&#39;: 1, &#39;One Month Fee&#39;: 1, &#39;1.5 baths&#39;: 1, &#39;NO FEE!!!&#39;: 1, &#39;6 bedrooms&#39;: 1, &#39;** MIDTOWN NO FEE MANSION! * SPRAWLING 2BR SUPER SHARE * CHEF INSPIRED KITCHEN * ELEV/LNDRY BLDG **&#39;: 1, &#39;huge balcony&#39;: 1, &#39;Private Storage&#39;: 1, &#39;dishwaser&#39;: 1, &#39;EASY TO SHOW!&#39;: 1, &#39;LINOLEUM&#39;: 1, &#39;Private Balcony&#39;: 1, &#39;** HEART OF THE VILLAGE! * MASSIVE 3BR SUPER SHARE * MR CLEAN APPROVED * ORNATE PREWAR DETAILS * GOURMET KITCHEN * TONS OF SUNLIGHT **&#39;: 1, &#39;** ENTIRE FLOOR! * ENORMOUS 4BR MEGA-SHARE * MAGIC ERASER CLEAN * UNIQUE RENOVATIONS * PETS OK **&#39;: 1, &#39;Sunny Southern &amp; Western Exposure&#39;: 1, &#39;HUGE Closets&#39;: 1, &#39;Separate Entryway&#39;: 1, &#39;basketball court&#39;: 1, &#39;one flight walk up&#39;: 1, &#39;500 Sq Ft&#39;: 1, &#39;PRIVATE GARAGE AVAILABLE&#39;: 1, &#39;SS Appliances w/ Dishwasher&#39;: 1, &#39;spacious rooms&#39;: 1, &#34;two en-suite balcony&#39;s.&#34;: 1, &#39;dry cleaning service&#39;: 1, &#39;Common courtyard&#39;: 1, &#39;No Broker Fee&#39;: 1, &#39;** SPRAWLING SUNFILLED 1BR HOME * UNIQUE PREWAR DETAILS * GOURMET KITCHEN * HEART OF MIDTOWN! **&#39;: 1, &#39;LOW FEE&#39;: 1, &#39;** SPRAWLING TRUE 2BR HOME * COURTYARD! * EAT-IN KITCHEN * GUT RENOVATED * 2 BLKS TO BEDFORD L **&#39;: 1, &#39;$250 application fee with background and credit check. Board interview and approval.&#39;: 1, &#39;Walk-in-closet&#39;: 1, &#39;CitiBikes Nearby&#39;: 1, &#34;** MIDTOWN EAST ELEGANCE! * MASSIVE 1BR HOME * WALLS OF WINDOWS * GOURMET KITCHEN * BRAND SPANKIN&#39; NEW! **&#34;: 1, &#39;great location!&#39;: 1, &#39;36th St &amp; 3rd Ave&#39;: 1, &#39;** SPRAWLING 2BR SUPER SHARE * SPARKLING CLEAN &amp; BRITE * SS EAT-IN KITCHEN * ROOMY CLOSETS * 4 BLKS TO BEDFORD L **&#39;: 1, &#39;** W50s WONDER! * MASSIVE 1BR HOME * MR CLEAN APPROVED * GOURMET KITCHEN * ROOMY CLOSETS * NEAR CENTRAL PARK! **&#39;: 1, &#39;** WICKED W50s WINNER! * MASSIVE 2BR SUPER SHARE * WINDOWS AL AROUND * CHEF INSPIRED KITCHEN * ELEV BLDG * PETS OK * STEPS TO CENTRAL PARK! **&#39;: 1, &#39;Laundry facility on every floor&#39;: 1, &#39;low-rise&#39;: 1, &#39;Large &amp; Medium Storage&#39;: 1, &#39;central air&#39;: 1, &#39;laundry in bldg.&#39;: 1, &#39;Pets: Case by case&#39;: 1, &#39;1 month free&#39;: 1, &#39;REAL WALL ALLOWED&#39;: 1, &#39;electronic keycard&#39;: 1, &#39;** CLASSY CORNER STUDIO * OVERSIZED &amp; UNDERPRICED * WINDOWS ALL AROUND * PETS OK **&#39;: 1, &#39;natural sunlight&#39;: 1, &#39;Digital TV&#39;: 1, &#39;private roof deck&#39;: 1, &#39;European air condition in each room&#39;: 1, &#39;Built In AC&#39;: 1, &#39;Harwood Floors&#39;: 1, &#39;55th &amp; 6th ave&#39;: 1, &#39;Wardrobe Style Closets&#39;: 1, &#39;A Full service Luxury highrise&#39;: 1, &#39;Spa center&#39;: 1, &#39;Mosaic tiled kitchen&#39;: 1, &#39;newly renovated large bright&#39;: 1, &#39;Spacious private garden&#39;: 1, &#39;Redwood Hardwood Floor&#39;: 1, &#39;Oversized&#39;: 1, &#39;Low Fee Listing&#39;: 1, &#39;All common areas feature Wi-Fi accessibility&#39;: 1, &#39;** EYE POPPING NO FEE! * MASSIVE 1BR HOME * EXPOSED BRICK * PRIVATE TERRACE * DISHWASHER * ELEV BLDG * ROOF DECK * PETS OK **&#39;: 1, &#39;AC&#39;: 1, &#39;Floor-to-ceiling windows&#39;: 1, &#39;shuttle service&#39;: 1, &#39;Large apartment&#39;: 1, &#39;GUT RENOVATED&#39;: 1, &#39;on-site management&#39;: 1, &#39;high floor unit&#39;: 1, &#39;COME LIVE THE GOOD LIFE FOR  LESS $$$$&#39;: 1, &#39;Historical Brownstone originally built in 1901!&#39;: 1, &#39;Bridge View&#39;: 1, &#39;Low fee and great space too!&#39;: 1, &#39;heated lap pool&#39;: 1, &#39;** SUNDRENCHED &amp; SPACIOUS * MASSIVE 3BR HOME * ALL MODERN &amp; NEW * STEPS TO L TRAIN **&#39;: 1, &#39;Recreational Room&#39;: 1, &#39;childrens playroom&#39;: 1, &#39;Tenant pays for electric!&#39;: 1, &#39;** SUPER SWEET 1BR HOME * ELEGANT E60s! * MR CLEAN APPROVED * CHEF INSPIRED KITCHEN * TONS OF NATURAL LIGHT! * CATS OK **&#39;: 1, &#39;Great Views&#39;: 1, &#39;Washer Dryer in Unit&#39;: 1, &#39;Closed circuit television security system&#39;: 1, &#39;Diswasher&#39;: 1, &#39;Previous tenant found easy on-street parking.&#39;: 1, &#39;tenants lounge with free Wi-Fi&#39;: 1, &#39;Walls of Windows&#39;: 1, &#39;A full service Luxury residence&#39;: 1, &#39;skylight&#39;: 1, &#39;Solarium&#39;: 1, &#39;3br&#39;: 1, &#39;Brand new washer &amp; dryer&#39;: 1, &#39;Well mainatained Swimming pool&#39;: 1, &#39;Roof&#39;: 1, &#39;outdoor space&#39;: 1, &#39;golf simulator&#39;: 1, &#39;game room&#39;: 1, &#39;cinema room&#39;: 1, &#39;furnished wrap around terrace&#39;: 1, &#39;Walk-in closet&#39;: 1, &#39;** OVERSIZED 1BR HOME * GUT RENOVATED * PERFECT NATURAL LIGHT * HEART OF CHELSEA * PETS OK **&#39;: 1, &#39;MASSIVE HOME&#39;: 1, &#39;ON-SITE GARAGE&#39;: 1, &#39;** SASSY SOHO STEAL! * NO FEE! * SPRAWLING STUDIO HOME * GOURMET KITCHEN * HUGE CLOSETS * ELEV BLDG **&#39;: 1, &#39;Garage Fitness Facility Laundry Room Valet Lounge Billiards Room Rooftop Deck WiFi Access&#39;: 1, &#39;22&#39;: 1, &#39;Walk In Closet&#39;: 1, &#39;Childrens Room&#39;: 1, &#39;utilities included&#39;: 1, &#39;New Stainless Appliances&#39;: 1, &#34;** ALL BRAND NEW NO FEE! * EXPANSIVE 2BR McMANSION * PRIVATE TERRACE * COOK&#39;S SS KITCHEN * ELEV/LNDRY BLDG * 3 BLKS TO L TRAIN **&#34;: 1, &#39;on-site parking garage&#39;: 1, &#39;Half Bath&#39;: 1, &#39;Ceiling Fan&#39;: 1, &#39;Bright spacious 2 BR/1BA&#39;: 1, &#39;1st&#39;: 1, &#39;NO FEE HARDWOOD FLOORS&#39;: 1, &#39;Open Granite Kitchen&#39;: 1, &#39;A/C Units&#39;: 1, &#34;Commuter&#39;s paradise&#34;: 1, &#39;designer finishes&#39;: 1, &#39;NYU&#39;: 1, &#39;** NO FEE BABY! * MASSIVE 2BR w/TERRACE * GOURMET SS KITCHEN * ELEV/LNDRY BLDG * SCENIC ROOF DECK * 3 BLKS TO TRAIN **&#39;: 1, &#39;Central Park 1/2 block away!&#39;: 1, &#39;Elevator &amp; LAUNDRY&#39;: 1, &#39;Resident Events&#39;: 1, &#39;build-in Microwave-oven&#39;: 1, &#39;Control &amp; pay for your own heat with your own thermostat&#39;: 1, &#39;** ONE OF A KIND NO FEE! * MASSIVE 3BR MANSION * EAT-IN KITCHEN * TONS OF SUNLIGHT * 2 BLKS TO TRAIN **&#39;: 1, &#34;** CHIC CHELSEA STEAL! * SUPER SWEET STUDIO * GOURMET CHEF&#39;S KITCHEN * ALL MODERN &amp; NEW * TONS OF STORAGE * PETS OK **&#34;: 1, &#39;Basketball Court&#39;: 1, &#39;Roof Access&#39;: 1, &#39;landmark building&#39;: 1, &#39;Recent Renovation&#39;: 1, &#39;A One-of-a-Kind Full Service Luxury Highrise&#39;: 1, &#39;24hr doormen&#39;: 1, &#39;sun drenched&#39;: 1, &#39;Easy Qualification&#39;: 1, &#39;Laundry.&#39;: 1, &#39;Near Transportation&#39;: 1, &#39;no board approval&#39;: 1, &#39;on-site parking&#39;: 1, &#39;Beamed Ceilings&#39;: 1, &#39;ONE MONTH FREE&#39;: 1, &#39;Lexington 95th&#39;: 1, &#39;Loft Area&#39;: 1, &#39;** UNIQUE FIND! * SPRAWLING 2BR SUPER SHARE * WALLS OF WINDOWS * STUNNING RENOVATIONS * 2 BLKS TO BEDFORD L STOP **&#39;: 1, &#39;Huge Private Backyard&#39;: 1, &#39;Air Conditioning: Unknown Type&#39;: 1, &#39;Southern Facing&#39;: 1, &#39;No broker fee!&#39;: 1, &#39;** MASSIVE 1BR HOME * RENT STABILIZED * SEPARATE KITCHEN * WALLS OF WINDOWS * ROOMY CLOSETS **&#39;: 1, &#39;NO BROKER FEE! NO FEE&#39;: 1, &#39;Complimentary breakfast on weekdays&#39;: 1, &#39;Reduced fee while it lasts!&#39;: 1, &#39;Large room&#39;: 1, &#39;Available 06/01/16&#39;: 1, &#39;PETS WELCOME&#39;: 1, &#34;** REAL NO FEE LUXURY! * OVERSIZED 2BR HOME ~ FIT FOR QUEENS!! *  CHEF&#39;S KITCHEN * WALLS OF WINDOWS * 1 BLK TO TRAIN **&#34;: 1, &#39;Private Entrances&#39;: 1, &#39;ceiling-fan...&#39;: 1, &#39;Elevator building&#39;: 1, &#39;deco brick walls&#39;: 1, &#39;EAT-IN-KITCHEN&#39;: 1, &#39;* MARVELOUS MIDTOWN GEM * SPACIOUS SUNDRENCHED STUDIO * STUNNING PREWAR DETAILS * CATS OK **&#39;: 1, &#39;NEW Marble Bathroom&#39;: 1, &#39;small dogs ok&#39;: 1, &#39;Spotless Laundry&#39;: 1, &#39;Parquet Floors&#39;: 1, &#39;4 roof-decks with river views&#39;: 1, &#39;A full service Luxury highrise&#39;: 1, &#39;** EXTRAVAGANT EAST VILLAGE! * MASSIVE 4BR MANSION * 2 FULL BATHS * GOURMET KITCHEN * ROOMY CLOSETS **&#39;: 1, &#39;Recessed Lights&#39;: 1, &#39;\xa0Subway&#39;: 1, &#39;Onsite super and porter&#39;: 1, &#39;Near All Trains&#39;: 1, &#39;gut renovated&#39;: 1, &#39;King size bedroom&#39;: 1, &#39;high speed elevator&#39;: 1, &#39;Continental Breakfast Served 5 Days A Week&#39;: 1, &#39;** MASTERFUL BKLN MANSION! * SPRAWLING 3BR HOME * ORNATE PREWAR DETAILS * GOURMET KITCHEN * 1 BLK TO BEDFORD L **&#39;: 1, &#39;Heat &amp; Water Included&#39;: 1, &#39;ALL NEW&#39;: 1, &#39;** PRISTINE PREWAR GEM! * MASSIVE 3BR SUPER SHARE * GUT RENOVATED * CHEF;S KITCHEN * ELEV BLDG * PETS OK **&#39;: 1, &#39;79th/2nd&#39;: 1, &#39;Pets Upon Approval&#39;: 1, &#39;** OVERSIZED &amp; UNDERPRICED!! * SPRAWLING SUNFILLED STUDIO * GOURMET KITCHEN * GUT RENOVATED * W50s ~ NEAR CENTRAL PARK! **&#39;: 1, &#39;** SUPER SWEET STUDIO * NO FEE * DISHWASHER * ROOMY CLOSETS * ELEV BLDG * PETS OK **&#39;: 1, &#34;** BRAND SPANKIN&#39; NEW * OVERSIZED 3BR HOME * WASHER/DRYER * SS KITCHEN w/ISLAND * HEART OF DESIRABLE SOHO **&#34;: 1, &#39;** RARE FIND ~ UNIQUE CARRIAGE HOUSE * MASSIVE TRUE 2BR * PRIVATE GARDEN * WASHER/DRYER * 2 BLKS TO L TRAIN **&#39;: 1, &#39;No application fee!&#39;: 1, &#39;Four Barbecue Grills&#39;: 1, &#39;oversized closet&#39;: 1, &#39;** RIVERSIDE NO FEE SPECIAL! * SPRAWLING 1BR HOME * FIREPLACE * BAY WINDOWS * EXPOSED BRICK * DISHWASHER * LNDRY BLDG **&#39;: 1, &#39;abundant closets&#39;: 1, &#39;Indoor parking&#39;: 1, &#39;Party/Meeting Room&#39;: 1, &#39;2nd Ave&#39;: 1, &#39;** ELEGANT EAST VILLAGE! * MASSIVE 2BR SUPER SHARE * MODERN &amp; NEW * EXPOSED BRICK * LNDRY BLDG **&#39;: 1, &#39;Massive Living-room&#39;: 1, &#39;Catering Facility&#39;: 1, &#39;private deck&#39;: 1, &#39;1.5 bathrooms&#39;: 1, &#39;** HOLY NO FEE! * OVERSIZED 2BR HOME * PRIVATE TERRACE &amp; SCENIC ROOF DECK * SS KITCHEN * DISHWASHER * ELEV/LNDRY BLDG * 3 BLKS TO L TRAIN **&#39;: 1, &#39;Virtual DM&#39;: 1, &#39;Available  04/15/16&#39;: 1, &#39;Alcove Studio&#39;: 1, &#39;24hr Doorman&#39;: 1, &#39;Newly Renovated w/ Oak wood floors   Mid century modern style interior   Large Closets in Every Bedroom EXTRA storage space in hall. Large Living room&#39;: 1, &#39;Shares okay&#39;: 1, &#39;however there\&#39;s a standing &#34;no walls\&#39; building policy!&#39;: 1, &#39;Private Dining Room&#39;: 1, &#39;** DIAMOND NO FEE DEAL! * SPRAWLING SUNFILLED 2BR w/PRIVATE TERRACE * SS KITCHEN * ELEV/LNDRY BLDG * 3 BLKS TO L TRAIN **&#39;: 1, &#39;True 2 Bedroom - On Lexington Ave&#39;: 1, &#39;** DIAMOND NO FEE DEAL! * MASSIVE 1BR w/ HOME OFFICE * CONDO QUALITY FINISHES * EAT-IN KITCHEN * 1 BLK TO THE PARK **&#39;: 1, &#39;Bicycle room and individual resident storage&#39;: 1, &#39;** BROWNSTONE BEAUTY * MASSIVE 2BR HOME * STEPS TO THE PARK * SS KITCHEN * DISHWASHER * OVERSIZED CLOSETS * NEAR COLUMBIA U **&#39;: 1, &#39;** OVERSIZED 2BR SUPER SHARE * FRENCH DOORS * SS EAT-IN KITCHEN * MR CLEAN APPROVED * HEART OF MIDTOWN! **&#39;: 1, &#39;Library&#39;: 1, &#39;French Door&#39;: 1, &#39;Poo&#39;: 1, &#39;XXLARGE STUDIO&#39;: 1, &#39;prime location&#39;: 1, &#39;loft storage&#39;: 1, &#39;RENOVATED 1 Bed&#39;: 1, &#39;Convertible-2&#39;: 1, &#39;1/2 Month Fee&#39;: 1, &#39;1.5 Bath&#39;: 1, &#39;Close to Subway - Renovated!&#39;: 1, &#39;Yoga an Pilates class&#39;: 1, &#39;2 Bedroon Convertible&#39;: 1, &#39;Queen Size bedrooms&#39;: 1, &#39;Oversize Terrace&#39;: 1, &#39;Keyed Elevator with direct access into your living room&#39;: 1, &#39;Sun Drenched&#39;: 1, &#34;** RENT STABILIZED * OVERSIZED 1BR HOME * MR CLEAN APPROVED * SEPARATE COOK&#39;S KITCHEN * HEART OF MIDTOWN **&#34;: 1, &#39;Package Receiving&#39;: 1, &#39;$1500. Move-in Visa Giftcard will be handed to new tenants upon rental lease signing&#39;: 1, &#39;Washer/Dyer Combo&#39;: 1, &#39;1 MONTH FREE&#39;: 1, &#39;** RARE FIND! * HUGE TRUE 2BR * COURTYARD * FULLY RENOVATED * EAT-IN KITCHEN * 2 BLKS TO BEDFORD L **&#39;: 1, &#39;Steam Room&#39;: 1, &#39;Building Link Notification &amp; Key Track for tenants convenience&#39;: 1, &#39;attached parking&#39;: 1, &#39;** THE PERFECT SHARE! * MASSIVE 2BR HOME * GUT RENOVATED * LNDRY BLDG * PETS OK * HEART OF THE VILLAGE **&#39;: 1, &#39;WASHER/DRYER INSIDE THE UNIT&#39;: 1, &#34;Lot&#39;s of Light&#34;: 1, &#39;Kids Play Room&#39;: 1, &#39;Sleep Loft&#39;: 1, &#39;RIVER VIEWS&#39;: 1, &#39;windowed kitchen&#39;: 1, &#39;Large Closets&#39;: 1, &#39;private terrace&#39;: 1, &#39;2 Full Bathrooms&#39;: 1, &#39;South Facing&#39;: 1, &#39;walk up&#39;: 1, &#39;No Fee or One Month Free&#39;: 1, &#39;A One-of-a-Kind Full service Luxury Highrise&#39;: 1, &#39;King sized Bedroom&#39;: 1, &#39;Actual photos&#39;: 1, &#39;Hardwood Flooring Throughout&#39;: 1, &#34;** GREENPOINT GIANT * SPRAWLING 2BR HOME * CHEF&#39;S KITCHEN * PERFECT NATURAL LIGHT * STEPS TO THE PARK &amp; TRAIN! **&#34;: 1, &#39;postwar&#39;: 1, &#39;concierge services&#39;: 1, &#39;** REAL NO FEE BABY! * EXPANSIVE 3BR MASTERPIECE * SPACIOUS &amp; SUNFILLED * SPARKLING CLEAN * EAT-IN KITCHEN * 2 BLKS TO TRAIN **&#39;: 1, &#39;Exposed Brick Walls&#39;: 1, &#39;All New&#39;: 1, &#39;small dressing-area in front of bathroom&#39;: 1, &#39;Woodburning Fireplace&#39;: 1, &#39;** CHELSEA BABY! * MASSIVE 2BR SUPER SHARE * ALL MODERN &amp; NEW * ELEV /LNDRY BLDG **&#39;: 1, &#39;Approved animals only&#39;: 1, &#39;Window Bathroom&#39;: 1, &#39;Private lounge w/ wet bar &amp; billiards table&#39;: 1, &#39;eat in kitchen&#39;: 1, &#39;air conditioned&#39;: 1, &#39;Separate Kitchen&#39;: 1, &#39;STAINLESS STEEL&#39;: 1, &#39;Ached Doorways&#39;: 1, &#39;3 bath&#39;: 1, &#39;Accepts Credit Cards (Fee Applies)&#39;: 1, &#39;rooftop access&#39;: 1, &#39;Private Shuttle&#39;: 1, &#39;Granite Counter tops.&#39;: 1, &#39;** MIDTOWN MARVEL! * MASSIVE 1BR HOME * GOURMET KITCHEN * UNIQUE PREWAR DETAILS * ROOMY CLOSETS * ALL NEW **&#39;: 1, &#39;** STEPS TO CENTRAL PARK!! * EXPANSIVE STUDIO STEAL! * A/C * EXTRA STORAGE * STUNNING RENOVATIONS * ELEV/LNDRY BLDG **&#39;: 1, &#39;Roof deck with stunning view&#39;: 1, &#39;Pet friendly&#39;: 1, &#39;** HUGE TRUE 2BR SUPER SHARE * EXPOSED BRICK * GOURMET KITCHEN * LNDRY BLDG * HEART OF THE VILLAGE **&#39;: 1, &#39;Brand Spanking New&#39;: 1, &#39;virtual doorman&#39;: 1, &#39;Move-in coordination&#39;: 1, &#39;** HOLY DEAL BATMAN! * ENTIRE FLOOR! * MASSIVE 4BR MANSION * GOURMET KITCHEN * PETS OK **&#39;: 1, &#39;1200sq ft&#39;: 1, &#39;counter-top space&#39;: 1, &#39;One Month rent free concession on a 12 month lease&#39;: 1, &#39;Floor To Ceiling Windows&#39;: 1, &#39;Full Floor&#39;: 1, &#39;1100 sq ft&#39;: 1, &#39;Tall Ceilings&#39;: 1, &#39;Convertible 2&#39;: 1, &#39;$250 Security Deposit&#39;: 1, &#39;75th &amp; 1st&#39;: 1, &#39;Exposed Bricks&#39;: 1, &#39;Indoor swimming pool&#39;: 1, &#39;Valet services&#39;: 1, &#39;OPEN HOUSE SAT. MAY 14 12- 1PM&#39;: 1, &#39;Bright &amp; Sunny!&#39;: 1, &#39;Steps from Tompkins Sq Park&#39;: 1, &#39;Gut Renovations&#39;: 1, &#39;Huge Bedrooms&#39;: 1, &#39;24-hour concierge&#39;: 1, &#39;** SPRAWLING 3BR SUPER SHARE * CLEAN &amp; BRITE * NEAR WATERFRONT! * 2 BLKS TO BEDFORD L STOP **&#39;: 1, &#39;Combo Washer Dryer&#39;: 1, &#39;Outdoor Space (Private Roof Deck)&#39;: 1, &#39;$500 Security Deposit&#39;: 1, &#39;Cinema room&#39;: 1, &#39;ELEVATOR/LAUNDRY/ SO CLOSE TO THE 6 $2450!!&#39;: 1, &#39;INDOOR GARAGE AVAILABLE&#39;: 1, &#39;new stainless steel appliances&#39;: 1, &#39;W/D&#39;: 1, &#39;Large Private Deck&#39;: 1, &#39;Common Areas&#39;: 1, &#39;oak cabinets&#39;: 1, &#39;Rent includes cable tv and wireless internet&#39;: 1, &#39;GROUND FLOOR&#39;: 1, &#39;laundry room as well as housekeeping &amp; dry-cleaning services&#39;: 1, &#39;24 Hour Doorman Concierge&#39;: 1, &#39;Vaulted Ceilings&#39;: 1, &#39;Wonderful 2 bed in WV   Grab it or Grieve it..xoxo&#39;: 1, &#39;Third Floor walk up&#39;: 1, &#39;Duplex Layout&#39;: 1, &#39;Modern Finishes&#39;: 1, &#39;Concierge and Live-In Super.&#39;: 1, &#39;Flex two bed&#39;: 1, &#39;** MASSIVE 3BR SUPER SHARE * WASHER/DRYER * ORNATE PREWAR DETAILS * STEPS TO BEDFORD L STOP **&#39;: 1, &#39;2 Story Tenant Lounge&#39;: 1, &#39;NO FEE!!!Roof Deck&#39;: 1, &#39;Video Access Control&#39;: 1, &#39;FLEXIBLE VIEWING TIMES&#39;: 1, &#39;Available  05/15/16    Dishwasher&#39;: 1, &#39;Individual Climate Control&#39;: 1, &#39;** COURT SQUARE GEM! * SPRAWLING SUNDRENCHED 2BR HOME * CUSTOM FINISHES * DISHWASHER * FIREPLACES * EAT-IN KITCHEN * BAY WINDOWS **&#39;: 1, &#34;** MIDTOWN MIRACLE * SPRAWLING 1BR HOME * COOK&#39;S KITCHEN * WINDOWS ALL AROUND * ROOMY CLOSETS **&#34;: 1, &#39;washer dryer&#39;: 1, &#39;Views&#39;: 1, &#39;Light.&#39;: 1, &#39;ACT FAST WILL NOT LAST&#39;: 1, &#39;Local Gym Discount&#39;: 1, &#39;Rooftop Sundeck&#39;: 1, &#39;AMAZING DEAL!&#39;: 1, &#39;State-of-the-art swimming pool&#39;: 1, &#39;Outdoor terrace&#39;: 1, &#39;Private Backyard&#39;: 1, &#39;Great Natural Light&#39;: 1, &#39;attached parking garage&#39;: 1, &#39;** CENTRAL PARK STEAL! * MASSIVE STUDIO SUPREME * GUT RENOVATED * WALLS OF WINDOWS * ELEV/LNDRY BLDG **&#39;: 1, &#39;Oversized window&#39;: 1, &#39;Garage Parking&#39;: 1, &#39;Indoor 50ft lap pool; dishwasher; free bike storage&#39;: 1, &#39;Everything Brand New!&#39;: 1, &#39;Full-time Doorman&#39;: 1, &#39;Cats on approval&#39;: 1, &#34;** UPTOWN&#39;S BEST DEAL! * STEPS TO THE PARK! * MASSIVE 1BR HOME * MR CLEAN APPROVED * ROOMY CLOSETS **&#34;: 1, &#39;All Utilities included&#39;: 1, &#39;Private fenced yard&#39;: 1, &#39;Sitting Area&#39;: 1, &#39;High Floor&#39;: 1, &#39;competitively priced&#39;: 1, &#39;Double Hung Wooden Shutters&#39;: 1, &#39;Last&#39;: 1, &#39;attended garage and service entrance&#39;: 1, &#39;only $250 Deposit with Approved Credit&#39;: 1, &#39;Great Light and Location. Fresh paint.&#39;: 1, &#39;Large finished basement&#39;: 1, &#39;Wine Cooler&#39;: 1, &#39;Twenty-four-hour concierge and doorman&#39;: 1, &#39;Resident Super in the building&#39;: 1, &#39;Available  05/01/16      Swimming pool         Dishwasher&#39;: 1, &#39;Dog OKAY&#39;: 1, &#39;VERY COMFORTABLE LAYOUT&#39;: 1, &#39;PERFECT LOCATION!!!!&#39;: 1, &#39;Ceiling Fans&#39;: 1, &#39;Central Air Conditioning&#39;: 1, &#39;Cold Storage In Lobby&#39;: 1, &#39;000 Square Foot Exclusive Courtyard Oasis for VIA Residents&#39;: 1, &#39;Billiards and Shuffle Board Game Room Poker room Golf Simulator and Putting Green&#39;: 1, &#39;Park Block&#39;: 1, &#39;Voice Intercom&#39;: 1, &#39;4th floor Walk Up&#39;: 1, &#39;24 hour attended lobby&#39;: 1, &#39;pets upon approval&#39;: 1, &#39;** MIDTOWN MANSION * SPRAWLING SUNFILLED STUDIO * UTILITIES INCLUDED * DOORMAN * ELEV/LNDRY BLDG * PETS OK **&#39;: 1, &#34;** HUGE TRUE 3BR HOME * THE PERFECT SHARE * MASSIVE WINDOWS GALORE * COOK&#39;S KITCHEN * STEPS TO L TRAIN **&#34;: 1, &#39;Windowed Kitchen&#39;: 1, &#39;No Fee!!!&#39;: 1, &#39;Great Views of the Neighborhood&#39;: 1, &#39;Kids Playroom&#39;: 1, &#39;Game Room&#39;: 1, &#39;** HOLY DEAL BATMAN!! * OVERSIZED 3BR MANSION * 2 FULL BATHS * HUGE SCENIC TERRACE * DOORMAN * ELEV/LNDRY BLDG * ROOF DECK * REAL PIX **&#39;: 1, &#39;Super On Site&#39;: 1, &#39;On Site Super&#39;: 1, &#39;triplex&#39;: 1, &#39;Shared yard&#39;: 1, &#39;Polished Hardwood Floors&#39;: 1, &#39;Flex-4&#39;: 1, &#39;73rd St.&#39;: 1, &#39;Bluetooth System&#39;: 1, &#39;** MODERN VILLAGE MARVEL * SPRAWLING 2BR HOME * EXPOSED BRICK * LNDRY BLDG * NEAR THE PARK **&#39;: 1, &#39;Two Level Fitness Center&#39;: 1, &#34;** SPRAWLING 2BR SUPER SHARE * MASSIVE WINDOWS GALORE * COOK&#39;S KITCHEN * 2 BLKS TO BEDFORD L STOP **&#34;: 1, &#39;Mint Condition&#39;: 1, &#39;Jacuzzi bath tube&#39;: 1, &#39;BBQ Grill&#39;: 1, &#39;Chelsea&#39;: 1, &#39;Roof/Sundeck&#39;: 1, &#39;Overlooks Garden&#39;: 1, &#39;Electricity + Hot Water + Gas + Heat Included&#39;: 1, &#39;large living room&#39;: 1, &#39;Flat-screen TV&#39;: 1, &#39;FIOS High Speed Internet&#39;: 1, &#39;MONTH FREE&#39;: 1, &#39;valet and dry cleaning services&#39;: 1, &#39;boating hardwood floors&#39;: 1, &#39;A/C&#39;: 1, &#39;XXL Windows&#39;: 1, &#39;25lb weight limit on pet&#39;: 1, &#39;** PRISTINE PARK AVE FIND! * MASSIVE 2BR TRIPLEX DREAM SHARE * DINING RM * ELEV/LNDRY BLDG * HEART OF THE E50s **&#39;: 1, &#39;Big Rooms&#39;: 1, &#39;Natural Sunlight&#39;: 1, &#39;Hardwood floor&#39;: 1, &#39;shuttle service to subway&#39;: 1, &#39;000 sq. ft. landscaped terrace complete with an organic garden&#39;: 1, &#39;Walk-in Closet&#39;: 1, &#39;One month free rent&#39;: 1, &#39;50 ft. exercise pool and whirlpool with lifeguard on duty&#39;: 1, &#39;ALL UTILITIES INCLUDED!!&#39;: 1, &#39;Loft Like&#39;: 1, &#39;loft&#39;: 1, &#39;BROKER FEE.&#39;: 1, &#39;No fee&#39;: 1, &#39;Washer/ Dryer in Unit&#39;: 1, &#39;No Pets&#39;: 1, &#39;Full Skyline View&#39;: 1, &#39;Leed Certificate Gold&#39;: 1, &#39;BIG 2 BED DEAL..Grab it or Grieve it!!!&#39;: 1, &#39;** EXQUISITE RIVERSIDE SPECIAL! * STUNNING STUDIO DUPLEX * FIREPLACE * GUT RENOVATED * STEPS TO THE PARK! **&#39;: 1, &#39;Updated appliances&#39;: 1, &#39;Great area&#39;: 1, &#39;free cable tv and wireless internet&#39;: 1, &#39;laundry / dry-cleaning and auto care&#39;: 1, &#39;Brand New Stainless Steal Appliances!&#39;: 1, &#34;** EAST VILLAGE EXTRAVAGANZA * MASSIVE 2BR HOME * PERFECT SHARE * COOK&#39;S KITCHEN * PERFECT NATURAL LIGHT **&#34;: 1, &#39;Sparkling  Marble Bathroom&#39;: 1, &#39;Sleeping Alcove&#39;: 1, &#39;SS Appliances&#39;: 1, &#39;4&#39;: 1, &#39;Exposed BrickHardwood Floors MicrowaveRenovated open view Excellent&#39;: 1, &#39;soaking tub&#39;: 1, &#39;** EXPANSIVE KING-SIZED 2BR MEGA-SHARE * EAT-IN KITCHEN * BIKE STORAGE * COURTYARD * 3 BLKS TO BEDFORD L **&#39;: 1, &#39;Electricity Included&#39;: 1, &#39;PRE-WAR&#39;: 1, &#39;King-Sized Bedroom&#39;: 1, &#39;** OVERSIZED &amp; UNDERPRICED NO FEE * HUGE 2BR HOME * ALL MODERN &amp; NEW * EAT-IN KITCHEN * 2 BLKS TO THE TRAIN **&#39;: 1, &#39;Queen &amp; King Size Bedrooms&#39;: 1, &#39;ceiling-fan. 3Lg closets&#39;: 1, &#39;2 Queen Bedrooms&#39;: 1, &#39;Residents-only fitness center and aerobic room professionally outfitted with a full complement of strength and cardio-training equipment&#39;: 1, &#39;Oversized windows&#39;: 1, &#39;Conv. 3 Bedroom&#39;: 1, &#39;New&#39;: 1, &#39;** E60s EXCELLENCE * SPRAWLING 1BR HOME * GOURMET KITCHEN * WINDOWS ALL AROUND * PETS OK **&#39;: 1, &#39;Large rooms&#39;: 1, &#39;huge living room&#39;: 1, &#39;24-Hour Attended lobby&#39;: 1, &#39;personal trainer&#39;: 1, &#39;Queen size sleeping Alcove&#39;: 1, &#39;Heat and Hot Water Included&#39;: 1, &#39;Exercise equipment (if furnished)&#39;: 1, &#39;Top Floor&#39;: 1, &#39;on-sites super&#39;: 1, &#39;huge 1 bedroom&#39;: 1, &#39;Eat-In-Kitchen&#39;: 1, &#39;backyard&#39;: 1, &#39;Storage Closet&#39;: 1, &#39;Gas and Electric Included in Rent&#39;: 1, &#39;Bicycle Room&#39;: 1, &#39;Incredible Views!&#39;: 1, &#39;** RARE FIND! * SPRAWLING SUNDRENCHED 1BR HOME * STUNNING FINISHES * SS KITCHEN * WASHER/DRYER * DISHWASHER * HEART OF CHELSEA! **&#39;: 1, &#39;Spacious and Bright !!!&#39;: 1, &#39;Building Storage&#39;: 1, &#39;4 train is less than 1 block away&#39;: 1, &#34;** OVERSIZED 2BR SUPER SHARE * CHEF&#39;S KITCHEN * EXPOSED BRICK * LNDRY BLDG * HEART OF THE VILLAGE **&#34;: 1, &#39;New Appliances&#39;: 1, &#39;Unit has Balcony&#39;: 1, &#39;laundry in building&#39;: 1, &#39;Storage locker for each apt&#39;: 1, &#39;Stainless Kitchen&#39;: 1, &#39;Large open kitchen&#39;: 1, &#39;finished basement&#39;: 1, &#39;24/7 Fitness Center&#39;: 1, &#39;Nearby M &amp; R trains&#39;: 1, &#39;** W70s WINNER! * SUPER SWEET STUDIO * WALLS OF WINDOWS * HI END RENOVATIONS * OVERSIZED CLOSETS * STEPS TO THE PARK! **&#39;: 1, &#39;balocny&#39;: 1, &#39;Private Outdoor space&#39;: 1, &#39;NO FEE...LUXURY DOORMAN BUILDING^^^RIVER VIEWS&#39;: 1, &#39;Owner Occupied - 3 family townhouse - no realtor fees - this beautiful apt is offered below market rate&#39;: 1, &#39;Marble Bathrooms&#39;: 1, &#39;Air Conditioning&#39;: 1, &#39;ELEVATOR&#39;: 1, &#39;Equal Size Rooms&#39;: 1, &#39;Health Club &amp; Indoor Swimming Pool&#39;: 1, &#39;PRIVATE OUTDOOR GARDEN&#39;: 1, &#39;Childrens playroom&#39;: 1, &#39;Granite Counter-tops&#39;: 1, &#39;onsite super&#39;: 1, &#39;Free brealfast&#39;: 1, &#39;One month free&#39;: 1, &#39;Two Closets&#39;: 1, &#39;Lounge with WiFi&#39;: 1, &#39;HUGE&#39;: 1, &#39;2 year lease&#39;: 1, &#39;all kitchen appliances included&#39;: 1, &#39;Private roof-deck&#39;: 1, &#39;b Billiards Table&#39;: 1, &#39;Washer&#39;: 1, &#39;** MURRAY HILL NO FEE MANSION * SPRAWLING 1BR HOME * ORNATE PREWAR DETAILS * GOURMET KITCHEN * WINDOWS ALL AROUND **&#39;: 1, &#39;ABSOLUTE VALUE FOR SIZE &amp; LOCATION&#39;: 1, &#39;** PRISTINE TOWNHOUSE * MASSIVE 2BR SUPER SHARE * DISHWASHER * E50s BABY! * PERFECT NATURAL LIGHT * ROOMY CLOSETS **&#39;: 1, &#39;Gut Renovation&#39;: 1, &#39;junior 1 bedroom layout&#39;: 1, &#39;Social Lounge&#39;: 1, &#39;Atm&#39;: 1, &#39;30th St &amp; Madison Avenue&#39;: 1, &#39;laundry in bldg&#39;: 1, &#39;Gym Discount&#39;: 1, &#39;** WICKED W50s STEAL! * MASSIVE 1BR HOME * HI END RENOVATIONS * ELEV/LNDRY BLDG * REAL PIX * STEPS TO THE PARK! **&#39;: 1, &#39;Large Living room &amp; Bedrooms&#39;: 1, &#39;** OVERSIZED &amp; UNDERPRICED! * SPRAWLING CONV 3BR MANSION * MASSIVE WINDOWS GALORE * ELEV BLDG * STEPS TO THE PARK! **&#39;: 1, &#39;Fitness Center and health club&#39;: 1, &#39;quiet&#39;: 1, &#39;Superintendent lives in&#39;: 1, &#39;Dining/living room&#39;: 1, &#39;Updated Kitchen and Bathroom&#39;: 1, &#34;** OVERSIZED &amp; UNDERPRICED NO FEE * SPRAWLING 3BR SUPER SHARE * SEPARATE COOK&#39;S KITCHEN * WALLS OF WINDOWS * 2 BLKS TO TRAIN **&#34;: 1, &#39;** NO FEE BKLN LUXURY! * EXPANSIVE 1BR w/HOME OFFICE * EAT-IN KITCHEN * FULL RENOVATED * 1 BLK TO THE PARK * STEPS TO L TRAIN **&#39;: 1, &#34;** RARE FIND! * HUGE TRUE 2BR SUPER SHARE * CHEF&#39;S KITCHEN * COURTYARD! * 2 BLKS TO BEDFORD L STOP **&#34;: 1, &#39;no fee&#39;: 1, &#39;fully equipped gym&#39;: 1, &#39;Brand Newm Outdoor Deck&#39;: 1, &#39;One month Fee&#39;: 1, &#39;Roof garden and lounge&#39;: 1, &#39;Townhouse&#39;: 1, &#39;Concierge service. Fitness center&#39;: 1, &#39;** SPRAWLING TRUE 3BR SUPER SHARE * FIT FOR KINGS! * UNIQUE RENOVATIONS * STEPS TO THE WATERFRONT * 1 BLK TO BEDFORD L STOP **&#39;: 1, &#39;** DIAMOND UWS DEAL! * MASSIVE STUDIO * EXPOSED BRICK * DISHWASHER * PETS OK * STEPS TO THE PARK! **&#39;: 1, &#39;** EXPANSIVE 4BR DUPLEX DREAM SHARE * GARDEN! * HUGE WINDOWS GALORE * ORNATE PREWAR DETAILS * 2 BLKS TO BEDFORD L **&#39;: 1, &#39;Walk in closet&#39;: 1, &#39;** CLASSY CONV 2BR DUPLEX DREAM! * ROOM TO ENTERTAIN * LNDRY BLDG * CATS OK * HEART OF THE VILLAGE **&#39;: 1, &#39;Garden Roof Deck&#39;: 1, &#39;custom window treatments&#39;: 1, &#39;Stunning Renovations&#39;: 1, &#39;HUGE &amp; GUT RENOVATED&#39;: 1, &#39;Full Kitchen&#39;: 1, &#39;housekeeping + dry cleaning services&#39;: 1, &#39;custom lighting&#39;: 1, &#39;** LEX AVE LUXURY! * SPRAWLING SUNFILLED 1BR HOME * ALL UTILITIES INCL! * DOORMAN * ELEV/LNDRY BLDG * CATS OK **&#39;: 1, &#39;** PRISTINE PARK AVE S LOFT! * MASSIVE 3BR MANSION * WALLS OF WINDOWS * CHEF INSPIRED KITCHEN * ELEV BLDG **&#39;: 1, &#39;Seperate Kitchen&#39;: 1, &#39;** SPRAWLING 1BR w/HOME OFFICE * PRIVATE BACKYARD * SPARKLING CLEAN &amp; BRIGHT * STEPS TO L TRAIN **&#39;: 1, &#39;** OVERSIZED 1BR HOME * HUGE WINDOWS GALORE * WASHER/DRYER * RENT STABILIZED! * OFF 6TH AVE ~ HEART OF MIDTOWN! **&#39;: 1, &#39;PLUS 1 MONTH FREE!!!&#39;: 1, &#39;Storage in Building Included!&#39;: 1, &#39;pets ok&#39;: 1, &#39;-Greal location&#39;: 1, &#39;** HUGE TRUE 2BR SUPER SHARE * ORNATE PREWAR DETAILS * SO FRESH &amp; SO CLEAN * L TRAIN BABY! **&#39;: 1, &#39;Shuttle to 7 train&#39;: 1, &#39;tenants lounge with kitchenette&#39;: 1, &#39;Granite Bath&#39;: 1, &#39;** SPRAWLING SUNDRENCHED STUDIO * MR CLEAN APPROVED * ROOMY CLOSETS * PETS OK * W50s ~ STEPS TO THE PARK! **&#39;: 1, &#39;new construction&#39;: 1, &#39;700 SF&#39;: 1, &#39;Equal King-Size Bedrooms&#39;: 1, &#39;Queen Size Bedrooms&#39;: 1, &#39;Electric Included&#39;: 1, &#39;Common Terrace&#39;: 1, &#39;1/2 bath&#39;: 1, &#39;Elevator Building&#39;: 1, &#39;Fire Place&#39;: 1, &#39;Just Renovated&#39;: 1, &#39;Sun/Roofdeck&#39;: 1, &#39;Lounge W/ Free Wifi&#39;: 1, &#39;furnished rental&#39;: 1, &#39;Renovated Apt&#39;: 1, &#39;Club room&#39;: 1, &#39;Eat-in-Kitchen&#39;: 1, &#39;LEED certified&#39;: 1, &#39;87th &amp; 1st&#39;: 1, &#39;Large Windows w/ Natural Light&#39;: 1, &#39;onsite valet&#39;: 1, &#39;** CLASSY CORNER STUDIO SUPREME * WALLS OF WINDOWS * ALL MODERN &amp; NEW * PETS OK **&#39;: 1, &#39;5 BED&#39;: 1, &#34;** HOLY DEAL BATMAN! * SPRAWLING 3BR HOME * COOK&#39;S KITCHEN * 2 BLKS TO WATERFRONT * BEDFORD L STOP **&#34;: 1, &#39;and RCN&#39;: 1, &#39;Walls OK&#39;: 1, &#39;24-hour parking garage with an electric vehicle charging station.&#39;: 1, &#39;Yoga Studio&#39;: 1, &#39;water view&#39;: 1, &#39;** UNIQUE UNION SQ STEAL * MASSIVE 1BR HOME * MR CLEAN APPROVED * REAL PIX * ELEV BLDG **&#39;: 1, &#39;Live-In Resident Manager&#39;: 1, &#39;LOUNGE&#39;: 1, &#39;high ceilings.&#39;: 1, &#39;2 blocks away from Union Square&#39;: 1, &#39;S/S Appliances&#39;: 1, &#39;** CLASSY CONDO GEM! * MASSIVE 2BR SUPER SHARE * GOURMET KITCHEN * PERFECT SUN * CHIC CHELSEA LOCALE! **&#39;: 1, &#39;** NO BROKER FEE! * MASSIVE 2BR SUPER SHARE * EAT-IN KITCHEN * PRIVATE TERRACE * ELEV/LNDRY BLDG * 1 BLK TO L TRAIN **&#39;: 1, &#39;Available 06/04/16     Firepalce&#39;: 1, &#39;Custom murals on the ceiling and living room wall. Painted my a local artist.&#39;: 1, &#34;** BKLYN&#39;S FINEST! * MASSIVE TRUE 2BR * COURTYARD * FULLY RENOVATED * 2 BLKS TO BEDFORD L STOP **&#34;: 1, &#39;1 month free rent&#39;: 1, &#39;** REAL NO FEE! * MASSIVE TRUE 2BR SUPER SHARE * ALL MODERN &amp; NEW * EAT-IN KITCHEN * 2 BLKS TO THE TRAIN **&#39;: 1, &#39;** DOUBLE DUPLEX DEAL! * SPRAWLING 3BR HOME * 1.5 BATHS * PRIVATE DECK &amp; BALCONY! * EAT-IN KITCHEN * WASHER//DRYER * ALL MODERN NEW! **&#39;: 1, &#39;Julian Balcony&#39;: 1, &#39;High-speed internet access&#39;: 1, &#39;Photos of actual apartment&#39;: 1, &#39;Quiet Neighborhood&#39;: 1, &#39;** OVERSIZED 1BR DUPLEX DREAM * MR CLEAN APPROVED * UNIQUE DETAILS * NEAR CENTRAL PARK * W50s BABY * PETS OK **&#39;: 1, &#39;** SPRAWLING 2BR SUPER SHARE * GUT RENOVATED * CLEAN &amp; BRITE * 1/2 BLK TO BEDFORD L **&#39;: 1, &#39;Market on site&#39;: 1, &#39;Washer and dryer in unit&#39;: 1, &#39;exclusive rental&#39;: 1, &#39;Stunning New Renovation&#39;: 1, &#39;** OVERSIZED &amp; UNDERPRICED! * SPRAWLING SUNFILLED STUDIO * ROOMY CLOSETS * TONS OF SUNLIGHT * PETS OK **&#39;: 1, &#39;Rent stabilize&#39;: 1, &#39;ROOFTOP&#39;: 1, &#39;renovated kitchen&#39;: 1, &#39;convertible 2 bedroom&#39;: 1, &#39;Game Center&#39;: 1, &#39;Features: Washer/Dryer&#39;: 1, &#39;Brand New Renovation&#39;: 1, &#39;Utilities included&#39;: 1, &#39;crown molding&#39;: 1, &#39;Childrens Playroom.&#39;: 1, &#39;Pilates and training room.&#39;: 1, &#39;Residents can choose from three high-speed Internet providers: Verizon Fios&#39;: 1, &#39;FREE MONTH &amp; NO-FEE&#39;: 1, &#39;new flooring&#39;: 1, &#39;Rent Stabilize - Elevator Building&#39;: 1, &#39;rooftop with grills&#39;: 1, &#39;** MIDTOWN MANSION * HUGE 2BR HOME * EAT-IN KITCHEN * SS APPL * FRENCH DOORS * ROOMY CLOSETS **&#39;: 1, &#39;Dogs under 20 Lbs.                Parking ( additional Fee)&#39;: 1, &#39;Underground parking&#39;: 1, &#39;Built-in Breakfast Bar&#39;: 1, &#39;Pre-War small dogs&#39;: 1, &#39;wine cooler.&#39;: 1, &#39;Gramercy&#39;: 1, &#39;Flex 3 Bed&#39;: 1, &#39;new kitchen!&#39;: 1, &#39;package service&#39;: 1, &#39;Pet friendly ( case by case )&#39;: 1, &#39;Kitchen Island&#39;: 1, &#39;Laundry room&#39;: 1, &#39;** THE PERFECT SHARE! * SPRAWLING SUNFILLED 4BR MANSION * CLEAN &amp; BRITE * STEPS TO THE PARK &amp; BEDFORD L STOP **&#39;: 1, &#39;stunning&#39;: 1, &#39;Shared Yard&#39;: 1, &#39;24 hr concierge&#39;: 1, &#39;Baruch&#39;: 1, &#39;** THE PERFECT SHARE * SPRAWLING 3BR HOME * HI END RENOVATIONS * MR CLEAN APPROVED * ROOMY CLOSETS * G-VILLAGE BABY! **&#39;: 1, &#34;** HOLY NO FEE DEAL BATMAN! * MASSIVE 1BR HOME * CHEF&#39;S KITCHEN * MAGIC ERASER CLEAN * PETS OK * REAL PIX **&#34;: 1, &#39;1.5 Marble Baths&#39;: 1, &#39;Sunlight&#39;: 1, &#39;81ST &amp; CPW&#39;: 1, &#39;BRAND NEW SS APPLIANCES&#39;: 1, &#39;Close to Central Park&#39;: 1, &#39;Great Location&#39;: 1, &#39;Washer/Dryer In Unit&#39;: 1, &#39;an expansive landscaped terrace and sun deck&#39;: 1, &#39;Convertible 1br&#39;: 1, &#39;Close to hospitals&#39;: 1, &#39;Dining Area&#39;: 1, &#39;12th St &amp; 3rd Ave&#39;: 1, &#39;own entrance&#39;: 1, &#39;Washer/ Dryer Hookups&#39;: 1, &#39;Brand New Appliances&#39;: 1, &#39;Walk-In Closet Views:&#39;: 1, &#39;Ample Closet Space&#39;: 1, &#39;Two Private Balconies&#39;: 1, &#39;live in super&#39;: 1, &#39;Gym Fitness Lounge Swimming Pool Sun Decks Exercise Studios Indoor Half-Basketball Court&#39;: 1, &#39;Storage in basement&#39;: 1, &#39;!!!!LOW FEE!!!!&#39;: 1, &#39;Large Living room&#39;: 1, &#39;Hot Water Included&#39;: 1, &#39;S-Steel Appliances&#39;: 1, &#39;bike storage&#39;: 1, &#39;A wide array of complimentary fitness classes offered weekly&#39;: 1, &#39;** SPRAWLING SUNDRENCHED 2BR HOME * NO FEE! * WALLS OF WINDOWS * CHEF INSPIRED EAT-IN KITCHEN * 2 BLKS TO TRAIN **&#39;: 1, &#39;private patio&#39;: 1, &#39;built in office area&#39;: 1, &#39;Ample sofa bed in living space for extra accommodations&#39;: 1, &#39;Fully equipped fitness center with studio for classes&#39;: 1, &#39;big closets&#39;: 1, &#39;Double height lobby French limestone and Rojo Alicante marble&#39;: 1, &#39;Exposed brick wall&#39;: 1, &#39;** HOLY NO FEE DEAL! * OVERSIZED 2BR SUPER SHARE * PRIVATE TERRACE * SS KITCHEN * DISHWASHER * ELEV/LNDRY BLDG * 3 BLKS TO L TRAIN **&#39;: 1, &#39;ONLY 1st and Security**Heat and Hot water included**NO FEE**732-330-4737&#39;: 1, &#39;Stainless Steel Full Size Appliances.&#39;: 1, &#39;Near Subway&#39;: 1, &#39;deco brick wall&#39;: 1, &#39;Herringbone Wood Floors&#39;: 1, &#39;natural light&#39;: 1, &#39;East and West Resident Lounges Reading Room Outdoor Lounges with River Views Party Room Chefs Kitchen Movie Screening Room Tot Spot Playroom Ping Pong&#39;: 1, &#39;$600 gift card for Move-ins prior to June 19&#39;: 1, &#39;parks in area&#39;: 1, &#39;Right on Lexington Ave - Close to subway&#39;: 1, &#39;Highland Park&#39;: 1, &#39;bicycle storage&#39;: 1})
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[109]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">csv</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;kaggle_apt_feature_dict.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">csv_file</span><span class="p">:</span>
    <span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">writer</span><span class="p">(</span><span class="n">csv_file</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">feature_count</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">([</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">])</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Setting up 10 one hot encoded variables based on the 10 most popular features. Search terms for each of the 10 features: <br/>
elevator <br/>
cats<br/>
hardwood<br/>
dogs<br/>
doorman<br/>
dishwasher<br/>
no fee<br/>
laundry<br/>
fitness, gym<br/>
pre-war, prewar, pre war</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[84]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">apt_feature_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;features&#39;</span><span class="p">])</span>
<span class="n">apt_feature_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">apt_feature_length</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="c1">#print(apt_feature_array.shape)</span>
<span class="n">apt_feature_search_string</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">&quot;elevator&quot;</span><span class="p">],[</span><span class="s2">&quot;cats&quot;</span><span class="p">],[</span><span class="s2">&quot;hardwood&quot;</span><span class="p">],[</span><span class="s2">&quot;dogs&quot;</span><span class="p">],[</span><span class="s2">&quot;doorman&quot;</span><span class="p">],[</span><span class="s2">&quot;dishwasher&quot;</span><span class="p">],</span>
                             <span class="p">[</span><span class="s2">&quot;no fee&quot;</span><span class="p">],[</span><span class="s2">&quot;laundry&quot;</span><span class="p">],[</span><span class="s2">&quot;fitness&quot;</span><span class="p">,</span><span class="s2">&quot;gym&quot;</span><span class="p">],[</span><span class="s2">&quot;pre-war&quot;</span><span class="p">,</span><span class="s2">&quot;prewar&quot;</span><span class="p">,</span><span class="s2">&quot;pre war&quot;</span><span class="p">]]</span>
<span class="n">z_break</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">apt_feature_length</span><span class="p">):</span>
    <span class="n">feature_list</span> <span class="o">=</span> <span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;features&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">feature_list</span><span class="p">:</span>
        <span class="n">temp_feature</span> <span class="o">=</span> <span class="n">feature</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="c1">#print(i, temp_feature)</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span><span class="c1">#search_category in apt_feature_search_string:</span>
            <span class="n">search_category</span> <span class="o">=</span> <span class="n">apt_feature_search_string</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">search_string</span> <span class="ow">in</span> <span class="n">search_category</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">search_string</span> <span class="ow">in</span> <span class="n">temp_feature</span><span class="p">:</span>
                    <span class="n">apt_feature_array</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
                    <span class="k">break</span>

<span class="nb">print</span><span class="p">(</span><span class="n">apt_feature_array</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">4</span><span class="p">,:])</span>
                
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
 [ 1.  1.  0.  1.  1.  0.  0.  0.  1.  0.]
 [ 0.  0.  1.  0.  0.  1.  0.  1.  0.  0.]
 [ 0.  0.  1.  0.  0.  0.  1.  0.  0.  0.]]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[85]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#add the one hot variables to the dataframe</span>
<span class="n">z_string</span> <span class="o">=</span> <span class="s2">&quot;apt_feature_&quot;</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">temp_string</span> <span class="o">=</span> <span class="n">z_string</span> <span class="o">+</span> <span class="n">apt_feature_search_string</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1">#print(temp_string)</span>
    <span class="n">df_raw</span><span class="p">[</span><span class="n">temp_string</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">apt_feature_array</span><span class="p">[:,</span><span class="n">i</span><span class="p">],</span><span class="n">index</span><span class="o">=</span><span class="n">df_raw</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[90]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#df_raw.head()</span>
<span class="c1">#df_raw[&#39;features_count&#39;].describe()</span>
<span class="c1">#df_raw.to_pickle(&quot;train_checkpoint_15&quot;)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="1.7-Listing-Id">1.7 Listing Id<a class="anchor-link" href="#1.7-Listing-Id">&#182;</a></h3><p>Not used.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="1.8-Manager-Id-and-Building-Id">1.8 Manager Id and Building Id<a class="anchor-link" href="#1.8-Manager-Id-and-Building-Id">&#182;</a></h3><p>Manager_id and building_id have too many unique values (roughly 3,500 and 7,500) to one hot encode. However, when analyzing the test set, it would be useful to know if the manager_id and building_id have been used before and what the past results were. Since managers likely have a similar system for creating entries and buildings have similar desirable (or undesirable) attributes, I created 4 features for each: count of listings and count of high/medium/low interest listings. For each entry I subtracted the result of that apartment interest level in order not to influence the predictions (ie for a manager with only 1 entry, the count of high/medium/low would predict the interest level 100% of the time, thus I have to remove the prediction for that entry, from that entry row). <br/></p>
<p>I considered adding other columns that had the proportion of low/medium/high interest % listings modified by how certain I am that those percentages are different than the benchmark percentage. The thinking being if a manager produces 50% high interest listings over 200 samples, he's likely doing something statistically signficant and that could be used to improve the rating. However I could not think of a good way to produce those percentages. Simply calculating the observed percentages produces issues with small sample size and I could not think of a Laplacian smoothing like procedure that would work in this case. I considered a one-proportion z-test (<a href="https://en.wikipedia.org/wiki/Statistical_hypothesis_testing">https://en.wikipedia.org/wiki/Statistical_hypothesis_testing</a>) but most manager samples lack sufficient number of samples. I feel like Bayes Theorem could be applied here or a probability density but could not come up with a good way to apply my thoughts to manager_id and building_id.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[91]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">count</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;manager_id&#39;</span><span class="p">])</span>
<span class="n">df_manager</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">count</span><span class="p">,</span> <span class="n">orient</span><span class="o">=</span><span class="s1">&#39;index&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">df_manager</span> <span class="o">=</span> <span class="n">df_manager</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;index&#39;</span><span class="p">:</span><span class="s1">&#39;manager_id&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="s1">&#39;count&#39;</span><span class="p">})</span>
<span class="n">df_manager</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt output_prompt">Out[91]:</div>

<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>3481.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>14.177535</td>
    </tr>
    <tr>
      <th>std</th>
      <td>53.045270</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>4.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>13.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>2533.000000</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[92]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">low_count</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">medium_count</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">high_count</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">df_temp</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span> <span class="p">{</span><span class="s1">&#39;manager_id&#39;</span><span class="p">:</span> <span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;manager_id&#39;</span><span class="p">],</span><span class="s1">&#39;interest_level&#39;</span><span class="p">:</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]})</span>

<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">df_manager</span><span class="p">[</span><span class="s1">&#39;manager_id&#39;</span><span class="p">]:</span>
    <span class="n">subset</span> <span class="o">=</span> <span class="n">df_temp</span><span class="p">[(</span><span class="n">df_temp</span><span class="p">[</span><span class="s1">&#39;manager_id&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">x</span><span class="p">)]</span>
    <span class="n">low_count</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">subset</span><span class="p">[</span><span class="n">subset</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;low&#39;</span><span class="p">]))</span>
    <span class="n">medium_count</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">subset</span><span class="p">[</span><span class="n">subset</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;medium&#39;</span><span class="p">]))</span>
    <span class="n">high_count</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">subset</span><span class="p">[</span><span class="n">subset</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;high&#39;</span><span class="p">]))</span>
    
<span class="n">df_manager</span><span class="p">[</span><span class="s1">&#39;low_count&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">low_count</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="n">df_manager</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">df_manager</span><span class="p">[</span><span class="s1">&#39;medium_count&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">medium_count</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="n">df_manager</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">df_manager</span><span class="p">[</span><span class="s1">&#39;high_count&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">high_count</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="n">df_manager</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>

<span class="n">df_manager</span> <span class="o">=</span> <span class="n">df_manager</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span> <span class="s1">&#39;count&#39;</span><span class="p">:</span><span class="s1">&#39;manager_count&#39;</span><span class="p">,</span> <span class="s1">&#39;low_count&#39;</span><span class="p">:</span><span class="s1">&#39;manager_low&#39;</span><span class="p">,</span><span class="s1">&#39;medium_count&#39;</span><span class="p">:</span><span class="s1">&#39;manager_medium&#39;</span>
                          <span class="p">,</span><span class="s1">&#39;high_count&#39;</span><span class="p">:</span><span class="s1">&#39;manager_high&#39;</span><span class="p">})</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[123]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_manager</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt output_prompt">Out[123]:</div>

<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>manager_id</th>
      <th>manager_count</th>
      <th>manager_low</th>
      <th>manager_medium</th>
      <th>manager_high</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>812d39efccb575c6ece9dc21d777cfa8</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>c53e54425cc299b2017c5e84f1614d28</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>6e249f377fd507282ab0caa8976fff46</td>
      <td>39</td>
      <td>36</td>
      <td>3</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>01c92a064394eb8fd1a084631c8bc701</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>65a2ad830b1c49ed8cc2520d56beff86</td>
      <td>7</td>
      <td>6</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Some histograms that show that more experienced managers tend to have a lower rate of low interest listings and a higher rate of high interest listings.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[125]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_temp</span> <span class="o">=</span> <span class="n">df_manager</span><span class="p">[</span><span class="n">df_manager</span><span class="p">[</span><span class="s1">&#39;manager_count&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">df_temp_10</span> <span class="o">=</span> <span class="n">df_manager</span><span class="p">[</span><span class="n">df_manager</span><span class="p">[</span><span class="s1">&#39;manager_count&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">10</span><span class="p">]</span>

<span class="n">low_proportion</span> <span class="o">=</span> <span class="n">df_temp</span><span class="p">[</span><span class="s1">&#39;manager_low&#39;</span><span class="p">]</span><span class="o">/</span><span class="n">df_temp</span><span class="p">[</span><span class="s1">&#39;manager_count&#39;</span><span class="p">]</span>
<span class="n">medium_proportion</span> <span class="o">=</span> <span class="n">df_temp</span><span class="p">[</span><span class="s1">&#39;manager_medium&#39;</span><span class="p">]</span><span class="o">/</span><span class="n">df_temp</span><span class="p">[</span><span class="s1">&#39;manager_count&#39;</span><span class="p">]</span>
<span class="n">high_proportion</span> <span class="o">=</span> <span class="n">df_temp</span><span class="p">[</span><span class="s1">&#39;manager_high&#39;</span><span class="p">]</span><span class="o">/</span><span class="n">df_temp</span><span class="p">[</span><span class="s1">&#39;manager_count&#39;</span><span class="p">]</span>

<span class="n">low_proportion_10</span> <span class="o">=</span> <span class="n">df_temp_10</span><span class="p">[</span><span class="s1">&#39;manager_low&#39;</span><span class="p">]</span><span class="o">/</span><span class="n">df_temp_10</span><span class="p">[</span><span class="s1">&#39;manager_count&#39;</span><span class="p">]</span>
<span class="n">medium_proportion_10</span> <span class="o">=</span> <span class="n">df_temp_10</span><span class="p">[</span><span class="s1">&#39;manager_medium&#39;</span><span class="p">]</span><span class="o">/</span><span class="n">df_temp_10</span><span class="p">[</span><span class="s1">&#39;manager_count&#39;</span><span class="p">]</span>
<span class="n">high_proportion_10</span> <span class="o">=</span> <span class="n">df_temp_10</span><span class="p">[</span><span class="s1">&#39;manager_high&#39;</span><span class="p">]</span><span class="o">/</span><span class="n">df_temp_10</span><span class="p">[</span><span class="s1">&#39;manager_count&#39;</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="c1">#ax1.plot(x, y)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">low_proportion</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Low Interest: Managers &gt;= 1 Listings and Managers &gt;= 10 Listings&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">low_proportion_10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">ax3</span><span class="p">,</span> <span class="n">ax4</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">ax3</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">medium_proportion</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax3</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Medium Interest: Managers &gt;= 1 Listings and Managers &gt;= 10 Listings&#39;</span><span class="p">)</span>
<span class="n">ax4</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">medium_proportion_10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">ax5</span><span class="p">,</span> <span class="n">ax6</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">ax5</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">high_proportion</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax5</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;High Interest: Managers &gt;= 1 Listings and Managers &gt;= 10 Listings&#39;</span><span class="p">)</span>
<span class="n">ax6</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">high_proportion_10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>


<div class="output_text output_subarea ">
<pre>&lt;matplotlib.figure.Figure at 0x1809c8d0&gt;</pre>
</div>

</div>

<div class="output_area"><div class="prompt"></div>


<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAeIAAAEICAYAAACDNvdHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

<div class="output_area"><div class="prompt"></div>


<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAe4AAAEICAYAAACZChfJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

<div class="output_area"><div class="prompt"></div>


<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAeQAAAEICAYAAACOKIcAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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=
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Can examine the most successful managers to get a sense of what they do in order to produce high interest listings.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[127]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">df_manager</span><span class="p">[(</span><span class="n">df_manager</span><span class="p">[</span><span class="s2">&quot;manager_count&quot;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">10</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df_manager</span><span class="p">[</span><span class="s2">&quot;manager_high&quot;</span><span class="p">]</span><span class="o">/</span><span class="n">df_manager</span><span class="p">[</span><span class="s2">&quot;manager_count&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.5</span> <span class="p">)])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_raw</span><span class="p">[</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;manager_id&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;12c0a30e296faa0dfd422fe918d7d4f4&#39;</span><span class="p">])</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>                            manager_id  manager_count  manager_low  \
260   3e04672678ee02c7bb843a9d4641c440             17            6   
372   456848d13f96dc522e5cf381095caeca             31            3   
1504  e9920062e07ee893c10e38d0259665b0             27            2   
1974  3b630ec9cb6eee53b92cfac7f42e3bf4             29            4   
2195  cb91d4992adf2a996e1454fb39434fb8             12            2   
2372  f948a6d058c0d51c2b802734f5db9d74             11            0   
2497  12c0a30e296faa0dfd422fe918d7d4f4             91           12   
2501  603575a3da76fa757cd6451f3707819d             26            3   
2603  53072af31d51fcdbc29dba6bc28a5011             15            0   
2939  2529098e553450cef6ba3198a1c2eec4             12            0   
3354  c80aad40b6abd065b4aefee40a2154f6             15            1   
3418  35f11f952ba96803a9d9e23e83e7f972             46            4   

      manager_medium  manager_high  
260                2             9  
372                7            21  
1504               9            16  
1974               9            16  
2195               3             7  
2372               4             7  
2497              28            51  
2501               5            18  
2603               7             8  
2939               5             7  
3354               5             9  
3418              13            29  
        bathrooms  bedrooms                       building_id  \
100079        1.0         1  f06ad2f6f1a821c8efc03dc195d369df   
100809        1.0         1  291d5ee9387222f0dfc16fa7f03d595e   
101275        1.0         0  9146db779d273a1bf21c4d2694442e60   
101859        1.0         1  9940dd41685d931927f6de04d739fb87   
103970        1.0         1  b3d1d4fc621d8707062eb4953d0e2464   
104657        1.0         0  86f4e42de411c5b83623d74645ca005e   
10597         1.0         1  ff48c0928efab3d04ead52e700395776   
10635         1.0         1  19f448a953a5c5107291bdf9edef60d7   
10716         1.0         0  1a66f794f047e9db083fb37d9e0ec421   
109831        1.0         0  af8eb4fdf0613237bdcd11390d5b73b1   
110660        1.0         1  c995bfc9d0bfd89a2aafcf8ed7226388   
110779        1.0         1  f44a9ce21963b200c3c13900e58192b1   
112927        1.0         1  c0b06184e5f79a277b66bdc0683509b0   
114744        1.0         2  21b6e706820f387c25e355da35d6e50d   
11481         1.0         1  93c6937fb02380968b3cc687c1e83e36   
114907        1.0         3  095eb9f84fdd2a60facc31316a94ec96   
116701        1.0         1  4b63b9124f46fc833bfdf1e18dc67663   
117430        1.0         1  0beac60ffdb53a14a45bccd8ee5e39a5   
118411        1.0         1  f4a923aa5d1ff6c066752f532a20b3e8   
119313        1.0         1  45f231f1aa5f02827e9ceb6b66aefb2f   
119802        1.0         2  519c422fbeb3d99f7e1ca0989e49fd67   
120874        1.0         1  9a92ba1ec95a631fa7f4c1d7bf82dadf   
122721        1.0         2  6422e551e68669cd63457159aed81137   
122952        1.0         2  f11dfc667448ce16d5ce37d79c3e3a4b   
123498        1.0         2  3e813705368e8d311e1dcdf2c9c5d94b   
123595        1.0         2  340fb26443cc5dd265678de837190abd   
123658        1.0         1  a41804b41ab70da02d3fe807c185b56f   
14922         1.0         2  d7c06729b903193f10e340c3c7c9ddc0   
1567          1.0         2  3b0750086f326971ad1df690d637c471   
17313         1.0         1  05fd08dd033e5a761ae8700dba250919   
...           ...       ...                               ...   
51919         1.0         0  93c6937fb02380968b3cc687c1e83e36   
55590         1.0         0  17e43c1ef6d2044b50933f6bb28c4020   
56337         1.0         2  595455a05bbb6b9aba040e79a4ca8a9b   
58926         1.0         1  be4d9d78910c9151f0d3513832a69a1e   
60436         1.0         1  c5ae83491d159403de3f7cc197cf8c8a   
64838         1.0         1  480656e7a37c7ca49b337a007742fd5f   
65242         1.0         0  9146db779d273a1bf21c4d2694442e60   
66704         1.0         0  86f4e42de411c5b83623d74645ca005e   
67874         1.0         1  d7c06729b903193f10e340c3c7c9ddc0   
71325         1.0         1  148d3925e316791f6736279c979ddbee   
73207         1.0         1  deef5e79e40c45b7df7f85c257ea8a57   
74883         1.0         2  19243d4ab13cdc9ba6bb9bf8179b8e38   
76461         1.0         2  d813594b750e7bd64437f330fba74371   
78132         1.0         1  3b0750086f326971ad1df690d637c471   
79271         1.0         1  2586732a129b4591959b25a957aa2d22   
79757         1.0         1  0beac60ffdb53a14a45bccd8ee5e39a5   
81548         2.0         4  ea1d531cdd0212e110b54592ea306e23   
82066         1.0         2  16850f026799abf2a6a1b5cded839051   
82670         1.0         1  f44a9ce21963b200c3c13900e58192b1   
84647         1.0         1  cceb927007e584d34838e8a0763ea7e6   
87878         1.0         2  72b8cd3f8e47b92df8413566d34b69c0   
90976         1.0         0  45f231f1aa5f02827e9ceb6b66aefb2f   
92178         1.0         1  cee4114b412f0f5169f94bb499193f7a   
92767         1.0         0  38dd51b2f9e74798e408682c574cf283   
92925         1.5         3  ad9910fe2167472266162644a5c120d0   
93205         1.0         1  bd6eee912a1558d3cc23cba73c7052af   
94233         1.0         0  10603b0444aa325788f90889a60c06d2   
95817         1.0         2  72b8cd3f8e47b92df8413566d34b69c0   
96794         1.0         1  18cfe7a2bed9d9a4a13af66fcdb6a554   
98250         1.0         3  ad9910fe2167472266162644a5c120d0   

                   created                                        description  \
100079 2016-04-21 05:27:10          Currently under renovation, this one b...   
100809 2016-04-30 04:38:03          &lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;Currentl...   
101275 2016-04-06 06:40:26          Beautiful studio apartment with a spac...   
101859 2016-04-15 03:34:14          This is a beautifully renovated one be...   
103970 2016-04-20 04:38:34          Currently under renovation, this one b...   
104657 2016-04-15 05:24:23          Currently under renovation, this Studi...   
10597  2016-06-09 04:06:57          Currently under renovation, this one b...   
10635  2016-06-23 04:05:12          Apartment under renovation, photo is a...   
10716  2016-06-12 08:05:39          Located close to Montefiore Hospital!&lt;...   
109831 2016-04-15 04:44:54          Currently under renovation, this Studi...   
110660 2016-04-30 04:00:10          Currently under renovation, this one b...   
110779 2016-04-08 03:36:17          Currently under renovation, this one b...   
112927 2016-04-23 03:52:06          Currently under renovation, this one b...   
114744 2016-04-08 03:27:27          Currently under renovation, this 2 bed...   
11481  2016-06-12 13:25:54          Currently under renovation, this one b...   
114907 2016-04-06 07:13:14          This is a beautiful 3 bedroom apartmen...   
116701 2016-04-06 18:24:06          This is a beautiful one bedroom apartm...   
117430 2016-04-19 03:52:02          Currently under renovation, this one b...   
118411 2016-04-21 03:47:05          This is a beautiful one bedroom apartm...   
119313 2016-04-06 05:12:22          Gorgeous one apartment! Apartment feat...   
119802 2016-04-06 06:35:27          This is a newly renovated, spacious tw...   
120874 2016-04-13 05:07:07          This is a beautiful one bedroom apartm...   
122721 2016-04-15 05:08:08          This is a beautiful two bedroom apartm...   
122952 2016-04-08 04:26:03          This is a beautiful two bedroom apartm...   
123498 2016-04-19 03:38:40          Currently under renovation, this two b...   
123595 2016-04-15 04:08:48          Currently under renovation, this two b...   
123658 2016-04-06 08:10:05          Currently under renovation, this 1 bed...   
14922  2016-06-12 14:00:05          This two bedroom apartment features a ...   
1567   2016-06-12 09:45:58          Currently under renovation, this large...   
17313  2016-06-15 05:47:32          A fabulous one bedroom with all stainl...   
...                    ...                                                ...   
51919  2016-05-18 03:39:40          This delightful studio, one bath apart...   
55590  2016-05-13 05:07:18          Currently under renovation, this STUDI...   
56337  2016-05-15 03:22:12          As you enter this two bedroom apartmen...   
58926  2016-05-19 05:16:00          Currently under renovation, this one b...   
60436  2016-05-18 04:49:43          This is a beautiful garden level one b...   
64838  2016-05-18 04:45:16          This stunning LARGE one bedroom, one b...   
65242  2016-05-20 04:01:07          This is a beautiful Studio apartment w...   
66704  2016-05-20 04:08:46          This is a beautiful Studio apartment w...   
67874  2016-05-11 04:45:31          !Currently under renovation, this one ...   
71325  2016-05-18 04:30:53          This is a beautiful one bedroom apartm...   
73207  2016-05-18 04:10:31          Currently under renovation, this one b...   
74883  2016-05-11 03:22:00          This is a luxury 2 bedroom apartment i...   
76461  2016-05-07 03:58:56          Currently under renovation, this two b...   
78132  2016-05-25 04:20:34          Currently under renovation, this one b...   
79271  2016-05-18 04:25:40          Currently under renovation, this one b...   
79757  2016-05-18 04:40:54          Currently under renovation, this one b...   
81548  2016-05-10 04:23:17          Beautiful 4BR/1.5BA apartment features...   
82066  2016-05-06 04:28:40          Currently under renovation, this two b...   
82670  2016-05-11 04:17:13          Currently under renovation, this one b...   
84647  2016-04-06 18:07:43          Currently under renovation, this 1 bed...   
87878  2016-04-06 07:13:56          This is a beautiful two bedroom apartm...   
90976  2016-04-06 04:52:53          Gorgeous Studio apartment with hardwoo...   
92178  2016-04-12 03:45:13          Currently under renovation, this one b...   
92767  2016-04-06 04:12:28          Currently under renovation, this studi...   
92925  2016-04-15 05:06:04          This is a beautiful 3 bedroom apartmen...   
93205  2016-04-06 05:27:23          Currently under renovation, this one b...   
94233  2016-04-15 03:19:51          This is a beautiful Studio apartment t...   
95817  2016-04-06 05:48:33          This is a beautiful two bedroom apartm...   
96794  2016-04-06 18:10:05          New Listing! Pictures and description ...   
98250  2016-04-15 04:10:25          This is a beautiful 3 bedroom apartmen...   

                 display_address  \
100079        1215 Morris Avenue   
100809      213 St. Ann&#39;s Avenue   
101275       2685 Creston Avenue   
101859        219 E 196th Street   
103970        2140 Cruger Avenue   
104657       2962 Decatur Avenue   
10597           3291 Hull Avenue   
10635     2580 Bainbridge Avenue   
10716                246 E 204th   
109831        1250 Morris Avenue   
110660          2180 Ryer Avenue   
110779            1 W 182 Street   
112927       3204 Holland Avenue   
114744          418 E 134 Street   
11481           3070 Hull Avenue   
114907          367 E 204 Street   
116701          2105 Burr Avenue   
117430      2110 Bronx Park East   
118411     314 East 201st Street   
119313                55 E 190th   
119802      2324 Bathgate Avenue   
120874          3451 Giles Place   
122721         1148 Ogden Avenue   
122952         144 Bruckner Blvd   
123498         1500 Noble Avenue   
123595      2419 Davidson Avenue   
123658        2010 Powell Avenue   
14922       2264 Davidson Avenue   
1567        1560 Grand Concourse   
17313        3030 Middletown Rd.   
...                          ...   
51919           3070 Hull Avenue   
55590      2330 Valentine Avenue   
56337        974 Sheridan Avenue   
58926         975 Sherman Avenue   
60436      413 East 140th Street   
64838   3341 Reservoir Oval West   
65242        2685 Creston Avenue   
66704        2962 Decatur Avenue   
67874       2264 Davidson Avenue   
71325         1494 Watson Avenue   
73207          2045 Story Avenue   
74883        2325 Holland Avenue   
76461        2600 Creston Avenue   
78132       1560 Grand Concourse   
79271         1100 Gerard Avenue   
79757       2110 Bronx Park East   
81548        176 West 225 Street   
82066     1425 University Avenue   
82670             1 W 182 Street   
84647       2894 Grand Concourse   
87878         305-307 East 239th   
90976                 55 E 190th   
92178    3034 Kingsbridge Avenue   
92767         2324 Walton Avenue   
92925     1650 Undercliff Avenue   
93205         3804 Bailey Avenue   
94233         2000 Bruckner Blvd   
95817         305-307 East 239th   
96794          2280 Grand Avenue   
98250     1650 Undercliff Avenue   

                                               features interest_level  \
100079                                               []           high   
100809                                               []           high   
101275                                       [Elevator]           high   
101859                                               []           high   
103970           [Elevator, Cats Allowed, Dogs Allowed]           high   
104657                                       [Elevator]            low   
10597                                                []           high   
10635            [Elevator, Cats Allowed, Dogs Allowed]           high   
10716                      [Cats Allowed, Dogs Allowed]         medium   
109831                                               []           high   
110660                                               []         medium   
110779                                       [Elevator]           high   
112927                                               []           high   
114744                                       [Elevator]         medium   
11481            [Elevator, Cats Allowed, Dogs Allowed]            low   
114907                     [Cats Allowed, Dogs Allowed]         medium   
116701           [Elevator, Cats Allowed, Dogs Allowed]           high   
117430                     [Cats Allowed, Dogs Allowed]         medium   
118411           [Elevator, Cats Allowed, Dogs Allowed]           high   
119313                                       [Elevator]         medium   
119802                     [Cats Allowed, Dogs Allowed]           high   
120874                                               []           high   
122721           [Elevator, Cats Allowed, Dogs Allowed]         medium   
122952             [No Fee, Cats Allowed, Dogs Allowed]           high   
123498  [Doorman, Elevator, Cats Allowed, Dogs Allowed]           high   
123595                                               []           high   
123658                     [Cats Allowed, Dogs Allowed]           high   
14922                                                []           high   
1567                                         [Elevator]         medium   
17313                        [Elevator, Fitness Center]           high   
...                                                 ...            ...   
51919            [Elevator, Cats Allowed, Dogs Allowed]         medium   
55590                                        [Elevator]           high   
56337                                                []           high   
58926                                                []           high   
60436                      [Cats Allowed, Dogs Allowed]           high   
64838                                                []           high   
65242                                        [Elevator]            low   
66704                                        [Elevator]           high   
67874                                                []         medium   
71325                      [Cats Allowed, Dogs Allowed]         medium   
73207            [Elevator, Cats Allowed, Dogs Allowed]           high   
74883                                                []           high   
76461                      [Cats Allowed, Dogs Allowed]           high   
78132                                        [Elevator]            low   
79271            [Elevator, Cats Allowed, Dogs Allowed]         medium   
79757                                                []         medium   
81548                                                []         medium   
82066                                                []         medium   
82670                                        [Elevator]           high   
84647                                                []           high   
87878                                                []           high   
90976                                        [Elevator]           high   
92178                                                []           high   
92767                                        [Elevator]           high   
92925            [Elevator, Cats Allowed, Dogs Allowed]            low   
93205                                                []         medium   
94233            [Elevator, Cats Allowed, Dogs Allowed]           high   
95817                                                []         medium   
96794                                                []           high   
98250            [Elevator, Cats Allowed, Dogs Allowed]            low   

        latitude  listing_id     ...       apt_feature_cats  \
100079   40.8335     6907079     ...                    0.0   
100809   40.8064     6947346     ...                    0.0   
101275   40.8676     6832401     ...                    0.0   
101859   40.8676     6876669     ...                    0.0   
103970   40.8548     6900539     ...                    1.0   
104657   40.8683     6878187     ...                    0.0   
10597    40.8767     7130690     ...                    0.0   
10635    40.8635     7205093     ...                    1.0   
10716    40.8741     7147899     ...                    1.0   
109831   40.8343     6877697     ...                    0.0   
110660   40.8549     6946759     ...                    0.0   
110779   40.8574     6843255     ...                    0.0   
112927   40.8719     6916038     ...                    0.0   
114744   40.8060     6843126     ...                    0.0   
11481    40.8718     7152163     ...                    1.0   
114907   40.8717     6833106     ...                    1.0   
116701   40.8549     6835321     ...                    1.0   
117430   40.8539     6894303     ...                    1.0   
118411   40.8707     6905758     ...                    1.0   
119313   40.8634     6831123     ...                    0.0   
119802   40.8552     6832326     ...                    1.0   
120874   40.8814     6866598     ...                    0.0   
122721   40.8366     6878045     ...                    1.0   
122952   40.8035     6843763     ...                    1.0   
123498   40.8371     6894147     ...                    1.0   
123595   40.8622     6877154     ...                    0.0   
123658   40.8302     6834260     ...                    1.0   
14922    40.8585     7152862     ...                    0.0   
1567     40.8427     7148577     ...                    0.0   
17313    40.8441     7164398     ...                    0.0   
...          ...         ...     ...                    ...   
51919    40.8718     7029317     ...                    1.0   
55590    40.8576     7007184     ...                    0.0   
56337    40.8290     7016255     ...                    0.0   
58926    40.8289     7038516     ...                    0.0   
60436    40.8103     7030077     ...                    1.0   
64838    40.8786     7030040     ...                    0.0   
65242    40.8676     7042593     ...                    0.0   
66704    40.8683     7042688     ...                    0.0   
67874    40.8585     6995385     ...                    0.0   
71325    40.8257     7029926     ...                    1.0   
73207    40.8253     7029715     ...                    1.0   
74883    40.8605     6994255     ...                    0.0   
76461    40.8652     6979801     ...                    1.0   
78132    40.8427     7064173     ...                    0.0   
79271    40.8330     7029897     ...                    1.0   
79757    40.8539     7029982     ...                    0.0   
81548    40.8759     6990265     ...                    0.0   
82066    40.8435     6974636     ...                    0.0   
82670    40.8574     6994990     ...                    0.0   
84647    40.8706     6835017     ...                    0.0   
87878    40.9019     6833131     ...                    0.0   
90976    40.8634     6831011     ...                    0.0   
92178    40.8790     6859521     ...                    0.0   
92767    40.8591     6830431     ...                    0.0   
92925    40.8497     6878027     ...                    1.0   
93205    40.8841     6831293     ...                    0.0   
94233    40.8260     6876481     ...                    1.0   
95817    40.9019     6831615     ...                    0.0   
96794    40.8591     6835078     ...                    0.0   
98250    40.8497     6877194     ...                    1.0   

       apt_feature_hardwood apt_feature_dogs  apt_feature_doorman  \
100079                  0.0              0.0                  0.0   
100809                  0.0              0.0                  0.0   
101275                  0.0              0.0                  0.0   
101859                  0.0              0.0                  0.0   
103970                  0.0              1.0                  0.0   
104657                  0.0              0.0                  0.0   
10597                   0.0              0.0                  0.0   
10635                   0.0              1.0                  0.0   
10716                   0.0              1.0                  0.0   
109831                  0.0              0.0                  0.0   
110660                  0.0              0.0                  0.0   
110779                  0.0              0.0                  0.0   
112927                  0.0              0.0                  0.0   
114744                  0.0              0.0                  0.0   
11481                   0.0              1.0                  0.0   
114907                  0.0              1.0                  0.0   
116701                  0.0              1.0                  0.0   
117430                  0.0              1.0                  0.0   
118411                  0.0              1.0                  0.0   
119313                  0.0              0.0                  0.0   
119802                  0.0              1.0                  0.0   
120874                  0.0              0.0                  0.0   
122721                  0.0              1.0                  0.0   
122952                  0.0              1.0                  0.0   
123498                  0.0              1.0                  1.0   
123595                  0.0              0.0                  0.0   
123658                  0.0              1.0                  0.0   
14922                   0.0              0.0                  0.0   
1567                    0.0              0.0                  0.0   
17313                   0.0              0.0                  0.0   
...                     ...              ...                  ...   
51919                   0.0              1.0                  0.0   
55590                   0.0              0.0                  0.0   
56337                   0.0              0.0                  0.0   
58926                   0.0              0.0                  0.0   
60436                   0.0              1.0                  0.0   
64838                   0.0              0.0                  0.0   
65242                   0.0              0.0                  0.0   
66704                   0.0              0.0                  0.0   
67874                   0.0              0.0                  0.0   
71325                   0.0              1.0                  0.0   
73207                   0.0              1.0                  0.0   
74883                   0.0              0.0                  0.0   
76461                   0.0              1.0                  0.0   
78132                   0.0              0.0                  0.0   
79271                   0.0              1.0                  0.0   
79757                   0.0              0.0                  0.0   
81548                   0.0              0.0                  0.0   
82066                   0.0              0.0                  0.0   
82670                   0.0              0.0                  0.0   
84647                   0.0              0.0                  0.0   
87878                   0.0              0.0                  0.0   
90976                   0.0              0.0                  0.0   
92178                   0.0              0.0                  0.0   
92767                   0.0              0.0                  0.0   
92925                   0.0              1.0                  0.0   
93205                   0.0              0.0                  0.0   
94233                   0.0              1.0                  0.0   
95817                   0.0              0.0                  0.0   
96794                   0.0              0.0                  0.0   
98250                   0.0              1.0                  0.0   

       apt_feature_dishwasher  apt_feature_no fee  apt_feature_laundry  \
100079                    0.0                 0.0                  0.0   
100809                    0.0                 0.0                  0.0   
101275                    0.0                 0.0                  0.0   
101859                    0.0                 0.0                  0.0   
103970                    0.0                 0.0                  0.0   
104657                    0.0                 0.0                  0.0   
10597                     0.0                 0.0                  0.0   
10635                     0.0                 0.0                  0.0   
10716                     0.0                 0.0                  0.0   
109831                    0.0                 0.0                  0.0   
110660                    0.0                 0.0                  0.0   
110779                    0.0                 0.0                  0.0   
112927                    0.0                 0.0                  0.0   
114744                    0.0                 0.0                  0.0   
11481                     0.0                 0.0                  0.0   
114907                    0.0                 0.0                  0.0   
116701                    0.0                 0.0                  0.0   
117430                    0.0                 0.0                  0.0   
118411                    0.0                 0.0                  0.0   
119313                    0.0                 0.0                  0.0   
119802                    0.0                 0.0                  0.0   
120874                    0.0                 0.0                  0.0   
122721                    0.0                 0.0                  0.0   
122952                    0.0                 1.0                  0.0   
123498                    0.0                 0.0                  0.0   
123595                    0.0                 0.0                  0.0   
123658                    0.0                 0.0                  0.0   
14922                     0.0                 0.0                  0.0   
1567                      0.0                 0.0                  0.0   
17313                     0.0                 0.0                  0.0   
...                       ...                 ...                  ...   
51919                     0.0                 0.0                  0.0   
55590                     0.0                 0.0                  0.0   
56337                     0.0                 0.0                  0.0   
58926                     0.0                 0.0                  0.0   
60436                     0.0                 0.0                  0.0   
64838                     0.0                 0.0                  0.0   
65242                     0.0                 0.0                  0.0   
66704                     0.0                 0.0                  0.0   
67874                     0.0                 0.0                  0.0   
71325                     0.0                 0.0                  0.0   
73207                     0.0                 0.0                  0.0   
74883                     0.0                 0.0                  0.0   
76461                     0.0                 0.0                  0.0   
78132                     0.0                 0.0                  0.0   
79271                     0.0                 0.0                  0.0   
79757                     0.0                 0.0                  0.0   
81548                     0.0                 0.0                  0.0   
82066                     0.0                 0.0                  0.0   
82670                     0.0                 0.0                  0.0   
84647                     0.0                 0.0                  0.0   
87878                     0.0                 0.0                  0.0   
90976                     0.0                 0.0                  0.0   
92178                     0.0                 0.0                  0.0   
92767                     0.0                 0.0                  0.0   
92925                     0.0                 0.0                  0.0   
93205                     0.0                 0.0                  0.0   
94233                     0.0                 0.0                  0.0   
95817                     0.0                 0.0                  0.0   
96794                     0.0                 0.0                  0.0   
98250                     0.0                 0.0                  0.0   

        apt_feature_fitness  apt_feature_pre-war  image_count  
100079                  0.0                  0.0            1  
100809                  0.0                  0.0            1  
101275                  0.0                  0.0            6  
101859                  0.0                  0.0            4  
103970                  0.0                  0.0            1  
104657                  0.0                  0.0            1  
10597                   0.0                  0.0            1  
10635                   0.0                  0.0            5  
10716                   0.0                  0.0            5  
109831                  0.0                  0.0            1  
110660                  0.0                  0.0            1  
110779                  0.0                  0.0            1  
112927                  0.0                  0.0            1  
114744                  0.0                  0.0            5  
11481                   0.0                  0.0            1  
114907                  0.0                  0.0            7  
116701                  0.0                  0.0            3  
117430                  0.0                  0.0            1  
118411                  0.0                  0.0            1  
119313                  0.0                  0.0            8  
119802                  0.0                  0.0            5  
120874                  0.0                  0.0            3  
122721                  0.0                  0.0            1  
122952                  0.0                  0.0            6  
123498                  0.0                  0.0            1  
123595                  0.0                  0.0            1  
123658                  0.0                  0.0            1  
14922                   0.0                  0.0            5  
1567                    0.0                  0.0            1  
17313                   1.0                  0.0            8  
...                     ...                  ...          ...  
51919                   0.0                  0.0            4  
55590                   0.0                  0.0            5  
56337                   0.0                  0.0            6  
58926                   0.0                  0.0            1  
60436                   0.0                  0.0            9  
64838                   0.0                  0.0            5  
65242                   0.0                  0.0            1  
66704                   0.0                  0.0            4  
67874                   0.0                  0.0            1  
71325                   0.0                  0.0            1  
73207                   0.0                  0.0            1  
74883                   0.0                  0.0            9  
76461                   0.0                  0.0            1  
78132                   0.0                  0.0            1  
79271                   0.0                  0.0            1  
79757                   0.0                  0.0            1  
81548                   0.0                  0.0            7  
82066                   0.0                  0.0            1  
82670                   0.0                  0.0            5  
84647                   0.0                  0.0            1  
87878                   0.0                  0.0            7  
90976                   0.0                  0.0            6  
92178                   0.0                  0.0            1  
92767                   0.0                  0.0            1  
92925                   0.0                  0.0            1  
93205                   0.0                  0.0            1  
94233                   0.0                  0.0            1  
95817                   0.0                  0.0            8  
96794                   0.0                  0.0            1  
98250                   0.0                  0.0            1  

[91 rows x 35 columns]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[99]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">count</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;building_id&#39;</span><span class="p">])</span>
<span class="n">df_building</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">count</span><span class="p">,</span> <span class="n">orient</span><span class="o">=</span><span class="s1">&#39;index&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">df_building</span> <span class="o">=</span> <span class="n">df_building</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;index&#39;</span><span class="p">:</span><span class="s1">&#39;building_id&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="s1">&#39;count&#39;</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_building</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>             count
count  7585.000000
mean      6.506526
std      95.982172
min       1.000000
25%       1.000000
50%       2.000000
75%       4.000000
max    8286.000000
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[100]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">low_count</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">medium_count</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">high_count</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">df_temp</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span> <span class="p">{</span><span class="s1">&#39;building_id&#39;</span><span class="p">:</span> <span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;building_id&#39;</span><span class="p">],</span><span class="s1">&#39;interest_level&#39;</span><span class="p">:</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]})</span>

<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">df_building</span><span class="p">[</span><span class="s1">&#39;building_id&#39;</span><span class="p">]:</span>
    <span class="n">subset</span> <span class="o">=</span> <span class="n">df_temp</span><span class="p">[(</span><span class="n">df_temp</span><span class="p">[</span><span class="s1">&#39;building_id&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">x</span><span class="p">)]</span>
    <span class="n">low_count</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">subset</span><span class="p">[</span><span class="n">subset</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;low&#39;</span><span class="p">]))</span>
    <span class="n">medium_count</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">subset</span><span class="p">[</span><span class="n">subset</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;medium&#39;</span><span class="p">]))</span>
    <span class="n">high_count</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">subset</span><span class="p">[</span><span class="n">subset</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;high&#39;</span><span class="p">]))</span>
    
<span class="n">df_building</span><span class="p">[</span><span class="s1">&#39;low_count&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">low_count</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="n">df_building</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">df_building</span><span class="p">[</span><span class="s1">&#39;medium_count&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">medium_count</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="n">df_building</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">df_building</span><span class="p">[</span><span class="s1">&#39;high_count&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">high_count</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="n">df_building</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>

<span class="n">df_building</span> <span class="o">=</span> <span class="n">df_building</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span> <span class="s1">&#39;count&#39;</span><span class="p">:</span><span class="s1">&#39;building_count&#39;</span><span class="p">,</span> <span class="s1">&#39;low_count&#39;</span><span class="p">:</span><span class="s1">&#39;building_low&#39;</span><span class="p">,</span><span class="s1">&#39;medium_count&#39;</span><span class="p">:</span><span class="s1">&#39;building_medium&#39;</span>
                          <span class="p">,</span><span class="s1">&#39;high_count&#39;</span><span class="p">:</span><span class="s1">&#39;building_high&#39;</span><span class="p">})</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[101]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_building</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt output_prompt">Out[101]:</div>

<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>building_id</th>
      <th>building_count</th>
      <th>building_low</th>
      <th>building_medium</th>
      <th>building_high</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>8fe78423f414e06b9c9ea3dca908cbf7</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>539c0e594529c138692772e44208992a</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>498df36f2cbe93ffbd6bd9320ecdb4eb</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>28c347c30620314c523b6716e4f387fb</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>e08fdf2850ac74107be94c1760432bde</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[103]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#add data to df_raw</span>
<span class="n">df_raw</span> <span class="o">=</span> <span class="n">df_raw</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df_manager</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;manager_id&#39;</span><span class="p">),</span><span class="n">on</span><span class="o">=</span><span class="s1">&#39;manager_id&#39;</span><span class="p">)</span>
<span class="n">df_raw</span> <span class="o">=</span> <span class="n">df_raw</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df_building</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;building_id&#39;</span><span class="p">),</span><span class="n">on</span><span class="o">=</span><span class="s1">&#39;building_id&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[105]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#df_raw.columns.values</span>
<span class="c1">#df_raw.head()</span>
<span class="c1">#df_raw.describe()</span>
<span class="c1">#df_raw[&#39;features_count&#39;].describe()</span>
<span class="c1">#df_raw.to_pickle(&quot;train_checkpoint_16&quot;)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For each row, have to remove the predictor for that row or the model will overfit. Ie for a manager with only 1 entry, the manager_low/medium/high tells the model what the answer is going to be so for each row need to remove the answer for that row.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[106]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">row_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;manager_id&#39;</span><span class="p">])</span>
<span class="c1">#print( df_raw.get_value(df_raw.index[0],&#39;manager_count&#39;))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">row_length</span><span class="p">):</span>
    <span class="n">interest_level</span> <span class="o">=</span> <span class="n">df_raw</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="n">df_raw</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="s1">&#39;interest_level&#39;</span><span class="p">)</span>
    <span class="n">temp_string</span> <span class="o">=</span> <span class="s1">&#39;manager_&#39;</span> <span class="o">+</span> <span class="n">interest_level</span>
    <span class="c1">#print(df_raw.get_value(df_raw.index[i],&#39;manager_count&#39;),df_raw.get_value(df_raw.index[i],temp_string))</span>
    <span class="n">z1</span> <span class="o">=</span> <span class="n">df_raw</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="n">df_raw</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="s1">&#39;manager_count&#39;</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">df_raw</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="n">df_raw</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="s1">&#39;manager_count&#39;</span><span class="p">,</span><span class="n">z1</span><span class="p">)</span>
    <span class="n">z2</span> <span class="o">=</span> <span class="n">df_raw</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="n">df_raw</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">temp_string</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">df_raw</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="n">df_raw</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">temp_string</span><span class="p">,</span><span class="n">z2</span><span class="p">)</span>    
    <span class="c1">#print(df_raw.get_value(df_raw.index[i],&#39;manager_count&#39;),df_raw.get_value(df_raw.index[i],temp_string))</span>
    
    <span class="n">temp_string</span> <span class="o">=</span> <span class="s1">&#39;building_&#39;</span> <span class="o">+</span> <span class="n">interest_level</span>
    <span class="n">z1</span> <span class="o">=</span> <span class="n">df_raw</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="n">df_raw</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="s1">&#39;building_count&#39;</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">df_raw</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="n">df_raw</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="s1">&#39;building_count&#39;</span><span class="p">,</span><span class="n">z1</span><span class="p">)</span>
    <span class="n">z2</span> <span class="o">=</span> <span class="n">df_raw</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="n">df_raw</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">temp_string</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">df_raw</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="n">df_raw</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">temp_string</span><span class="p">,</span><span class="n">z2</span><span class="p">)</span> 
    <span class="c1">#break</span>
   
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[108]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#df_raw.columns.values</span>
<span class="c1">#df_raw.head()</span>
<span class="c1">#df_raw.describe()</span>
<span class="c1">#df_raw[&#39;features_count&#39;].describe()</span>
<span class="c1">#df_raw.to_pickle(&quot;train_checkpoint_18&quot;)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="1.9-Photos">1.9 Photos<a class="anchor-link" href="#1.9-Photos">&#182;</a></h3><p>Around 70 Gb of photo data is available for the listings. The data is stored in a directory arranged by each listing_id. I created a feature that has the number of photos for each listing.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[114]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#sample code for creating the dictionary of counts</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pickle</span>

<span class="n">base_directory</span> <span class="o">=</span> <span class="s1">&#39;.../Kaggle_renthop_images/images&#39;</span> <span class="c1">#not actual directory</span>
<span class="n">image_list</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span> <span class="n">base_directory</span><span class="p">)</span>

<span class="n">image_dict</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">image_list</span><span class="p">:</span>
    
    <span class="n">sub_directory</span> <span class="o">=</span> <span class="n">base_directory</span> <span class="o">+</span> <span class="s2">&quot;/&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">sub_directory</span><span class="p">):</span>
        <span class="n">image_dict</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">sub_directory</span><span class="p">))</span>
        
<span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span> <span class="n">image_dict</span><span class="p">,</span> <span class="nb">open</span><span class="p">(</span> <span class="s2">&quot;image_count_dict.p&quot;</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span> <span class="p">)</span> <span class="p">)</span> <span class="c1">#save it with pickle since will want it for test data</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyboardInterrupt</span>                         Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-114-abfe6c6f41d7&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">     10</span>     sub_directory <span class="ansi-yellow-intense-fg ansi-bold">=</span> base_directory <span class="ansi-yellow-intense-fg ansi-bold">+</span> <span class="ansi-blue-intense-fg ansi-bold">&#34;/&#34;</span> <span class="ansi-yellow-intense-fg ansi-bold">+</span> str<span class="ansi-yellow-intense-fg ansi-bold">(</span>x<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-intense-fg ansi-bold">     11</span>     <span class="ansi-green-intense-fg ansi-bold">if</span> os<span class="ansi-yellow-intense-fg ansi-bold">.</span>path<span class="ansi-yellow-intense-fg ansi-bold">.</span>isdir<span class="ansi-yellow-intense-fg ansi-bold">(</span>sub_directory<span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-fg">---&gt; 12</span><span class="ansi-red-fg">         </span>image_dict<span class="ansi-yellow-intense-fg ansi-bold">[</span>x<span class="ansi-yellow-intense-fg ansi-bold">]</span> <span class="ansi-yellow-intense-fg ansi-bold">=</span> len<span class="ansi-yellow-intense-fg ansi-bold">(</span> os<span class="ansi-yellow-intense-fg ansi-bold">.</span>listdir<span class="ansi-yellow-intense-fg ansi-bold">(</span>sub_directory<span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-intense-fg ansi-bold">     13</span> 
<span class="ansi-green-intense-fg ansi-bold">     14</span> pickle<span class="ansi-yellow-intense-fg ansi-bold">.</span>dump<span class="ansi-yellow-intense-fg ansi-bold">(</span> image_dict<span class="ansi-yellow-intense-fg ansi-bold">,</span> open<span class="ansi-yellow-intense-fg ansi-bold">(</span> <span class="ansi-blue-intense-fg ansi-bold">&#34;image_count_dict.p&#34;</span><span class="ansi-yellow-intense-fg ansi-bold">,</span> <span class="ansi-blue-intense-fg ansi-bold">&#34;wb&#34;</span> <span class="ansi-yellow-intense-fg ansi-bold">)</span> <span class="ansi-yellow-intense-fg ansi-bold">)</span> <span class="ansi-red-intense-fg ansi-bold">#save it with pickle since will want it for test data</span>

<span class="ansi-red-fg">KeyboardInterrupt</span>: </pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[220]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pickle</span>
<span class="n">image_dict</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span> <span class="nb">open</span><span class="p">(</span> <span class="s2">&quot;image_count_dict.p&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span> <span class="p">)</span> <span class="p">)</span>

<span class="n">image_count</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;listing_id&#39;</span><span class="p">]:</span>
    <span class="n">y</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">image_dict</span><span class="p">:</span>
        <span class="n">image_count</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">image_dict</span><span class="p">[</span><span class="n">y</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">image_count</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    
<span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;image_count&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">image_count</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="n">df_raw</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;image_count&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;image_count&#39;</span><span class="p">],</span><span class="mi">20</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">40</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>count    49352.000000
mean         5.612680
std          3.633711
min          0.000000
25%          4.000000
50%          5.000000
75%          7.000000
max         68.000000
Name: image_count, dtype: float64
</pre>
</div>
</div>

<div class="output_area"><div class="prompt"></div>


<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[227]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">benchmark_dict</span><span class="p">)</span>
<span class="n">g1</span> <span class="o">=</span> <span class="n">df_raw</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;image_count&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">agg</span><span class="p">({</span><span class="s1">&#39;image_count&#39;</span><span class="p">:</span> <span class="s1">&#39;count&#39;</span><span class="p">})</span>
<span class="n">g2</span> <span class="o">=</span> <span class="n">df_raw</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;image_count&#39;</span><span class="p">,</span> <span class="s1">&#39;interest_level&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">agg</span><span class="p">({</span><span class="s1">&#39;image_count&#39;</span><span class="p">:</span> <span class="s1">&#39;count&#39;</span><span class="p">})</span>
<span class="n">g3</span> <span class="o">=</span> <span class="n">g2</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="mi">100</span> <span class="o">*</span> <span class="n">x</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">sum</span><span class="p">()))</span>
<span class="c1">#print(g1.to_string())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">g3</span><span class="o">.</span><span class="n">to_string</span><span class="p">())</span>
<span class="c1">#print(g2.to_string())</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>{&#39;medium&#39;: 0.22752877289674178, &#39;low&#39;: 0.6946830928837737, &#39;high&#39;: 0.07778813421948452}
                            image_count
image_count interest_level             
0           high               1.385809
            low               95.205100
            medium             3.409091
1           high               6.785411
            low               80.067854
            medium            13.146735
2           high               8.051166
            low               76.072235
            medium            15.876599
3           high               8.715697
            low               67.881449
            medium            23.402854
4           high               7.793033
            low               66.272565
            medium            25.934401
5           high               9.584481
            low               64.118457
            medium            26.297062
6           high               8.517913
            low               65.274268
            medium            26.207819
7           high               7.850242
            low               66.163446
            medium            25.986312
8           high               7.934919
            low               66.958698
            medium            25.106383
9           high               7.955182
            low               70.588235
            medium            21.456583
10          high               7.741935
            low               70.250896
            medium            22.007168
11          high               7.633588
            low               70.737913
            medium            21.628499
12          high               8.700980
            low               69.240196
            medium            22.058824
13          high              14.323607
            low               63.925729
            medium            21.750663
14          high               7.296137
            low               74.678112
            medium            18.025751
15          high               4.020101
            low               77.386935
            medium            18.592965
16          high               1.948052
            low               85.714286
            medium            12.337662
17          high               4.629630
            low               82.407407
            medium            12.962963
18          high               4.464286
            low               75.892857
            medium            19.642857
19          high               3.846154
            low               80.769231
            medium            15.384615
20          high               1.111111
            low               85.555556
            medium            13.333333
21          low               90.476190
            medium             9.523810
22          low              100.000000
23          low               81.250000
            medium            18.750000
24          low               93.750000
            medium             6.250000
25          low               94.117647
            medium             5.882353
26          high               5.263158
            low               89.473684
            medium             5.263158
27          low              100.000000
28          low               81.818182
            medium            18.181818
29          low              100.000000
30          low              100.000000
31          low              100.000000
32          low              100.000000
33          low              100.000000
34          low              100.000000
35          low              100.000000
36          low              100.000000
37          low              100.000000
38          low              100.000000
43          low              100.000000
44          low              100.000000
45          low              100.000000
46          low              100.000000
50          low              100.000000
60          low              100.000000
68          low              100.000000
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[111]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#df_raw.columns.values</span>
<span class="c1">#df_raw.head()</span>
<span class="c1">#df_raw.describe()</span>
<span class="c1">#df_raw[&#39;features_count&#39;].describe()</span>
<span class="n">df_raw</span><span class="o">.</span><span class="n">to_pickle</span><span class="p">(</span><span class="s2">&quot;train_checkpoint_19&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="1.10-Latitude-and-Longitude">1.10 Latitude and Longitude<a class="anchor-link" href="#1.10-Latitude-and-Longitude">&#182;</a></h3><p>Shows the location of the apartment. An issue with this data is similar to the bathrooms and price dilemma discussed above. Some of the data is obviously wrong but obviously wrong submission have their own predictive value. Like the price data, I decided to limit the extreme outliers into more limited extremes.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[117]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="k">import</span> <span class="n">KMeans</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">loc_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;longitude&#39;</span><span class="p">:</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;longitude&#39;</span><span class="p">],</span><span class="s1">&#39;latitude&#39;</span><span class="p">:</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;latitude&#39;</span><span class="p">]})</span> <span class="c1">#&#39;listing_id&#39;:df_raw[&#39;listing_id&#39;],</span>
<span class="nb">print</span><span class="p">(</span> <span class="n">loc_df</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>

<span class="n">lat_range</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">=</span> <span class="n">loc_df</span><span class="o">.</span><span class="n">describe</span><span class="p">()[</span><span class="s1">&#39;longitude&#39;</span><span class="p">][</span><span class="s1">&#39;25%&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">lat_range</span><span class="p">,</span> <span class="n">loc_df</span><span class="o">.</span><span class="n">describe</span><span class="p">()[</span><span class="s1">&#39;longitude&#39;</span><span class="p">][</span><span class="s1">&#39;75%&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">lat_range</span>
<span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> 	<span class="n">loc_df</span><span class="o">.</span><span class="n">describe</span><span class="p">()[</span><span class="s1">&#39;latitude&#39;</span><span class="p">][</span><span class="s1">&#39;25%&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">lat_range</span><span class="p">,</span> <span class="n">loc_df</span><span class="o">.</span><span class="n">describe</span><span class="p">()[</span><span class="s1">&#39;latitude&#39;</span><span class="p">][</span><span class="s1">&#39;75%&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">lat_range</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Extreme Lat/Long Count of Outliers&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span> <span class="nb">len</span><span class="p">(</span><span class="n">loc_df</span><span class="p">[</span><span class="n">loc_df</span><span class="p">[</span><span class="s1">&#39;longitude&#39;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">x_min</span><span class="p">]</span> <span class="p">))</span>
<span class="nb">print</span><span class="p">(</span> <span class="nb">len</span><span class="p">(</span><span class="n">loc_df</span><span class="p">[</span><span class="n">loc_df</span><span class="p">[</span><span class="s1">&#39;longitude&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">x_max</span><span class="p">]</span> <span class="p">))</span>
<span class="nb">print</span><span class="p">(</span> <span class="nb">len</span><span class="p">(</span><span class="n">loc_df</span><span class="p">[</span><span class="n">loc_df</span><span class="p">[</span><span class="s1">&#39;latitude&#39;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">y_min</span><span class="p">]</span> <span class="p">))</span>
<span class="nb">print</span><span class="p">(</span> <span class="nb">len</span><span class="p">(</span><span class="n">loc_df</span><span class="p">[</span><span class="n">loc_df</span><span class="p">[</span><span class="s1">&#39;latitude&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">y_max</span><span class="p">]</span> <span class="p">))</span>

<span class="n">loc_df</span> <span class="o">=</span> <span class="n">loc_df</span><span class="p">[(</span><span class="n">loc_df</span><span class="p">[</span><span class="s1">&#39;latitude&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">y_min</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">loc_df</span><span class="p">[</span><span class="s1">&#39;latitude&#39;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">y_max</span><span class="p">)</span> <span class="o">&amp;</span> 
                 <span class="p">(</span><span class="n">loc_df</span><span class="p">[</span><span class="s1">&#39;longitude&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">x_min</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">loc_df</span><span class="p">[</span><span class="s1">&#39;longitude&#39;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">x_max</span><span class="p">)</span> <span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Outliers Removed&quot;</span><span class="p">,</span> <span class="n">loc_df</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>           latitude     longitude
count  49352.000000  49352.000000
mean      40.741545    -73.955716
std        0.638535      1.177912
min        0.000000   -118.271000
25%       40.728300    -73.991700
50%       40.751800    -73.977900
75%       40.774300    -73.954800
max       44.883500      0.000000
Extreme Lat/Long Count of Outliers
7
24
13
16
Outliers Removed            latitude     longitude
count  49319.000000  49319.000000
mean      40.750964    -73.972487
std        0.039985      0.030819
min       39.799600    -74.663700
25%       40.728300    -73.991700
50%       40.751800    -73.977900
75%       40.774300    -73.954800
max       41.086800    -73.204000
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In the scatter plot, can mostly see the shape of NYC (hey there's Central Park) and notice the coverage of the five buroughs. Manhattan and Brooklyn are represented the most. Not much of Staten Island is represented.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[26]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">loc_df</span><span class="p">[</span><span class="s1">&#39;longitude&#39;</span><span class="p">],</span><span class="n">loc_df</span><span class="p">[</span><span class="s1">&#39;latitude&#39;</span><span class="p">],</span><span class="s1">&#39;.&#39;</span><span class="p">)</span>
<span class="n">z1</span> <span class="o">=</span> <span class="n">lat_range</span><span class="o">*.</span><span class="mi">85</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">x_min</span> <span class="o">+</span> <span class="n">z1</span><span class="p">,</span><span class="n">x_max</span> <span class="o">-</span><span class="n">z1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">y_min</span> <span class="o">+</span> <span class="n">z1</span><span class="p">,</span><span class="n">y_max</span> <span class="o">-</span><span class="n">z1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>


<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[29]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#fit the model</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">metrics</span>

<span class="n">n_cluster_range</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">15</span><span class="p">,</span><span class="mi">20</span><span class="p">]</span>
<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">n_cluster_range</span><span class="p">:</span>
    <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="n">x</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">loc_df</span><span class="p">)</span>
    <span class="n">kmeans_pred</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">loc_df</span><span class="p">)</span>

    <span class="n">score</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">silhouette_score</span><span class="p">(</span><span class="n">loc_df</span><span class="p">,</span> <span class="n">kmeans_pred</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">,</span><span class="n">sample_size</span><span class="o">=</span><span class="mi">5000</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">score</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>2 0.430142975047
3 0.462536995206
4 0.41993860184
5 0.444590289401
6 0.413698724972
7 0.43568479083
9 0.421432604323
12 0.451194861985
15 0.438334223761
20 0.482186668379
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Choosing 5 as the number of clusters as NYC is divided into 5 buroughs and the silhouette scores are roughly in the same range.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[30]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">loc_df</span><span class="p">)</span>
<span class="n">kmeans_pred</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">loc_df</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[42]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">loc_df</span><span class="p">[</span><span class="s1">&#39;longitude&#39;</span><span class="p">],</span><span class="n">loc_df</span><span class="p">[</span><span class="s1">&#39;latitude&#39;</span><span class="p">],</span><span class="n">c</span><span class="o">=</span><span class="n">kmeans_pred</span><span class="p">)</span>
<span class="c1">#plt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1]) #,marker=&#39;D&#39;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>


<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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=
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Plots by interest level.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[44]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">constant_offset</span> <span class="o">=</span> <span class="mf">0.09</span>
<span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">=</span> 	<span class="n">loc_df</span><span class="o">.</span><span class="n">describe</span><span class="p">()[</span><span class="s1">&#39;longitude&#39;</span><span class="p">][</span><span class="s1">&#39;25%&#39;</span><span class="p">]</span><span class="o">-</span><span class="n">constant_offset</span><span class="p">,</span> <span class="n">loc_df</span><span class="o">.</span><span class="n">describe</span><span class="p">()[</span><span class="s1">&#39;longitude&#39;</span><span class="p">][</span><span class="s1">&#39;75%&#39;</span><span class="p">]</span><span class="o">+</span><span class="n">constant_offset</span>
<span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="n">loc_df</span><span class="o">.</span><span class="n">describe</span><span class="p">()[</span><span class="s1">&#39;latitude&#39;</span><span class="p">][</span><span class="s1">&#39;25%&#39;</span><span class="p">]</span><span class="o">-</span><span class="n">constant_offset</span><span class="p">,</span> <span class="n">loc_df</span><span class="o">.</span><span class="n">describe</span><span class="p">()[</span><span class="s1">&#39;latitude&#39;</span><span class="p">][</span><span class="s1">&#39;75%&#39;</span><span class="p">]</span><span class="o">+</span><span class="n">constant_offset</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;longitude&#39;</span><span class="p">][</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;low&quot;</span><span class="p">],</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;latitude&#39;</span><span class="p">][</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;low&quot;</span><span class="p">],</span><span class="s1">&#39;.&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">x_min</span><span class="p">,</span><span class="n">x_max</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">y_min</span><span class="p">,</span><span class="n">y_max</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;longitude&#39;</span><span class="p">][</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;medium&quot;</span><span class="p">],</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;latitude&#39;</span><span class="p">][</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;medium&quot;</span><span class="p">],</span><span class="s1">&#39;.&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">x_min</span><span class="p">,</span><span class="n">x_max</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">y_min</span><span class="p">,</span><span class="n">y_max</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;longitude&#39;</span><span class="p">][</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;high&quot;</span><span class="p">],</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;latitude&#39;</span><span class="p">][</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;high&quot;</span><span class="p">],</span><span class="s1">&#39;.&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">x_min</span><span class="p">,</span><span class="n">x_max</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">y_min</span><span class="p">,</span><span class="n">y_max</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>


<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

<div class="output_area"><div class="prompt"></div>


<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

<div class="output_area"><div class="prompt"></div>


<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Some heatmaps. First by interest_level and then by price_per_bed. Heatmap code from <a href="https://pythonspot.com/en/generate-heatmap-in-matplotlib/">https://pythonspot.com/en/generate-heatmap-in-matplotlib/</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[45]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">numpy.random</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
 
<span class="n">constant_offset</span> <span class="o">=</span> <span class="mf">0.01</span><span class="c1">#0.05</span>
<span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">=</span> <span class="n">loc_df</span><span class="o">.</span><span class="n">describe</span><span class="p">()[</span><span class="s1">&#39;longitude&#39;</span><span class="p">][</span><span class="s1">&#39;25%&#39;</span><span class="p">]</span><span class="o">-</span><span class="n">constant_offset</span><span class="p">,</span> <span class="n">loc_df</span><span class="o">.</span><span class="n">describe</span><span class="p">()[</span><span class="s1">&#39;longitude&#39;</span><span class="p">][</span><span class="s1">&#39;75%&#39;</span><span class="p">]</span><span class="o">+</span><span class="n">constant_offset</span>
<span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="n">loc_df</span><span class="o">.</span><span class="n">describe</span><span class="p">()[</span><span class="s1">&#39;latitude&#39;</span><span class="p">][</span><span class="s1">&#39;25%&#39;</span><span class="p">]</span><span class="o">-</span><span class="n">constant_offset</span><span class="p">,</span> <span class="n">loc_df</span><span class="o">.</span><span class="n">describe</span><span class="p">()[</span><span class="s1">&#39;latitude&#39;</span><span class="p">][</span><span class="s1">&#39;75%&#39;</span><span class="p">]</span><span class="o">+</span><span class="n">constant_offset</span>


<span class="n">loc_df2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;longitude&#39;</span><span class="p">:</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;longitude&#39;</span><span class="p">],</span><span class="s1">&#39;latitude&#39;</span><span class="p">:</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;latitude&#39;</span><span class="p">],</span><span class="s1">&#39;interest_level&#39;</span><span class="p">:</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]})</span> 
<span class="n">loc_df2</span> <span class="o">=</span> <span class="n">loc_df2</span><span class="p">[(</span><span class="n">loc_df2</span><span class="p">[</span><span class="s1">&#39;latitude&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">y_min</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">loc_df2</span><span class="p">[</span><span class="s1">&#39;latitude&#39;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">y_max</span><span class="p">)</span> <span class="o">&amp;</span> 
                 <span class="p">(</span><span class="n">loc_df2</span><span class="p">[</span><span class="s1">&#39;longitude&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">x_min</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">loc_df2</span><span class="p">[</span><span class="s1">&#39;longitude&#39;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">x_max</span><span class="p">)</span> <span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">loc_df2</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
<span class="c1"># Create heatmap</span>
<span class="n">bin_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">heatmap</span><span class="p">,</span> <span class="n">xedges</span><span class="p">,</span> <span class="n">yedges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram2d</span><span class="p">(</span><span class="n">loc_df2</span><span class="p">[</span><span class="s1">&#39;longitude&#39;</span><span class="p">][</span><span class="n">loc_df2</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;low&quot;</span><span class="p">],</span> <span class="n">loc_df2</span><span class="p">[</span><span class="s1">&#39;latitude&#39;</span><span class="p">][</span><span class="n">loc_df2</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;low&quot;</span><span class="p">]</span> <span class="p">,</span> 
                                          <span class="n">bins</span><span class="o">=</span><span class="p">(</span><span class="n">bin_size</span><span class="p">,</span><span class="n">bin_size</span><span class="p">))</span>
<span class="n">heatmap2</span><span class="p">,</span> <span class="n">xedges</span><span class="p">,</span> <span class="n">yedges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram2d</span><span class="p">(</span><span class="n">loc_df2</span><span class="p">[</span><span class="s1">&#39;longitude&#39;</span><span class="p">][</span><span class="n">loc_df2</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;medium&quot;</span><span class="p">],</span> <span class="n">loc_df2</span><span class="p">[</span><span class="s1">&#39;latitude&#39;</span><span class="p">][</span><span class="n">loc_df2</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;medium&quot;</span><span class="p">]</span> <span class="p">,</span> 
                                         <span class="n">bins</span><span class="o">=</span><span class="p">(</span><span class="n">bin_size</span><span class="p">,</span><span class="n">bin_size</span><span class="p">))</span>
<span class="n">heatmap3</span><span class="p">,</span> <span class="n">xedges</span><span class="p">,</span> <span class="n">yedges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram2d</span><span class="p">(</span><span class="n">loc_df2</span><span class="p">[</span><span class="s1">&#39;longitude&#39;</span><span class="p">][</span><span class="n">loc_df2</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;high&quot;</span><span class="p">],</span><span class="n">loc_df2</span><span class="p">[</span><span class="s1">&#39;latitude&#39;</span><span class="p">][</span><span class="n">loc_df2</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;high&quot;</span><span class="p">]</span> <span class="p">,</span> 
                                          <span class="n">bins</span><span class="o">=</span><span class="p">(</span><span class="n">bin_size</span><span class="p">,</span><span class="n">bin_size</span><span class="p">))</span>

<span class="n">extent</span> <span class="o">=</span> <span class="p">[</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">]</span>
 
<span class="c1"># Plot heatmap</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">clf</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">heatmap</span><span class="p">,</span> <span class="n">extent</span><span class="o">=</span><span class="n">extent</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">heatmap2</span><span class="p">,</span> <span class="n">extent</span><span class="o">=</span><span class="n">extent</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">heatmap3</span><span class="p">,</span> <span class="n">extent</span><span class="o">=</span><span class="n">extent</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>       interest_level  latitude  longitude
100007            low   40.7539   -73.9677
100020            low   40.7427   -73.9957
100027            low   40.7278   -73.9808
100030            low   40.7769   -73.9467
100044           high   40.7488   -73.9770
</pre>
</div>
</div>

<div class="output_area"><div class="prompt"></div>


<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPEAAAD8CAYAAACmVULXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

<div class="output_area"><div class="prompt"></div>


<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPEAAAD8CAYAAACmVULXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

<div class="output_area"><div class="prompt"></div>


<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPEAAAD8CAYAAACmVULXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[120]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">numpy.random</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
 
<span class="n">constant_offset</span> <span class="o">=</span> <span class="mf">0.01</span><span class="c1">#0.05</span>
<span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">=</span> <span class="n">loc_df</span><span class="o">.</span><span class="n">describe</span><span class="p">()[</span><span class="s1">&#39;longitude&#39;</span><span class="p">][</span><span class="s1">&#39;25%&#39;</span><span class="p">]</span><span class="o">-</span><span class="n">constant_offset</span><span class="p">,</span> <span class="n">loc_df</span><span class="o">.</span><span class="n">describe</span><span class="p">()[</span><span class="s1">&#39;longitude&#39;</span><span class="p">][</span><span class="s1">&#39;75%&#39;</span><span class="p">]</span><span class="o">+</span><span class="n">constant_offset</span>
<span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="n">loc_df</span><span class="o">.</span><span class="n">describe</span><span class="p">()[</span><span class="s1">&#39;latitude&#39;</span><span class="p">][</span><span class="s1">&#39;25%&#39;</span><span class="p">]</span><span class="o">-</span><span class="n">constant_offset</span><span class="p">,</span> <span class="n">loc_df</span><span class="o">.</span><span class="n">describe</span><span class="p">()[</span><span class="s1">&#39;latitude&#39;</span><span class="p">][</span><span class="s1">&#39;75%&#39;</span><span class="p">]</span><span class="o">+</span><span class="n">constant_offset</span>

<span class="c1"># Create data</span>
<span class="n">loc_df3</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;longitude&#39;</span><span class="p">:</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;longitude&#39;</span><span class="p">],</span><span class="s1">&#39;latitude&#39;</span><span class="p">:</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;latitude&#39;</span><span class="p">],</span><span class="s1">&#39;per_bedroom&#39;</span><span class="p">:</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;price_per_bed&#39;</span><span class="p">]})</span> 
<span class="n">loc_df3</span> <span class="o">=</span> <span class="n">loc_df3</span><span class="p">[(</span><span class="n">loc_df3</span><span class="p">[</span><span class="s1">&#39;latitude&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">y_min</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">loc_df3</span><span class="p">[</span><span class="s1">&#39;latitude&#39;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">y_max</span><span class="p">)</span> <span class="o">&amp;</span> 
                 <span class="p">(</span><span class="n">loc_df3</span><span class="p">[</span><span class="s1">&#39;longitude&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">x_min</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">loc_df3</span><span class="p">[</span><span class="s1">&#39;longitude&#39;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">x_max</span><span class="p">)</span> <span class="p">]</span>


<span class="c1"># Create heatmap</span>
<span class="n">bin_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">per_bedroom_median</span> <span class="o">=</span> <span class="n">loc_df3</span><span class="p">[</span><span class="s1">&#39;per_bedroom&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">median</span><span class="p">()</span>
<span class="n">per_bedroom_min</span> <span class="o">=</span> <span class="n">per_bedroom_median</span> <span class="o">-</span> <span class="n">loc_df3</span><span class="o">.</span><span class="n">describe</span><span class="p">()[</span><span class="s1">&#39;per_bedroom&#39;</span><span class="p">][</span><span class="s1">&#39;25%&#39;</span><span class="p">]</span>
<span class="n">per_bedroom_max</span> <span class="o">=</span> <span class="n">per_bedroom_median</span> <span class="o">+</span> <span class="n">loc_df3</span><span class="o">.</span><span class="n">describe</span><span class="p">()[</span><span class="s1">&#39;per_bedroom&#39;</span><span class="p">][</span><span class="s1">&#39;25%&#39;</span><span class="p">]</span>
<span class="n">heatmap</span><span class="p">,</span> <span class="n">xedges</span><span class="p">,</span> <span class="n">yedges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram2d</span><span class="p">(</span>
    <span class="n">loc_df3</span><span class="p">[</span><span class="s1">&#39;longitude&#39;</span><span class="p">][</span><span class="n">loc_df3</span><span class="p">[</span><span class="s1">&#39;per_bedroom&#39;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">per_bedroom_min</span><span class="p">],</span> 
    <span class="n">loc_df3</span><span class="p">[</span><span class="s1">&#39;latitude&#39;</span><span class="p">][</span><span class="n">loc_df3</span><span class="p">[</span><span class="s1">&#39;per_bedroom&#39;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">per_bedroom_min</span> <span class="p">]</span> <span class="p">,</span> 
                                         <span class="n">bins</span><span class="o">=</span><span class="p">(</span><span class="n">bin_size</span><span class="p">,</span><span class="n">bin_size</span><span class="p">))</span>
<span class="n">heatmap2</span><span class="p">,</span> <span class="n">xedges</span><span class="p">,</span> <span class="n">yedges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram2d</span><span class="p">(</span>
    <span class="n">loc_df3</span><span class="p">[</span><span class="s1">&#39;longitude&#39;</span><span class="p">][(</span><span class="n">loc_df3</span><span class="p">[</span><span class="s1">&#39;per_bedroom&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">per_bedroom_min</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">loc_df3</span><span class="p">[</span><span class="s1">&#39;per_bedroom&#39;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">per_bedroom_median</span><span class="p">)],</span>
    <span class="n">loc_df3</span><span class="p">[</span><span class="s1">&#39;latitude&#39;</span><span class="p">][(</span><span class="n">loc_df3</span><span class="p">[</span><span class="s1">&#39;per_bedroom&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">per_bedroom_min</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">loc_df3</span><span class="p">[</span><span class="s1">&#39;per_bedroom&#39;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">per_bedroom_median</span><span class="p">)]</span> <span class="p">,</span>
     <span class="n">bins</span><span class="o">=</span><span class="p">(</span><span class="n">bin_size</span><span class="p">,</span><span class="n">bin_size</span><span class="p">))</span>
<span class="n">heatmap3</span><span class="p">,</span> <span class="n">xedges</span><span class="p">,</span> <span class="n">yedges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram2d</span><span class="p">(</span>
    <span class="n">loc_df3</span><span class="p">[</span><span class="s1">&#39;longitude&#39;</span><span class="p">][(</span><span class="n">loc_df3</span><span class="p">[</span><span class="s1">&#39;per_bedroom&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">per_bedroom_median</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">loc_df3</span><span class="p">[</span><span class="s1">&#39;per_bedroom&#39;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">per_bedroom_max</span><span class="p">)],</span>
    <span class="n">loc_df3</span><span class="p">[</span><span class="s1">&#39;latitude&#39;</span><span class="p">][(</span><span class="n">loc_df3</span><span class="p">[</span><span class="s1">&#39;per_bedroom&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">per_bedroom_median</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">loc_df3</span><span class="p">[</span><span class="s1">&#39;per_bedroom&#39;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">per_bedroom_max</span><span class="p">)]</span> <span class="p">,</span>
     <span class="n">bins</span><span class="o">=</span><span class="p">(</span><span class="n">bin_size</span><span class="p">,</span><span class="n">bin_size</span><span class="p">))</span>
<span class="n">heatmap4</span><span class="p">,</span> <span class="n">xedges</span><span class="p">,</span> <span class="n">yedges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram2d</span><span class="p">(</span>
    <span class="n">loc_df3</span><span class="p">[</span><span class="s1">&#39;longitude&#39;</span><span class="p">][</span><span class="n">loc_df3</span><span class="p">[</span><span class="s1">&#39;per_bedroom&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">per_bedroom_max</span><span class="p">],</span>
    <span class="n">loc_df3</span><span class="p">[</span><span class="s1">&#39;latitude&#39;</span><span class="p">][</span><span class="n">loc_df3</span><span class="p">[</span><span class="s1">&#39;per_bedroom&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">per_bedroom_max</span><span class="p">]</span> <span class="p">,</span> 
                                          <span class="n">bins</span><span class="o">=</span><span class="p">(</span><span class="n">bin_size</span><span class="p">,</span><span class="n">bin_size</span><span class="p">))</span>

<span class="n">extent</span> <span class="o">=</span> <span class="p">[</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">]</span>
 
<span class="c1"># Plot heatmap</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">clf</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">heatmap</span><span class="p">,</span> <span class="n">extent</span><span class="o">=</span><span class="n">extent</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">heatmap2</span><span class="p">,</span> <span class="n">extent</span><span class="o">=</span><span class="n">extent</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">heatmap3</span><span class="p">,</span> <span class="n">extent</span><span class="o">=</span><span class="n">extent</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">heatmap4</span><span class="p">,</span> <span class="n">extent</span><span class="o">=</span><span class="n">extent</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>


<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPEAAAD8CAYAAACmVULXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz
AAALEgAACxIB0t1+/AAADVxJREFUeJzt3X+s3Xddx/Hne9ytTcsqtGMEbF07t6KgXSN1m5KF/XAI
BbYhkR86xMxYJUKg2YCVxTlCMLUdqSYYDOBwBsL4IYgsmG6WbJpoN8tsu5attGjHtpbCmLBYpEL2
8Y/v97bf3p1z7znn3p7vfd/zfCQn93u+v+77nPN93e/3fO/5nneUUpCU12ltFyBpegyxlJwhlpIz
xFJyhlhKzhBLyRliKTlDLCVniKXkxtouoB9nxLwyn4Vtl6EOji078brMe/Roi5XMDT/iKP9XjkUv
86YK8XwWclFc0XYZ6uDA9RcfHz5v/fYWK5kb7ivbep7Xw2kpuVR7Ys1e7n3b455YSs4QS8kZYik5
QywlZ4il5AyxlJwhlpLrOcQR8ayI+I+IuLO+vzgi7o6I/fXP53ZY5kURsbNxeyoi3lVPWx0R2+vx
OyLiwpl7WNLo6GdP/E7gocb9G4FtpZTzgW31/ZOUUvaVUlaXUlYDLwV+CHyxnrwJeH897eb6vqQ+
9RTiiFgKvBr4eGP01cDt9fDtwDVTrOYK4JullEfq+wVYVA//FHCol1oknazXj13+OfAe4MzGuOeX
Ug7Xw98Gnj/FOt4EfLpx/13A1oi4leqPya/2WIs0pxzYMr2LR6bcE0fEa4DvlFK+1m2eUn0Dfddv
oY+IM4CrgM81Rr8NWF9KWQasB/66y7Lr6vfMO37MsanKlUZOL4fTLwOuioiDwB3A5RHxSeBIRLwA
oP75nUnW8SrggVLKkca4twJfqIc/B3Q8sVVK+WgpZU0pZc3pzOuhXGm0THk4XUrZAGwAiIhLgRtK
KddGxGaqIG6sf35pktW8mZMPpaF6D/xy4B7gcmB/n7VLc8J0rwCbzqWIG4HPRsTvAY8AbwCIiBcC
Hy+lrK3vLwSuBP5gwvK/D/xFRIwBPwLWTaMWaWRFpoZqi2Jx8Zs9NAruK9t4qjzZ09fz+IktKTlD
LCVniKXkDLGUnCGWkjPEUnKGWErOEEvJGWIpOUMsJWeIpeQMsZScIZaSM8RScqlCfGzZQg5sufik
7ySSRl2qEEt6JkMsJTedr+cZunmPHrUjvTSBe2IpOUMsJWeIpeQMsZScIZaSM8RScm02Gf9MY/zB
iNg5cw9LGh2tNRkvpbyxMe3vONFcTVIf2mwyPr7uoOrjNLHhmqQe9LonHm8y/nRj3HSbjI+7BDhS
SunYFdH+xNLk2mwyPq5T29Pmuu1PLE2il89OjzcZXwvMBxY1m4yXUg4P2GScuq3pb1C9X5Y0gCn3
xKWUDaWUpaWU5VSHxF8tpVwL/ANVc3EYrMk4wK8BD5dSHuuraknHTef/xBuBKyNiP1UYN0LVZDwi
vjI+U6PJeKezz93eJ0vqkU3GpVnIJuPSCDHEUnKGWErOEEvJGWIpOUMsJWeIpeQMsZScIZaSM8RS
coZYSs4QS8kZYik5QywlZ4il5AyxlJwhlpIzxFJyhlhKzhBLyRliKTlDLCVniKXkDLGUXGtNxuvp
74iIhyNib0RsmpmHJI2W1pqMR8RlVD2OLyilvAS4dbCHII22NpuMvw3YWEo5BlBKmayroqQu2mwy
vhK4JCLui4h7I+KXOy1kk3Fpcm02GR8DFgMXA+8GPhsRz2ggZZNxaXJtNhl/DPhC/Qfg/oh4GjgL
+O5Aj0QaUW02Gf974DKAiFgJnAE80Vf1klptMn4bcG5E7AHuAN5aMjVLlmYJm4xLs5BNxqURYoil
5AyxlJwhlpIzxFJyhlhKzhBLyRliKTlDLCVniKXkDLGUnCGWkjPEUnKGWErOEEvJGWIpOUMsJWeI
peQMsZScIZaSM8RScoZYSs4QS8kZYim51pqMR8QtEfF4Y9ramXtY0uhorcl4bcv49FLKVyYuL2lq
bTYZlzQD2mwyDvCOiNgdEbd1OhwHm4xLU2mzyfhHgHOB1cBh4ENd1m2TcWkSrTUZbw5HxMeAOwd6
BNKIa63JeB38ca8D9vRRt6Ram03GN0XEgxGxG7gMWD+NWqSRZZNxaRayybg0QgyxlJwhlpIzxFJy
hlhKzhBLyRliKTlDLCVniKXkDLGUXC9XMUlTOrDl4uPD563f3mIlo8c9sZScIZaSM8RScr4n1ozw
fXB73BNLyRliKTlDLCVniKXkDLGUnCGWkjPEUnKGWErOEEvJtdZkvDHP9RFRIuKs6T8cafS02mQ8
IpYBrwC+NUDtkmi/yfgWqr7HeXrJSLNMa03GI+Jq4PFSyq7JFrLJuDS5VpqMR8QC4H3AzVP9fpuM
S5Nrq8n4zwIrgF0RAbAUeCAiLiylfHvQByONolaajJdSHiylnF1KWV6v9zHglwyw1L82m4xLmgE2
GZdmIZuMSyPEEEvJGWIpOUMsJWeIpeQMsZScIZaSM8RScoZYSs4QS8kZYik5QywlZ4il5AyxlJwh
lpIzxFJyhlhKzhBLyRliKTlDLCVniKXkDLGUnCGWkjPEUnKtNRmPiA9ExO56/F0R8cKZe1jS6Giz
yfjmUsqqetqd9NAhUdIztdZkvJTyVGPaQmw0Lg2kl9amcKLJ+JmNcdNqMg4QER8Efgf4AXBZp4Ui
Yh2wDmA+C3osVxodrTQZbyx3UyllGfAp4O1d1m2TcWkSvRxOjzcZPwjcAVzebDIOMECT8Yk+Bby+
56olHddKk3GAiDi/cfdq4OE+6pZUa7PJ+MaI2BMRu4FXUJ39ltQnm4xLs5BNxqURYoil5AyxlJwh
lpIzxFJyhlhKzhBLyRliKTlDLCVniKXkDLGUnCGWkjPEUnKGWErOEEvJGWIpOUMsJWeIpeQMsZSc
IZaSM8RScoZYSs4QS8kZYim5NpuMb46Ih+tG41+MiOfM3MOSRkebTcbvBn6hlLIK+AawYYD6pZHX
ZpPxu0opP6mnbQeW9lq0pBN63ROPNxl/ujFu2k3GG64D/rHThIhYFxE7ImLHjznWY7nS6Gi1yXg9
7SbgJ1Q9ijut2ybj0iTGephnvMn4WmA+sKjZZLyUcnjQJuMR8bvAa4ArSqb2jNIs0maT8VdSHaJf
VUr54QC1S3PO1kM72XpoJytX9R6JNpuMfxg4E7i7/vfTX02jFmlk9XI4fVwp5R7gnnr4e1RnnCfO
cwhY27h/FFjSYb7z+itVUieR6a1oRHwXeKTDpLOAJ4Zczmz6/dYw92o4p5TyvF5mTBXibiJiRyll
zaj+fmsY7Rr87LSUnCGWkpsrIf7oiP9+sIZxI1fDnHhPLI2yubInlkbWrA1xRHymcR3ywYjYOWH6
z0TE/0TEDV2W73q9c0RsiIgDEbEvIn693xoi4sLG+F0R8bouy18QEf8WEQ9GxJcjYlE9/oyI+EQ9
fldEXNpCDadHxO31+IciouuloKewht+ecL350xGxepg11NNW1dP21tPnD/l5WB4R/9tYR38ffCql
zPob8CHg5gnjPk91QcUNXZbZBNxYD98I/Fk9/GJgFzAPWAF8E3hWPzUAC4Cxenj8c+NjHZb5d+Dl
9fB1wAfq4T8CPlEPnw18DThtyDX8FnBHY10HgeXDrGHCPL9IdalqX9vDDDwPY8Bu4IL6/pIWtofl
wJ6B8zHogsO6AQE8CpzfGHcNsBm4he4h3ge8oPHE7quHNwAbGvNtBX6l3xoa01YAR7q8aD/gxHmH
ZcDX6+G/BN7SmG8bcOGQa3gz8OV6I15C9cUMi4dZw4R5/hT44CDbwzSfh7XAJ6e7TU6zhmmFeNYe
TjdcAhwppewHiIhnA+8F3j/Fct2ud/5pqhdg3GP1uJ5rqOu4KCL2Ag8Cf1hOfMFB016qL08A+E2q
Fw6qI4GrImIsIlZQfevJsg7Ln8oaPg8cBQ4D3wJuLaU8OeQamt5I9+vNT2UNK4ESEVsj4oGIeE8L
NQCsqA+l742IS3qo4YRB0z8TN+CfgD0dblc35vkIcH3j/q3AG+rhW+i+J/7+hPv/Xf/8MHBtY/zj
VBtxzzVMWO/PA/cD8ztM+zngLqrD5T8BvlePHwO2ADuprv56gurjpMOs4WVU13CfTnVIf5Tq6GVo
NTSmX0S18fe9PczA83AD8F9UH5VcAHy/vj/MGuYBS+rhl1LtZBb1nKM2Q9xDyMeoDk2WNsb9C9X7
t4P1E/4k8PYOy87I4XSnGjrM81VgzRSPZSVwf5dp/wq8eJg18MxD+tuo/zgO+3mg+oP2vkG2hxl4
Ht4E3N6Y9sfAu1veHu6ZavmT5u91xjZuwCuBeyeZfgvd98SbOfnE1qZ6+CWcfGLrP5nkREanGurl
xk9knAMcAs7qsOzZ9c/TgL8FrqvvLwAW1sNXAv/c7/MwAzW8lxMn1xYCXwdWDbOGxrjHgXMH2R5m
4Hl4LvBA/ZqMUR0NvHrINTxvfBsEzq2fj0nPT5y03pkI26m6AX9D9f6ipxBTfZHfmnp4CdUJo/31
C7O4Md9NVGel9wGv6rcG4C1U72921hvANV1qeCfVCaNvUF1vPX5SY3n9ux+qazunhRqeTXV2fy9V
gLvufU5VDfW0S4Htg24PM1TDtfU69lD/sR/ya/H6Ccu/tp+c+IktKbkMZ6clTcIQS8kZYik5Qywl
Z4il5AyxlJwhlpIzxFJy/w/GN1NaCVxsQgAAAABJRU5ErkJggg==
"
>
</div>

</div>

<div class="output_area"><div class="prompt"></div>


<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPEAAAD8CAYAAACmVULXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

<div class="output_area"><div class="prompt"></div>


<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPEAAAD8CAYAAACmVULXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

<div class="output_area"><div class="prompt"></div>


<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPEAAAD8CAYAAACmVULXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Low per bedroom apartments on the outskirts. High per bedroom apartments have fewer high density areas. 25% to 50% quantile and 50% to 75% quantiles have more specific densities and some overlap.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Creating two new features: latitude_modified and longitude_modified. Replaces obviously false extreme location outliers with more reasonable extremes.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[113]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_temp</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span> <span class="p">{</span><span class="s1">&#39;longitude&#39;</span><span class="p">:</span> <span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;longitude&#39;</span><span class="p">],</span><span class="s1">&#39;latitude&#39;</span><span class="p">:</span><span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;latitude&#39;</span><span class="p">]})</span>
<span class="n">latitude_modified</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">df_temp</span><span class="p">[</span><span class="s1">&#39;latitude&#39;</span><span class="p">])</span>
<span class="n">longitude_modified</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">df_temp</span><span class="p">[</span><span class="s1">&#39;longitude&#39;</span><span class="p">])</span>

<span class="n">constant_offset</span> <span class="o">=</span> <span class="mf">0.25</span>
<span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">=</span> <span class="n">df_raw</span><span class="o">.</span><span class="n">describe</span><span class="p">()[</span><span class="s1">&#39;longitude&#39;</span><span class="p">][</span><span class="s1">&#39;25%&#39;</span><span class="p">]</span><span class="o">-</span><span class="n">constant_offset</span><span class="p">,</span> <span class="n">df_raw</span><span class="o">.</span><span class="n">describe</span><span class="p">()[</span><span class="s1">&#39;longitude&#39;</span><span class="p">][</span><span class="s1">&#39;75%&#39;</span><span class="p">]</span><span class="o">+</span><span class="n">constant_offset</span>
<span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="n">df_raw</span><span class="o">.</span><span class="n">describe</span><span class="p">()[</span><span class="s1">&#39;latitude&#39;</span><span class="p">][</span><span class="s1">&#39;25%&#39;</span><span class="p">]</span><span class="o">-</span><span class="n">constant_offset</span><span class="p">,</span> <span class="n">df_raw</span><span class="o">.</span><span class="n">describe</span><span class="p">()[</span><span class="s1">&#39;latitude&#39;</span><span class="p">][</span><span class="s1">&#39;75%&#39;</span><span class="p">]</span><span class="o">+</span><span class="n">constant_offset</span>

<span class="c1">#print(x_min,x_max,y_min,y_max)</span>
<span class="n">latitude_modified</span><span class="p">[</span><span class="n">latitude_modified</span> <span class="o">&gt;</span> <span class="n">y_max</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_max</span>
<span class="n">latitude_modified</span><span class="p">[</span><span class="n">latitude_modified</span> <span class="o">&lt;</span> <span class="n">y_min</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_min</span>
<span class="n">longitude_modified</span><span class="p">[</span><span class="n">longitude_modified</span> <span class="o">&gt;</span> <span class="n">x_max</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_max</span>
<span class="n">longitude_modified</span><span class="p">[</span><span class="n">longitude_modified</span> <span class="o">&lt;</span> <span class="n">x_min</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_min</span>
<span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;latitude_modified&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">latitude_modified</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="n">df_raw</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">df_raw</span><span class="p">[</span><span class="s1">&#39;longitude_modified&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">longitude_modified</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="n">df_raw</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="c1">#df_raw.describe()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[116]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#df_raw.columns.values</span>
<span class="c1">#df_raw.head()</span>
<span class="c1">#df_raw.describe()</span>
<span class="c1">#df_raw[&#39;features_count&#39;].describe()</span>
<span class="c1">#df_raw.to_pickle(&quot;train_checkpoint_2&quot;)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Prepare the test data set.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[272]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">Counter</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">pickle</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;renthop_test.json&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">json_data</span><span class="p">:</span>
    <span class="n">test_data_json</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">json_data</span><span class="p">)</span>
    
<span class="n">df_test_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_records</span><span class="p">(</span><span class="n">test_data_json</span><span class="p">)</span>
<span class="n">df_test_data</span><span class="p">[</span><span class="s2">&quot;created&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df_test_data</span><span class="p">[</span><span class="s2">&quot;created&quot;</span><span class="p">])</span>

<span class="n">df_2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span> <span class="p">{</span><span class="s1">&#39;bathrooms&#39;</span><span class="p">:</span> <span class="n">df_test_data</span><span class="p">[</span><span class="s1">&#39;bathrooms&#39;</span><span class="p">],</span><span class="s1">&#39;bedrooms&#39;</span><span class="p">:</span><span class="n">df_test_data</span><span class="p">[</span><span class="s1">&#39;bedrooms&#39;</span><span class="p">],</span>
                            <span class="s1">&#39;price&#39;</span><span class="p">:</span><span class="n">df_test_data</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]})</span>

<span class="n">mod_bed</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">df_2</span><span class="p">[</span><span class="s1">&#39;bedrooms&#39;</span><span class="p">])</span>
<span class="n">mod_bed</span><span class="p">[</span><span class="n">mod_bed</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">studio_bedroom</span>
<span class="n">df_test_data</span><span class="p">[</span><span class="s1">&#39;bedrooms_modified&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">mod_bed</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="n">df_test_data</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>

<span class="n">price_modified</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">df_2</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">])</span>
<span class="n">price_modified</span><span class="p">[</span><span class="n">price_modified</span> <span class="o">&gt;=</span> <span class="mi">50000</span><span class="p">]</span> <span class="o">=</span> <span class="mi">50000</span>
<span class="n">per_bed</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">price_modified</span><span class="o">/</span><span class="n">mod_bed</span><span class="p">)</span>
<span class="n">df_test_data</span><span class="p">[</span><span class="s1">&#39;price_modified&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">price_modified</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="n">df_test_data</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">df_test_data</span><span class="p">[</span><span class="s1">&#39;price_per_bed&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">per_bed</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="n">df_test_data</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>

<span class="c1">#df_test_data.describe()</span>
<span class="c1">#df_test_data.to_pickle(&quot;test_checkpoint_1&quot;)</span>

<span class="n">created_hour_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">created_dow_list</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1">#0 is monday, 6 is sunday</span>
<span class="n">created_day_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">created_month_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">df_test_data</span><span class="p">[</span><span class="s1">&#39;created&#39;</span><span class="p">]:</span>
    <span class="n">x_hour</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">hour</span>
    <span class="n">x_minute</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">minute</span>
    <span class="n">x_dow</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">dayofweek</span>
    <span class="n">x_day</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">day</span>
    <span class="n">x_month</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">month</span>
    
    <span class="k">if</span> <span class="n">x_minute</span> <span class="o">&gt;</span> <span class="mi">30</span><span class="p">:</span>
        <span class="n">x_hour</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">x_hour</span> <span class="o">&gt;</span> <span class="mi">23</span><span class="p">:</span>
            <span class="n">x_hour</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">if</span> <span class="n">x_day</span> <span class="o">&gt;</span> <span class="mi">29</span><span class="p">:</span> <span class="c1">#only 1 month had a 31st day</span>
        <span class="n">x_day</span> <span class="o">=</span> <span class="mi">30</span>
        
    <span class="n">created_hour_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x_hour</span><span class="p">)</span>
    <span class="n">created_dow_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x_dow</span><span class="p">)</span>
    <span class="n">created_day_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x_day</span><span class="p">)</span>
    <span class="n">created_month_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x_month</span><span class="p">)</span>

<span class="n">df_test_data</span><span class="p">[</span><span class="s1">&#39;created_hour&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">created_hour_list</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">df_test_data</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">df_test_data</span><span class="p">[</span><span class="s1">&#39;created_dow&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">created_dow_list</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">df_test_data</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">df_test_data</span><span class="p">[</span><span class="s1">&#39;created_day&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">created_day_list</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">df_test_data</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">df_test_data</span><span class="p">[</span><span class="s1">&#39;created_month&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">created_month_list</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">df_test_data</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>


<span class="n">df_test_data</span><span class="p">[</span><span class="s1">&#39;description_length&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">df_test_data</span><span class="p">[</span><span class="s1">&#39;description&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">len</span><span class="p">(),</span> <span class="n">index</span><span class="o">=</span><span class="n">df_test_data</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>


<span class="n">df_3</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span> <span class="p">{</span><span class="s1">&#39;listing_id&#39;</span><span class="p">:</span> <span class="n">df_test_data</span><span class="p">[</span><span class="s1">&#39;listing_id&#39;</span><span class="p">],</span><span class="s1">&#39;features&#39;</span><span class="p">:</span><span class="n">df_test_data</span><span class="p">[</span><span class="s1">&#39;features&#39;</span><span class="p">]})</span>
<span class="n">feature_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">feature_list_count</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">df_3</span><span class="p">[</span><span class="s1">&#39;features&#39;</span><span class="p">]:</span>
    <span class="n">feature_list_count</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">y</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">feature_list</span><span class="p">:</span>
            <span class="n">feature_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="n">df_test_data</span><span class="p">[</span><span class="s1">&#39;features_count&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">feature_list_count</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">df_test_data</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>


<span class="n">apt_feature_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df_test_data</span><span class="p">[</span><span class="s1">&#39;features&#39;</span><span class="p">])</span>
<span class="n">apt_feature_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">apt_feature_length</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="c1">#print(apt_feature_array.shape)</span>
<span class="n">apt_feature_search_string</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">&quot;elevator&quot;</span><span class="p">],[</span><span class="s2">&quot;cats&quot;</span><span class="p">],[</span><span class="s2">&quot;hardwood&quot;</span><span class="p">],[</span><span class="s2">&quot;dogs&quot;</span><span class="p">],[</span><span class="s2">&quot;doorman&quot;</span><span class="p">],[</span><span class="s2">&quot;dishwasher&quot;</span><span class="p">],</span>
                             <span class="p">[</span><span class="s2">&quot;no fee&quot;</span><span class="p">],[</span><span class="s2">&quot;laundry&quot;</span><span class="p">],[</span><span class="s2">&quot;fitness&quot;</span><span class="p">,</span><span class="s2">&quot;gym&quot;</span><span class="p">],[</span><span class="s2">&quot;pre-war&quot;</span><span class="p">,</span><span class="s2">&quot;prewar&quot;</span><span class="p">,</span><span class="s2">&quot;pre war&quot;</span><span class="p">]]</span>
<span class="n">z_break</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">apt_feature_length</span><span class="p">):</span>
    <span class="n">feature_list</span> <span class="o">=</span> <span class="n">df_test_data</span><span class="p">[</span><span class="s1">&#39;features&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">feature_list</span><span class="p">:</span>
        <span class="n">temp_feature</span> <span class="o">=</span> <span class="n">feature</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="c1">#print(i, temp_feature)</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span><span class="c1">#search_category in apt_feature_search_string:</span>
            <span class="n">search_category</span> <span class="o">=</span> <span class="n">apt_feature_search_string</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">search_string</span> <span class="ow">in</span> <span class="n">search_category</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">search_string</span> <span class="ow">in</span> <span class="n">temp_feature</span><span class="p">:</span>
                    <span class="n">apt_feature_array</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
                    <span class="k">break</span>
                    
<span class="n">z_string</span> <span class="o">=</span> <span class="s2">&quot;apt_feature_&quot;</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">temp_string</span> <span class="o">=</span> <span class="n">z_string</span> <span class="o">+</span> <span class="n">apt_feature_search_string</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1">#print(temp_string)</span>
    <span class="n">df_test_data</span><span class="p">[</span><span class="n">temp_string</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">apt_feature_array</span><span class="p">[:,</span><span class="n">i</span><span class="p">],</span><span class="n">index</span><span class="o">=</span><span class="n">df_test_data</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
    
<span class="c1">#df_test_data.describe()</span>
<span class="c1">#df_test_data.to_pickle(&quot;test_checkpoint_12&quot;)</span>

<span class="n">df_test_data</span> <span class="o">=</span> <span class="n">df_test_data</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df_manager</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;manager_id&#39;</span><span class="p">),</span><span class="n">on</span><span class="o">=</span><span class="s1">&#39;manager_id&#39;</span><span class="p">)</span>
<span class="n">df_test_data</span> <span class="o">=</span> <span class="n">df_test_data</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df_building</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;building_id&#39;</span><span class="p">),</span><span class="n">on</span><span class="o">=</span><span class="s1">&#39;building_id&#39;</span><span class="p">)</span>

<span class="c1">#some managers/buildings in test set don&#39;t show up in train set</span>
<span class="n">df_test_data</span><span class="p">[</span><span class="s1">&#39;manager_count&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df_test_data</span><span class="p">[</span><span class="s1">&#39;manager_low&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df_test_data</span><span class="p">[</span><span class="s1">&#39;manager_medium&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df_test_data</span><span class="p">[</span><span class="s1">&#39;manager_high&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df_test_data</span><span class="p">[</span><span class="s1">&#39;building_count&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df_test_data</span><span class="p">[</span><span class="s1">&#39;building_low&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df_test_data</span><span class="p">[</span><span class="s1">&#39;building_medium&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df_test_data</span><span class="p">[</span><span class="s1">&#39;building_high&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">image_dict</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span> <span class="nb">open</span><span class="p">(</span> <span class="s2">&quot;image_count_dict.p&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span> <span class="p">)</span> <span class="p">)</span>

<span class="n">image_count</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">df_test_data</span><span class="p">[</span><span class="s1">&#39;listing_id&#39;</span><span class="p">]:</span>
    <span class="n">y</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">image_dict</span><span class="p">:</span>
        <span class="n">image_count</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">image_dict</span><span class="p">[</span><span class="n">y</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">image_count</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    
<span class="n">df_test_data</span><span class="p">[</span><span class="s1">&#39;image_count&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">image_count</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="n">df_test_data</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>


<span class="n">df_temp</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span> <span class="p">{</span><span class="s1">&#39;longitude&#39;</span><span class="p">:</span> <span class="n">df_test_data</span><span class="p">[</span><span class="s1">&#39;longitude&#39;</span><span class="p">],</span><span class="s1">&#39;latitude&#39;</span><span class="p">:</span><span class="n">df_test_data</span><span class="p">[</span><span class="s1">&#39;latitude&#39;</span><span class="p">]})</span>
<span class="n">latitude_modified</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">df_temp</span><span class="p">[</span><span class="s1">&#39;latitude&#39;</span><span class="p">])</span>
<span class="n">longitude_modified</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">df_temp</span><span class="p">[</span><span class="s1">&#39;longitude&#39;</span><span class="p">])</span>

<span class="n">constant_offset</span> <span class="o">=</span> <span class="mf">0.25</span>
<span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">=</span> <span class="n">df_raw</span><span class="o">.</span><span class="n">describe</span><span class="p">()[</span><span class="s1">&#39;longitude&#39;</span><span class="p">][</span><span class="s1">&#39;25%&#39;</span><span class="p">]</span><span class="o">-</span><span class="n">constant_offset</span><span class="p">,</span> <span class="n">df_raw</span><span class="o">.</span><span class="n">describe</span><span class="p">()[</span><span class="s1">&#39;longitude&#39;</span><span class="p">][</span><span class="s1">&#39;75%&#39;</span><span class="p">]</span><span class="o">+</span><span class="n">constant_offset</span>
<span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="n">df_raw</span><span class="o">.</span><span class="n">describe</span><span class="p">()[</span><span class="s1">&#39;latitude&#39;</span><span class="p">][</span><span class="s1">&#39;25%&#39;</span><span class="p">]</span><span class="o">-</span><span class="n">constant_offset</span><span class="p">,</span> <span class="n">df_raw</span><span class="o">.</span><span class="n">describe</span><span class="p">()[</span><span class="s1">&#39;latitude&#39;</span><span class="p">][</span><span class="s1">&#39;75%&#39;</span><span class="p">]</span><span class="o">+</span><span class="n">constant_offset</span>

<span class="c1">#print(x_min,x_max,y_min,y_max)</span>
<span class="n">latitude_modified</span><span class="p">[</span><span class="n">latitude_modified</span> <span class="o">&gt;</span> <span class="n">y_max</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_max</span>
<span class="n">latitude_modified</span><span class="p">[</span><span class="n">latitude_modified</span> <span class="o">&lt;</span> <span class="n">y_min</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_min</span>
<span class="n">longitude_modified</span><span class="p">[</span><span class="n">longitude_modified</span> <span class="o">&gt;</span> <span class="n">x_max</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_max</span>
<span class="n">longitude_modified</span><span class="p">[</span><span class="n">longitude_modified</span> <span class="o">&lt;</span> <span class="n">x_min</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_min</span>
<span class="n">df_test_data</span><span class="p">[</span><span class="s1">&#39;latitude_modified&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">latitude_modified</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="n">df_test_data</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">df_test_data</span><span class="p">[</span><span class="s1">&#39;longitude_modified&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">longitude_modified</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="n">df_test_data</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>

<span class="n">df_test_data</span><span class="o">.</span><span class="n">to_pickle</span><span class="p">(</span><span class="s2">&quot;test_checkpoint_2&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[277]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">df_test_data</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">any</span><span class="p">())</span>
<span class="sd">&#39;&#39;&#39;print(len(df_test_data.columns.values))</span>
<span class="sd">print(df_test_data.columns.values)</span>
<span class="sd">print(df_test_data.head())</span>
<span class="sd">print(df_test_data.describe())&#39;&#39;&#39;</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>False
</pre>
</div>
</div>

<div class="output_area"><div class="prompt output_prompt">Out[277]:</div>


<div class="output_text output_subarea output_execute_result">
<pre>&#39;print(len(df_test_data.columns.values))\nprint(df_test_data.columns.values)\nprint(df_test_data.head())\nprint(df_test_data.describe())&#39;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Checkpoint">Checkpoint<a class="anchor-link" href="#Checkpoint">&#182;</a></h2><p>Data can be loaded from pickle file train_checkpoint_2</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.0-Model-Building">2.0 Model Building<a class="anchor-link" href="#2.0-Model-Building">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>After some consideration, I chose the following models to train the data on:</p>
<ul>
<li>Random Forest: From what I've learned, trees are typically a good classifier. After looking at the data, I felt that trees would be good at making inferences from many of the marginal and unusual samples. Can also use 'feature_importances' to see the relative effect of each column </li>
<li>Logistic Regression: Simple to implement, outputs probabilities.</li>
<li>Naive Bayes: Not a good solution for this type of problem but simple enough to train and often effective.</li>
<li>Adaboost: For many of the reasons I chose Random Forest, I thought a boosting algorithm with some of the similar properties could prove useful.</li>
<li>SGD Classifier </li>
<li>XGBoost: Powerful boosting that is used on a large amount of Kaggle entries.</li>
<li>Voting Classifier: As I altered most of the inputs and modified the feature space, I am hopeful that by combining some of my models I can leverage their individual strengths to produce better predictions</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Load the data, separate the label data, and encode it. Drop unused columns.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[26]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">preprocessing</span>
<span class="n">lb</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">LabelBinarizer</span><span class="p">()</span>
<span class="c1">#le = preprocessing.LabelEncoder()</span>

<span class="n">df_pre_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="s2">&quot;train_checkpoint_2&quot;</span><span class="p">)</span>
<span class="n">df_kaggle_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="s2">&quot;test_checkpoint_2&quot;</span><span class="p">)</span>
<span class="c1">#print(len(df_pre_train.columns.values),len(df_kaggle_test.columns.values))</span>

<span class="n">temp</span> <span class="o">=</span> <span class="n">lb</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df_pre_train</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">])</span>

<span class="n">df_pre_train_label_matrix</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;interest0_low&#39;</span><span class="p">:</span><span class="n">temp</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="s1">&#39;interest1_medium&#39;</span><span class="p">:</span><span class="n">temp</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span><span class="s1">&#39;interest2_high&#39;</span><span class="p">:</span><span class="n">temp</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]})</span>
<span class="n">df_pre_train_label_vector</span> <span class="o">=</span> <span class="n">df_pre_train</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="s1">&#39;low&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;medium&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;high&#39;</span><span class="p">:</span><span class="mi">2</span><span class="p">})</span>

<span class="n">drop_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;bedrooms&#39;</span><span class="p">,</span><span class="s1">&#39;building_id&#39;</span><span class="p">,</span><span class="s1">&#39;created&#39;</span><span class="p">,</span><span class="s1">&#39;description&#39;</span><span class="p">,</span><span class="s1">&#39;display_address&#39;</span><span class="p">,</span><span class="s1">&#39;features&#39;</span><span class="p">,</span><span class="s1">&#39;interest_level&#39;</span><span class="p">,</span><span class="s1">&#39;latitude&#39;</span><span class="p">,</span>
                <span class="s1">&#39;listing_id&#39;</span><span class="p">,</span><span class="s1">&#39;longitude&#39;</span><span class="p">,</span><span class="s1">&#39;manager_id&#39;</span><span class="p">,</span><span class="s1">&#39;photos&#39;</span><span class="p">,</span><span class="s1">&#39;price&#39;</span><span class="p">,</span>
               <span class="s1">&#39;street_address&#39;</span><span class="p">]</span>
<span class="n">df_pre_train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">drop_columns</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

<span class="n">drop_columns_test</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;bedrooms&#39;</span><span class="p">,</span><span class="s1">&#39;building_id&#39;</span><span class="p">,</span><span class="s1">&#39;created&#39;</span><span class="p">,</span><span class="s1">&#39;description&#39;</span><span class="p">,</span><span class="s1">&#39;display_address&#39;</span><span class="p">,</span><span class="s1">&#39;features&#39;</span><span class="p">,</span><span class="s1">&#39;latitude&#39;</span><span class="p">,</span>
                <span class="s1">&#39;listing_id&#39;</span><span class="p">,</span><span class="s1">&#39;longitude&#39;</span><span class="p">,</span><span class="s1">&#39;manager_id&#39;</span><span class="p">,</span><span class="s1">&#39;photos&#39;</span><span class="p">,</span><span class="s1">&#39;price&#39;</span><span class="p">,</span>
               <span class="s1">&#39;street_address&#39;</span><span class="p">]</span>
<span class="n">df_kaggle_test</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">drop_columns_test</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[27]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_pre_train</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt output_prompt">Out[27]:</div>


<div class="output_text output_subarea output_execute_result">
<pre>array([&#39;bathrooms&#39;, &#39;bedrooms_modified&#39;, &#39;price_modified&#39;, &#39;price_per_bed&#39;,
       &#39;created_hour&#39;, &#39;created_dow&#39;, &#39;created_day&#39;, &#39;created_month&#39;,
       &#39;description_length&#39;, &#39;features_count&#39;, &#39;apt_feature_elevator&#39;,
       &#39;apt_feature_cats&#39;, &#39;apt_feature_hardwood&#39;, &#39;apt_feature_dogs&#39;,
       &#39;apt_feature_doorman&#39;, &#39;apt_feature_dishwasher&#39;,
       &#39;apt_feature_no fee&#39;, &#39;apt_feature_laundry&#39;, &#39;apt_feature_fitness&#39;,
       &#39;apt_feature_pre-war&#39;, &#39;manager_count&#39;, &#39;manager_low&#39;,
       &#39;manager_medium&#39;, &#39;manager_high&#39;, &#39;building_count&#39;, &#39;building_low&#39;,
       &#39;building_medium&#39;, &#39;building_high&#39;, &#39;image_count&#39;,
       &#39;latitude_modified&#39;, &#39;longitude_modified&#39;], dtype=object)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Standardize features</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[28]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&#39;&#39;&#39;standardize_columns = [&#39;bathrooms&#39;, &#39;bedrooms_modified&#39;,</span>
<span class="sd">       &#39;price_modified&#39;, &#39;price_per_bed&#39;, &#39;created_hour&#39;, &#39;created_dow&#39;,</span>
<span class="sd">       &#39;created_day&#39;, &#39;created_month&#39;, &#39;description_length&#39;,</span>
<span class="sd">       &#39;features_count&#39;, &#39;manager_low&#39;, &#39;manager_medium&#39;, &#39;manager_high&#39;,</span>
<span class="sd">       &#39;building_count&#39;, &#39;building_low&#39;, &#39;building_medium&#39;,</span>
<span class="sd">       &#39;building_high&#39;, &#39;image_count&#39;, &#39;latitude_modified&#39;,</span>
<span class="sd">       &#39;longitude_modified&#39;]&#39;&#39;&#39;</span>

<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="k">import</span> <span class="n">StandardScaler</span>

<span class="n">standardize_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;price_modified&#39;</span><span class="p">,</span> <span class="s1">&#39;price_per_bed&#39;</span><span class="p">,</span><span class="s1">&#39;latitude_modified&#39;</span><span class="p">,</span>
       <span class="s1">&#39;longitude_modified&#39;</span><span class="p">]</span>

<span class="n">X_scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">df_pre_train</span><span class="p">[</span><span class="n">standardize_columns</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df_pre_train</span><span class="p">[</span><span class="n">standardize_columns</span><span class="p">])</span>

<span class="n">df_kaggle_test</span><span class="p">[</span><span class="n">standardize_columns</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df_kaggle_test</span><span class="p">[</span><span class="n">standardize_columns</span><span class="p">])</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[29]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_pre_train</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt output_prompt">Out[29]:</div>

<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bathrooms</th>
      <th>bedrooms_modified</th>
      <th>price_modified</th>
      <th>price_per_bed</th>
      <th>created_hour</th>
      <th>created_dow</th>
      <th>created_day</th>
      <th>created_month</th>
      <th>description_length</th>
      <th>features_count</th>
      <th>...</th>
      <th>manager_low</th>
      <th>manager_medium</th>
      <th>manager_high</th>
      <th>building_count</th>
      <th>building_low</th>
      <th>building_medium</th>
      <th>building_high</th>
      <th>image_count</th>
      <th>latitude_modified</th>
      <th>longitude_modified</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>10</th>
      <td>1.5</td>
      <td>3.0</td>
      <td>-0.282271</td>
      <td>-1.121356</td>
      <td>8</td>
      <td>4</td>
      <td>24</td>
      <td>6</td>
      <td>588</td>
      <td>0</td>
      <td>...</td>
      <td>67</td>
      <td>22</td>
      <td>0</td>
      <td>2</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>5</td>
      <td>-0.906438</td>
      <td>0.971285</td>
    </tr>
    <tr>
      <th>10000</th>
      <td>1.0</td>
      <td>2.0</td>
      <td>0.756344</td>
      <td>0.218660</td>
      <td>12</td>
      <td>6</td>
      <td>12</td>
      <td>6</td>
      <td>8</td>
      <td>5</td>
      <td>...</td>
      <td>84</td>
      <td>1</td>
      <td>0</td>
      <td>23</td>
      <td>21</td>
      <td>2</td>
      <td>0</td>
      <td>11</td>
      <td>1.085420</td>
      <td>0.184457</td>
    </tr>
    <tr>
      <th>100004</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>-0.345473</td>
      <td>0.309541</td>
      <td>3</td>
      <td>6</td>
      <td>17</td>
      <td>4</td>
      <td>691</td>
      <td>4</td>
      <td>...</td>
      <td>77</td>
      <td>49</td>
      <td>7</td>
      <td>57</td>
      <td>22</td>
      <td>26</td>
      <td>9</td>
      <td>8</td>
      <td>-0.302920</td>
      <td>-0.956769</td>
    </tr>
    <tr>
      <th>100007</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>-0.166401</td>
      <td>0.638261</td>
      <td>2</td>
      <td>0</td>
      <td>18</td>
      <td>4</td>
      <td>492</td>
      <td>2</td>
      <td>...</td>
      <td>153</td>
      <td>24</td>
      <td>13</td>
      <td>98</td>
      <td>88</td>
      <td>9</td>
      <td>1</td>
      <td>3</td>
      <td>0.072106</td>
      <td>0.151944</td>
    </tr>
    <tr>
      <th>100013</th>
      <td>1.0</td>
      <td>4.0</td>
      <td>-0.134801</td>
      <td>-1.247043</td>
      <td>2</td>
      <td>3</td>
      <td>28</td>
      <td>4</td>
      <td>479</td>
      <td>1</td>
      <td>...</td>
      <td>14</td>
      <td>0</td>
      <td>0</td>
      <td>8285</td>
      <td>7587</td>
      <td>503</td>
      <td>195</td>
      <td>3</td>
      <td>1.815603</td>
      <td>0.750193</td>
    </tr>
  </tbody>
</table>
<p>5 rows  31 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Creating 3 sets: training set, validation set, and test set. Some of the models I use are improved by <a href="http://scikit-learn.org/stable/modules/calibration.html">probability calibration</a> and a validation set helps with the creation of those models.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[30]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>

<span class="n">X_train2</span><span class="p">,</span> <span class="n">X_val2</span><span class="p">,</span> <span class="n">y_train2</span><span class="p">,</span> <span class="n">y_val2</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df_pre_train</span><span class="p">,</span> <span class="n">df_pre_train_label_vector</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X_val2</span><span class="p">,</span> <span class="n">X_test2</span><span class="p">,</span> <span class="n">y_val2</span><span class="p">,</span> <span class="n">y_test2</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_val2</span><span class="p">,</span> <span class="n">y_val2</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="nb">print</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train2</span><span class="p">),</span><span class="nb">len</span><span class="p">(</span><span class="n">X_val2</span><span class="p">),</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test2</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>34546 7403 7403
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Scoring-Functions">Scoring Functions<a class="anchor-link" href="#Scoring-Functions">&#182;</a></h3><p>I create a custom scorer so that GridSearchCV can evaluate the models after probability calibration. Other than Logistic Regression, the other models I choose benefit from <a href="http://scikit-learn.org/stable/modules/calibration.html#calibration">probability calibration</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[31]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">ShuffleSplit</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">log_loss</span><span class="p">,</span> <span class="n">make_scorer</span>
<span class="kn">from</span> <span class="nn">sklearn.calibration</span> <span class="k">import</span> <span class="n">CalibratedClassifierCV</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">GridSearchCV</span>

<span class="c1">#cross validation sets used by GridSearch</span>
<span class="n">rs</span> <span class="o">=</span> <span class="n">ShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.20</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">cv_sets</span> <span class="o">=</span> <span class="n">rs</span><span class="o">.</span><span class="n">get_n_splits</span><span class="p">(</span><span class="n">X_train2</span><span class="p">)</span>

<span class="c1">#custom scorer used in GridSearchCV.</span>
<span class="c1">#Training data is used in cross-validation sets by GridSearch to train the initial model.</span>
<span class="c1">#heldout part of the cv set is used as X,y in the function.</span>
<span class="c1">#outside validation set used to fit the CalibratedClassifierCV</span>

<span class="k">def</span> <span class="nf">custom_ccv_scorer</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
    <span class="n">ccv</span> <span class="o">=</span> <span class="n">CalibratedClassifierCV</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s2">&quot;isotonic&quot;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="s2">&quot;prefit&quot;</span><span class="p">)</span>
    <span class="n">ccv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_val2</span><span class="p">,</span><span class="n">y_val2</span><span class="p">)</span> <span class="c1">#fit to overall validation set</span>
    <span class="n">ccv_predictions</span> <span class="o">=</span> <span class="n">ccv</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">ccv_score</span> <span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">ccv_predictions</span><span class="p">)</span>
    <span class="c1">#Take the negative as GridSearchCV optimizes by highest value while smaller positive values are better for log loss.</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">ccv_score</span>
    
<span class="c1">#log_loss argument works by default, don&#39;t need to implement a custom log_loss scoring function</span>
<span class="c1">#scoring_fnc = make_scorer(log_loss,greater_is_better=False, needs_proba=True)</span>

<span class="k">def</span> <span class="nf">describe_grid_model</span><span class="p">(</span><span class="n">grid_model</span><span class="p">):</span>
    <span class="n">best_model</span> <span class="o">=</span> <span class="n">grid_model</span><span class="o">.</span><span class="n">best_estimator_</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">best_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test2</span><span class="p">)</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">y_test2</span><span class="p">,</span><span class="n">predictions</span><span class="p">)</span>
    <span class="n">ccv</span> <span class="o">=</span> <span class="n">CalibratedClassifierCV</span><span class="p">(</span><span class="n">best_model</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s2">&quot;isotonic&quot;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="s2">&quot;prefit&quot;</span><span class="p">)</span>
    <span class="n">ccv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_val2</span><span class="p">,</span><span class="n">y_val2</span><span class="p">)</span> <span class="c1">#fit to overall validation set</span>
    <span class="n">ccv_predictions</span> <span class="o">=</span> <span class="n">ccv</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test2</span><span class="p">)</span>
    <span class="n">ccv_score</span> <span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">y_test2</span><span class="p">,</span><span class="n">ccv_predictions</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;CCV Score, Base Model Score:&#39;</span><span class="p">,</span> <span class="n">ccv_score</span><span class="p">,</span><span class="s1">&#39;,&#39;</span><span class="p">,</span><span class="n">score</span> <span class="p">)</span>
    <span class="n">df_grid</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">grid_model</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">df_grid</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">df_grid</span><span class="p">[</span><span class="s1">&#39;mean_test_score&#39;</span><span class="p">])</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Benchmark-Score">Benchmark Score<a class="anchor-link" href="#Benchmark-Score">&#182;</a></h3><p>Test the benchmark score on the overall data. I also submitted a benchmark sample to Kaggle and received a score of 0.79075. Scores for the benchmark model for the overall training set, the test subset of the training set, and the Kaggle score on the withheld test set are all roughly 0.79.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[32]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">log_loss</span>

<span class="n">benchmark_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;high&#39;</span><span class="p">:</span> <span class="mf">0.07778813421948452</span><span class="p">,</span>
 <span class="s1">&#39;low&#39;</span><span class="p">:</span> <span class="mf">0.6946830928837737</span><span class="p">,</span>
 <span class="s1">&#39;medium&#39;</span><span class="p">:</span> <span class="mf">0.22752877289674178</span><span class="p">}</span>
<span class="n">benchmark_array</span> <span class="o">=</span> <span class="p">[</span><span class="nb">round</span><span class="p">(</span><span class="mf">0.6946830928837737</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span><span class="nb">round</span><span class="p">(</span><span class="mf">0.22752877289674178</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span><span class="nb">round</span><span class="p">(</span><span class="mf">0.07778813421948452</span><span class="p">,</span><span class="mi">5</span><span class="p">)]</span>
<span class="c1">#benchmark_output = </span>
<span class="n">length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df_pre_train</span><span class="p">)</span>
<span class="n">benchmark_output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">benchmark_dict</span><span class="p">[</span><span class="s1">&#39;low&#39;</span><span class="p">],</span><span class="n">length</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">benchmark_dict</span><span class="p">[</span><span class="s1">&#39;medium&#39;</span><span class="p">],</span><span class="n">length</span><span class="p">),</span>
                            <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">benchmark_dict</span><span class="p">[</span><span class="s1">&#39;high&#39;</span><span class="p">],</span><span class="n">length</span><span class="p">)])</span>
<span class="n">benchmark_output</span> <span class="o">=</span> <span class="n">benchmark_output</span><span class="o">.</span><span class="n">T</span>

<span class="n">benchmark_score</span> <span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">df_pre_train_label_vector</span><span class="p">,</span> <span class="n">benchmark_output</span><span class="p">)</span>

<span class="c1">#used for some class_weight features</span>
<span class="n">cw_dict</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="nb">round</span><span class="p">(</span><span class="mf">0.6946830928837737</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span><span class="mi">1</span><span class="p">:</span><span class="nb">round</span><span class="p">(</span><span class="mf">0.22752877289674178</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span><span class="mi">2</span><span class="p">:</span><span class="nb">round</span><span class="p">(</span><span class="mf">0.07778813421948452</span><span class="p">,</span><span class="mi">5</span><span class="p">)}</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Benchmark Log Loss Score:&#39;</span><span class="p">,</span><span class="n">benchmark_score</span><span class="p">)</span>

<span class="n">length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_test2</span><span class="p">)</span>
<span class="n">benchmark_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">benchmark_dict</span><span class="p">[</span><span class="s1">&#39;low&#39;</span><span class="p">],</span><span class="n">length</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">benchmark_dict</span><span class="p">[</span><span class="s1">&#39;medium&#39;</span><span class="p">],</span><span class="n">length</span><span class="p">),</span>
                            <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">benchmark_dict</span><span class="p">[</span><span class="s1">&#39;high&#39;</span><span class="p">],</span><span class="n">length</span><span class="p">)])</span>
<span class="n">benchmark_test</span> <span class="o">=</span> <span class="n">benchmark_test</span><span class="o">.</span><span class="n">T</span>
<span class="n">benchmark_test_data_score</span> <span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">y_test2</span><span class="p">,</span> <span class="n">benchmark_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test Data Log Loss Score:&#39;</span><span class="p">,</span><span class="n">benchmark_test_data_score</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Benchmark Log Loss Score: 0.788576911432
Test Data Log Loss Score: 0.785216840872
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[34]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">log_loss</span>

<span class="n">benchmark_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;high&#39;</span><span class="p">:</span> <span class="mf">0.07778813421948452</span><span class="p">,</span>
 <span class="s1">&#39;low&#39;</span><span class="p">:</span> <span class="mf">0.6946830928837737</span><span class="p">,</span>
 <span class="s1">&#39;medium&#39;</span><span class="p">:</span> <span class="mf">0.22752877289674178</span><span class="p">}</span>

<span class="n">length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df_kaggle_test</span><span class="p">)</span>
<span class="c1">#print(length)</span>
<span class="n">benchmark_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">benchmark_dict</span><span class="p">[</span><span class="s1">&#39;low&#39;</span><span class="p">],</span><span class="n">length</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">benchmark_dict</span><span class="p">[</span><span class="s1">&#39;medium&#39;</span><span class="p">],</span><span class="n">length</span><span class="p">),</span>
                            <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">benchmark_dict</span><span class="p">[</span><span class="s1">&#39;high&#39;</span><span class="p">],</span><span class="n">length</span><span class="p">)])</span>
<span class="n">benchmark_2</span> <span class="o">=</span> <span class="n">benchmark_2</span><span class="o">.</span><span class="n">T</span>

<span class="n">df_bench_out</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;alisting_id&quot;</span><span class="p">:</span><span class="n">df_kaggle_test_pickle</span><span class="p">[</span><span class="s1">&#39;listing_id&#39;</span><span class="p">],</span><span class="s2">&quot;bhigh&quot;</span><span class="p">:</span><span class="n">benchmark_2</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span>
                       <span class="s2">&quot;cmedium&quot;</span><span class="p">:</span><span class="n">benchmark_2</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="s2">&quot;dlow&quot;</span><span class="p">:</span><span class="n">benchmark_2</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]})</span>
<span class="n">df_bench_out</span> <span class="o">=</span> <span class="n">df_bench_out</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span> <span class="s1">&#39;alisting_id&#39;</span><span class="p">:</span><span class="s1">&#39;listing_id&#39;</span><span class="p">,</span> <span class="s1">&#39;bhigh&#39;</span><span class="p">:</span><span class="s1">&#39;high&#39;</span><span class="p">,</span><span class="s1">&#39;cmedium&#39;</span><span class="p">:</span><span class="s1">&#39;medium&#39;</span>
                          <span class="p">,</span><span class="s1">&#39;dlow&#39;</span><span class="p">:</span><span class="s1">&#39;low&#39;</span><span class="p">})</span>

<span class="c1">#benchmark_score = log_loss(df_pre_train_label_vector, benchmark_output)  </span>
<span class="n">df_bench_out</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>

<span class="n">df_bench_out</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;renthop_bench_submission.csv&quot;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Submitted benchmark to Kaggle for testing and received a score of 0.79075&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.1-Logistic-Regression">2.1 Logistic Regression<a class="anchor-link" href="#2.1-Logistic-Regression">&#182;</a></h2><p>Logistic Regression does not need probability calibration. Thus uses GridSearchCV with "neg_log_loss" and not the custom scorer. I tried GridSearch with some different parameter configurations but the model failed to converge despite very high values for max_iter. Despite the data have different class distributions, class_weight of 'None' outperformed 'balanced' in every configuration.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[43]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="k">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">GridSearchCV</span>

<span class="c1">#gs_parameters = {&#39;solver&#39;:(&#39;sag&#39;),&#39;C&#39;:[,1,.3,1.0,1.5],&#39;max_iter&#39;:[10],&#39;class_weight&#39;:(&#39;balanced&#39;,None)}</span>
<span class="c1">#gs_parameters = {&#39;C&#39;:[.1,.3,1.0,1.5],&#39;max_iter&#39;:[100],&#39;class_weight&#39;:(&#39;balanced&#39;,None)}</span>
<span class="n">gs_parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;max_iter&#39;</span><span class="p">:[</span><span class="mi">100</span><span class="p">,</span><span class="mi">500</span><span class="p">,</span><span class="mi">1000</span><span class="p">,</span><span class="mi">2000</span><span class="p">,</span><span class="mi">5000</span><span class="p">],</span><span class="s1">&#39;class_weight&#39;</span><span class="p">:(</span><span class="s1">&#39;balanced&#39;</span><span class="p">,</span><span class="kc">None</span><span class="p">)}</span>
<span class="c1">#options: None for class_weight (getting beter results but not sure why), just sag as a solver</span>
<span class="c1">#&#39;solver&#39;:(&#39;sag&#39;,&#39;lbfgs&#39;,&#39;newton-cg&#39;)</span>
<span class="c1">#&#39;C&#39;:[.1,.3,1.0,1.5]</span>
<span class="c1">#tried some different C values, not much of a difference</span>

<span class="c1">#lr_model = LogisticRegression(random_state=0,solver=&#39;sag&#39;,multi_class=&#39;multinomial&#39;,class_weight=&#39;balanced&#39;,max_iter=1000,n_jobs=-1)</span>
<span class="n">lr_model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">,</span><span class="n">multi_class</span><span class="o">=</span><span class="s1">&#39;multinomial&#39;</span><span class="p">,</span><span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="c1">#500 iter lbfgs 0.623466269</span>
<span class="c1">#gs_lr_model = GridSearchCV(lr_model, param_grid=gs_parameters,scoring=&quot;neg_log_loss&quot;,cv=cv_sets)</span>
<span class="c1">#gs_lr_model.fit(X_train2,y_train2)</span>

<span class="n">lr_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train2</span><span class="p">,</span> <span class="n">y_train2</span><span class="p">)</span>
<span class="n">lr_predictions</span> <span class="o">=</span> <span class="n">lr_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test2</span><span class="p">)</span>
<span class="n">lr_score</span> <span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">y_test2</span><span class="p">,</span><span class="n">lr_predictions</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lr_score</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>0.623466269452
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#describe_grid_model(gs_lr_model)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[122]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;renthop_lr.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">lr_model</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.2-Random-Forest-Classifier">2.2 Random Forest Classifier<a class="anchor-link" href="#2.2-Random-Forest-Classifier">&#182;</a></h2><p>I fit the Random Forest by doing <a href="http://scikit-learn.org/stable/modules/calibration.html#calibration">probability calibration</a> due to how Random Forests can behave at certain probability ranges. I tested some different parameters like n_estimators, criterion, and min_sample_leaf before deciding on the model below.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[20]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="k">import</span> <span class="n">RandomForestClassifier</span>

<span class="n">rf_model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span><span class="n">oob_score</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span><span class="n">class_weight</span><span class="o">=</span><span class="s1">&#39;balanced_subsample&#39;</span><span class="p">,</span>
                                 <span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;gini&#39;</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1">#&#39;entropy&#39;,&#39;gini&#39;</span>

<span class="c1">#gs_parameters = {&#39;n_estimators&#39;:[100,200,500,1000],&#39;criterion&#39;:(&#39;gini&#39;,&#39;entropy&#39;)}</span>
<span class="c1">#gs_parameters = {&#39;n_estimators&#39;:[100,200,500,1000],&#39;criterion&#39;:(&#39;gini&#39;,&#39;entropy&#39;)}</span>
<span class="n">gs_parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:[</span><span class="mi">100</span><span class="p">,</span><span class="mi">200</span><span class="p">,</span><span class="mi">500</span><span class="p">,</span><span class="mi">1000</span><span class="p">]}</span> <span class="c1">#,&#39;criterion&#39;:(&#39;gini&#39;,&#39;entropy&#39;)</span>

<span class="c1"># gs_rf_model = GridSearchCV(rf_model, param_grid=gs_parameters,scoring=&quot;neg_log_loss&quot;,cv=cv_sets)</span>
<span class="n">gs_rf_model</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">rf_model</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">gs_parameters</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="n">custom_ccv_scorer</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">cv_sets</span><span class="p">)</span>
<span class="n">gs_rf_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train2</span><span class="p">,</span><span class="n">y_train2</span><span class="p">)</span>

<span class="c1"># rf_model.fit(X_train2,y_train2)</span>
<span class="c1"># rf_predictions = rf_model.predict_proba(X_test2)</span>
<span class="c1"># rf_score = log_loss(y_test2,rf_predictions)</span>
<span class="c1"># rf_score_ccv = custom_ccv_scorer(rf_model,X_test2,y_test2)</span>
<span class="c1"># print(rf_score,rf_score_ccv)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt output_prompt">Out[20]:</div>


<div class="output_text output_subarea output_execute_result">
<pre>GridSearchCV(cv=5, error_score=&#39;raise&#39;,
       estimator=RandomForestClassifier(bootstrap=True, class_weight=&#39;balanced_subsample&#39;,
            criterion=&#39;gini&#39;, max_depth=None, max_features=&#39;auto&#39;,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=2, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,
            oob_score=True, random_state=0, verbose=0, warm_start=False),
       fit_params={}, iid=True, n_jobs=1,
       param_grid={&#39;n_estimators&#39;: [100, 200, 500, 1000]},
       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=True,
       scoring=&lt;function custom_ccv_scorer at 0x00000000134D1EA0&gt;,
       verbose=0)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[84]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">describe_grid_model</span><span class="p">(</span><span class="n">gs_rf_model</span><span class="p">)</span>
<span class="c1">#print(gs_rf_model.cv_results_)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>CCV Score, Base Model Score: 0.44983942647 , 0.464199845765
0     {&#39;n_estimators&#39;: 100}
1     {&#39;n_estimators&#39;: 200}
2     {&#39;n_estimators&#39;: 500}
3    {&#39;n_estimators&#39;: 1000}
Name: params, dtype: object
0   -0.464240
1   -0.463038
2   -0.459915
3   -0.455477
Name: mean_test_score, dtype: float64
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The importance of the various features for the random forest model.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[264]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">gs_rf_model</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">,</span><span class="n">X_train2</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="nb">round</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>bathrooms 0.006
bedrooms_modified 0.014
price_modified 0.078
price_per_bed 0.084
created_hour 0.031
created_dow 0.022
created_day 0.036
created_month 0.013
description_length 0.046
features_count 0.027
apt_feature_elevator 0.005
apt_feature_cats 0.005
apt_feature_hardwood 0.006
apt_feature_dogs 0.005
apt_feature_doorman 0.004
apt_feature_dishwasher 0.006
apt_feature_no fee 0.011
apt_feature_laundry 0.006
apt_feature_fitness 0.004
apt_feature_pre-war 0.005
manager_count 0.041
manager_low 0.07
manager_medium 0.07
manager_high 0.077
building_count 0.038
building_low 0.061
building_medium 0.058
building_high 0.05
image_count 0.03
latitude_modified 0.044
longitude_modified 0.046
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[121]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;renthop_rf.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">gs_rf_model</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.3-Naive-Bayes">2.3 Naive Bayes<a class="anchor-link" href="#2.3-Naive-Bayes">&#182;</a></h2><p>From what I read on sklearn, Naive Bayes can be good as classifier but is known to be a bad estimator. Even though it is unlikely to be the best model, the model is so quick to train I did so anyway with the hope that it can be useful in a voting classifier situation.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[127]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="k">import</span> <span class="n">GaussianNB</span>

<span class="n">bnb_model</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">(</span><span class="n">priors</span><span class="o">=</span><span class="n">benchmark_array</span><span class="p">)</span>
<span class="n">bnb_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train2</span><span class="p">,</span><span class="n">y_train2</span><span class="p">)</span>
<span class="n">bnb_predictions</span> <span class="o">=</span> <span class="n">bnb_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test2</span><span class="p">)</span>
<span class="n">bnb_score</span> <span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">y_test2</span><span class="p">,</span><span class="n">bnb_predictions</span><span class="p">,</span><span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>

<span class="c1">#fit the CCV model for later use</span>
<span class="n">bnb_ccv</span> <span class="o">=</span> <span class="n">CalibratedClassifierCV</span><span class="p">(</span><span class="n">bnb_model</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;isotonic&quot;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="s2">&quot;prefit&quot;</span><span class="p">)</span> <span class="c1">#&#39;isotonic&#39; or &#39;sigmoid&#39;</span>
<span class="n">bnb_ccv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_val2</span><span class="p">,</span><span class="n">y_val2</span><span class="p">)</span>
<span class="n">bnb_ccv_predictions</span> <span class="o">=</span> <span class="n">bnb_ccv</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test2</span><span class="p">)</span>
<span class="n">bnb_ccv_score</span> <span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">y_test2</span><span class="p">,</span><span class="n">bnb_ccv_predictions</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">bnb_score</span><span class="p">,</span> <span class="n">bnb_ccv_score</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>2.05159284343 0.708279179393
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[120]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;renthop_nb.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">bnb_ccv</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.3-Stochastic-Gradient-Descent">2.3 Stochastic Gradient Descent<a class="anchor-link" href="#2.3-Stochastic-Gradient-Descent">&#182;</a></h2><p>Modified huber and log are the only loss arguments that work with predicting probabilities. I tried handtuning some of the other parameters before settling on the ones below.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[39]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="k">import</span> <span class="n">SGDClassifier</span>

<span class="n">sgd_model</span> <span class="o">=</span> <span class="n">SGDClassifier</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;modified_huber&#39;</span><span class="p">,</span><span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l2&#39;</span><span class="p">,</span><span class="n">n_iter</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span><span class="n">class_weight</span><span class="o">=</span><span class="s1">&#39;balanced&#39;</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="s1">&#39;optimal&#39;</span><span class="p">)</span>
<span class="c1">#sgd_model = SGDClassifier(loss=&#39;modified_huber&#39;,penalty=&#39;l2&#39;,n_iter=100,class_weight=&#39;balanced&#39;,learning_rate=&#39;optimal&#39;)</span>
<span class="c1">#penalty : str, none, l2, l1, or elasticnet</span>

<span class="n">sgd_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train2</span><span class="p">,</span><span class="n">y_train2</span><span class="p">)</span>
<span class="n">sgd_predictions</span> <span class="o">=</span> <span class="n">sgd_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">sgd_predictions</span><span class="p">)))</span>
<span class="n">sgd_score</span> <span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">y_test2</span><span class="p">,</span><span class="n">sgd_predictions</span><span class="p">)</span>

<span class="n">sgd_ccv</span> <span class="o">=</span> <span class="n">CalibratedClassifierCV</span><span class="p">(</span><span class="n">sgd_model</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;isotonic&quot;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="s2">&quot;prefit&quot;</span><span class="p">)</span>
<span class="n">sgd_ccv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_val2</span><span class="p">,</span><span class="n">y_val2</span><span class="p">)</span>
<span class="n">sgd_ccv_predictions</span> <span class="o">=</span> <span class="n">sgd_ccv</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test2</span><span class="p">)</span>
<span class="n">sgd_ccv_score</span> <span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">y_test2</span><span class="p">,</span><span class="n">sgd_ccv_predictions</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">sgd_score</span><span class="p">,</span><span class="n">sgd_ccv_score</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>[0 0 0]
6.44114507959 0.681982141406
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[119]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;renthop_sgd.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">sgd_ccv</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.4-K-Nearest-Neighbors">2.4 K-Nearest Neighbors<a class="anchor-link" href="#2.4-K-Nearest-Neighbors">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[71]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="k">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">GridSearchCV</span>

<span class="n">knn_model</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">weights</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span><span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>

<span class="c1">#gs_parameters = {&#39;n_neighbors&#39;:[5,10],&#39;weights&#39;:(&#39;uniform&#39;,&#39;distance&#39;),&#39;p&#39;:[1,2]}</span>
<span class="n">gs_parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_neighbors&#39;</span><span class="p">:[</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">15</span><span class="p">,</span><span class="mi">20</span><span class="p">]}</span>
<span class="n">gs_knn_model</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">knn_model</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">gs_parameters</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="n">custom_ccv_scorer</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">cv_sets</span><span class="p">)</span>
<span class="n">gs_knn_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train2</span><span class="p">,</span><span class="n">y_train2</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt output_prompt">Out[71]:</div>


<div class="output_text output_subarea output_execute_result">
<pre>GridSearchCV(cv=5, error_score=&#39;raise&#39;,
       estimator=KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights=&#39;uniform&#39;),
       fit_params={}, iid=True, n_jobs=1,
       param_grid={&#39;n_neighbors&#39;: [5, 10, 15, 20]},
       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=True,
       scoring=&lt;function custom_ccv_scorer at 0x00000000134D1EA0&gt;,
       verbose=0)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[83]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">describe_grid_model</span><span class="p">(</span><span class="n">gs_knn_model</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>CCV Score, Base Model Score: 0.683435326532 , 1.00908464346
0     {&#39;n_neighbors&#39;: 5}
1    {&#39;n_neighbors&#39;: 10}
2    {&#39;n_neighbors&#39;: 15}
3    {&#39;n_neighbors&#39;: 20}
Name: params, dtype: object
0   -0.723601
1   -0.707703
2   -0.702463
3   -0.697843
Name: mean_test_score, dtype: float64
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[118]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;renthop_knn.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">gs_knn_model</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.5-Adaboost">2.5 Adaboost<a class="anchor-link" href="#2.5-Adaboost">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[93]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="k">import</span> <span class="n">AdaBoostClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="k">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">RandomizedSearchCV</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="k">import</span> <span class="n">randint</span> <span class="k">as</span> <span class="n">sp_randint</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="k">import</span> <span class="n">uniform</span> <span class="k">as</span> <span class="n">sp_rand</span>

<span class="n">ada_model</span> <span class="o">=</span> <span class="n">AdaBoostClassifier</span><span class="p">(</span>
    <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">class_weight</span><span class="o">=</span><span class="s1">&#39;balanced&#39;</span><span class="p">),</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;search_parameters = {&#39;n_estimators&#39;:sp_randint(30,301),</span>
<span class="sd">                    &#39;learning_rate&#39;:sp_randint(0,2)}&#39;&#39;&#39;</span>

<span class="n">search_parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span><span class="n">sp_randint</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span><span class="mi">1001</span><span class="p">),</span>
                    <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span><span class="n">sp_rand</span><span class="p">(</span><span class="o">.</span><span class="mi">001</span><span class="p">,</span><span class="mf">1.0</span><span class="p">)}</span>

<span class="n">rs_ada_model</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">ada_model</span><span class="p">,</span><span class="n">param_distributions</span><span class="o">=</span><span class="n">search_parameters</span><span class="p">,</span>
                                  <span class="n">scoring</span><span class="o">=</span><span class="n">custom_ccv_scorer</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">cv_sets</span><span class="p">,</span><span class="n">n_iter</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">rs_ada_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train2</span><span class="p">,</span><span class="n">y_train2</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt output_prompt">Out[93]:</div>


<div class="output_text output_subarea output_execute_result">
<pre>RandomizedSearchCV(cv=5, error_score=&#39;raise&#39;,
          estimator=AdaBoostClassifier(algorithm=&#39;SAMME.R&#39;,
          base_estimator=DecisionTreeClassifier(class_weight=&#39;balanced&#39;, criterion=&#39;gini&#39;,
            max_depth=None, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter=&#39;best&#39;),
          learning_rate=1, n_estimators=100, random_state=None),
          fit_params={}, iid=True, n_iter=20, n_jobs=1,
          param_distributions={&#39;n_estimators&#39;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x000000000C0EE630&gt;, &#39;learning_rate&#39;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x000000000C0EE5F8&gt;},
          pre_dispatch=&#39;2*n_jobs&#39;, random_state=None, refit=True,
          return_train_score=True,
          scoring=&lt;function custom_ccv_scorer at 0x00000000134D1EA0&gt;,
          verbose=0)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[94]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">describe_grid_model</span><span class="p">(</span><span class="n">rs_ada_model</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>CCV Score, Base Model Score: 0.571028009793 , 6.80698024587
0     {&#39;learning_rate&#39;: 0.256575792242, &#39;n_estimator...
1     {&#39;learning_rate&#39;: 0.390324400716, &#39;n_estimator...
2     {&#39;learning_rate&#39;: 0.363187239991, &#39;n_estimator...
3     {&#39;learning_rate&#39;: 0.526237999985, &#39;n_estimator...
4     {&#39;learning_rate&#39;: 0.0751293632145, &#39;n_estimato...
5     {&#39;learning_rate&#39;: 0.516407308051, &#39;n_estimator...
6     {&#39;learning_rate&#39;: 0.380997049204, &#39;n_estimator...
7     {&#39;learning_rate&#39;: 0.481041633657, &#39;n_estimator...
8     {&#39;learning_rate&#39;: 0.653737793866, &#39;n_estimator...
9     {&#39;learning_rate&#39;: 0.0746083497833, &#39;n_estimato...
10    {&#39;learning_rate&#39;: 0.937062793119, &#39;n_estimator...
11    {&#39;learning_rate&#39;: 0.375701038393, &#39;n_estimator...
12    {&#39;learning_rate&#39;: 0.824547959806, &#39;n_estimator...
13    {&#39;learning_rate&#39;: 0.521307485454, &#39;n_estimator...
14    {&#39;learning_rate&#39;: 0.142927095424, &#39;n_estimator...
15    {&#39;learning_rate&#39;: 0.700549787568, &#39;n_estimator...
16    {&#39;learning_rate&#39;: 0.106887650733, &#39;n_estimator...
17    {&#39;learning_rate&#39;: 0.332770856249, &#39;n_estimator...
18    {&#39;learning_rate&#39;: 0.587050679356, &#39;n_estimator...
19    {&#39;learning_rate&#39;: 0.694941898933, &#39;n_estimator...
Name: params, dtype: object
0    -0.605836
1    -0.602284
2    -0.603434
3    -0.603873
4    -0.605057
5    -0.605245
6    -0.603581
7    -0.602636
8    -0.604927
9    -0.603739
10   -0.606324
11   -0.604624
12   -0.604098
13   -0.606578
14   -0.603182
15   -0.606367
16   -0.606520
17   -0.604594
18   -0.603426
19   -0.603432
Name: mean_test_score, dtype: float64
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[96]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">rs_ada_model</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">rs_ada_model</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>({&#39;learning_rate&#39;: 0.25657579224205407, &#39;n_estimators&#39;: 493}, {&#39;learning_rate&#39;: 0.39032440071569308, &#39;n_estimators&#39;: 919}, {&#39;learning_rate&#39;: 0.36318723999090974, &#39;n_estimators&#39;: 797}, {&#39;learning_rate&#39;: 0.52623799998468779, &#39;n_estimators&#39;: 399}, {&#39;learning_rate&#39;: 0.075129363214500589, &#39;n_estimators&#39;: 754}, {&#39;learning_rate&#39;: 0.51640730805095747, &#39;n_estimators&#39;: 854}, {&#39;learning_rate&#39;: 0.38099704920395472, &#39;n_estimators&#39;: 684}, {&#39;learning_rate&#39;: 0.48104163365710395, &#39;n_estimators&#39;: 754}, {&#39;learning_rate&#39;: 0.65373779386578224, &#39;n_estimators&#39;: 687}, {&#39;learning_rate&#39;: 0.074608349783252148, &#39;n_estimators&#39;: 388}, {&#39;learning_rate&#39;: 0.9370627931185338, &#39;n_estimators&#39;: 613}, {&#39;learning_rate&#39;: 0.37570103839341984, &#39;n_estimators&#39;: 571}, {&#39;learning_rate&#39;: 0.82454795980633244, &#39;n_estimators&#39;: 885}, {&#39;learning_rate&#39;: 0.52130748545354844, &#39;n_estimators&#39;: 429}, {&#39;learning_rate&#39;: 0.14292709542375748, &#39;n_estimators&#39;: 444}, {&#39;learning_rate&#39;: 0.70054978756757424, &#39;n_estimators&#39;: 451}, {&#39;learning_rate&#39;: 0.10688765073333828, &#39;n_estimators&#39;: 614}, {&#39;learning_rate&#39;: 0.33277085624918201, &#39;n_estimators&#39;: 423}, {&#39;learning_rate&#39;: 0.58705067935556965, &#39;n_estimators&#39;: 890}, {&#39;learning_rate&#39;: 0.69494189893297587, &#39;n_estimators&#39;: 964})
AdaBoostClassifier(algorithm=&#39;SAMME.R&#39;,
          base_estimator=DecisionTreeClassifier(class_weight=&#39;balanced&#39;, criterion=&#39;gini&#39;,
            max_depth=None, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter=&#39;best&#39;),
          learning_rate=0.39032440071569308, n_estimators=919,
          random_state=None)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Most important features for the Adaboost model.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[97]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">rs_ada_model</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">,</span><span class="n">X_train2</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="nb">round</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>bathrooms 0.002
bedrooms_modified 0.005
price_modified 0.087
price_per_bed 0.082
created_hour 0.02
created_dow 0.015
created_day 0.028
created_month 0.006
description_length 0.043
features_count 0.019
apt_feature_elevator 0.004
apt_feature_cats 0.002
apt_feature_hardwood 0.002
apt_feature_dogs 0.002
apt_feature_doorman 0.002
apt_feature_dishwasher 0.001
apt_feature_no fee 0.006
apt_feature_laundry 0.004
apt_feature_fitness 0.001
apt_feature_pre-war 0.004
manager_count 0.028
manager_low 0.105
manager_medium 0.105
manager_high 0.181
building_count 0.013
building_low 0.03
building_medium 0.055
building_high 0.05
image_count 0.019
latitude_modified 0.042
longitude_modified 0.037
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[117]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;renthop_ada.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">rs_ada_model</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.6-Gradient-Boosting">2.6 Gradient Boosting<a class="anchor-link" href="#2.6-Gradient-Boosting">&#182;</a></h2><p>I installed and implemented the XGBoost package. Some of the code for this part is from an <a href="https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/">example I found online</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[106]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="nn">xgb</span>

<span class="n">gb_model</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
                             <span class="n">objective</span><span class="o">=</span><span class="s1">&#39;binary:logistic&#39;</span><span class="p">)</span>
<span class="c1">#objective multi:softprob</span>
<span class="c1">#&quot;objective&quot; = &quot;multi:softprob&quot;,    # multiclass classification </span>
<span class="c1">#              &quot;num_class&quot; = 3,    # number of classes </span>

<span class="n">gs_parameters</span> <span class="o">=</span> <span class="p">{</span>   
    <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span><span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span>
    <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span><span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">500</span><span class="p">,</span><span class="mi">50</span><span class="p">),</span>
    <span class="s1">&#39;learning_rate&#39;</span><span class="p">:[</span><span class="mf">0.05</span><span class="p">,</span><span class="mf">0.10</span><span class="p">,</span><span class="mf">0.20</span><span class="p">,</span><span class="mf">0.30</span><span class="p">]</span>
<span class="p">}</span>
<span class="n">gs_gb_model</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">gb_model</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">gs_parameters</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;neg_log_loss&quot;</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">cv_sets</span><span class="p">)</span>
<span class="n">gs_gb_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train2</span><span class="p">,</span><span class="n">y_train2</span><span class="p">)</span> <span class="c1">#eval_metric=&quot;mlogloss &quot;</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt output_prompt">Out[106]:</div>


<div class="output_text output_subarea output_execute_result">
<pre>GridSearchCV(cv=5, error_score=&#39;raise&#39;,
       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,
       gamma=0, learning_rate=0.05, max_delta_step=0, max_depth=6,
       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,
       objective=&#39;binary:logistic&#39;, reg_alpha=0, reg_lambda=1,
       scale_pos_weight=1, seed=0, silent=True, subsample=1),
       fit_params={}, iid=True, n_jobs=1,
       param_grid={&#39;n_estimators&#39;: range(100, 500, 50), &#39;learning_rate&#39;: [0.05, 0.1, 0.2, 0.3], &#39;max_depth&#39;: range(3, 10, 2)},
       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=True,
       scoring=&#39;neg_log_loss&#39;, verbose=0)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[108]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#describe_grid_model(gs_gb_model)</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">gs_gb_model</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test2</span><span class="p">)</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">y_test2</span><span class="p">,</span><span class="n">predictions</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>0.246955397986
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>While the log loss of the xgboost model was on the test data was incredibly low, this was due to the model overfitting. When I submitted this model on Kaggle, the model performed about as well as the benchmark set. <br/>
Feature importance of xgboost model.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[123]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">feat_imp</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">gs_gb_model</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">booster</span><span class="p">()</span><span class="o">.</span><span class="n">get_fscore</span><span class="p">())</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">feat_imp</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Feature Importances&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Feature Importance Score&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>


<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYgAAAF2CAYAAAB02w9PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[111]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pickle</span>
<span class="c1"># now you can save it to a file</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;renthop_xgb.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">gs_gb_model</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.7-Voting-Classifier">2.7 Voting Classifier<a class="anchor-link" href="#2.7-Voting-Classifier">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[131]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="k">import</span> <span class="n">VotingClassifier</span>

<span class="c1">#vc_model = VotingClassifier(estimators=[(&#39;dt&#39;, clf1), (&#39;knn&#39;, clf2), (&#39;svc&#39;, clf3)], voting=&#39;soft&#39;, weights=[2,1,2])</span>
<span class="c1">#rf: gs_rf_model.best_estimator_</span>
<span class="c1">#lr: lr_model</span>
<span class="c1">#knn: gs_knn_model.best_estimator_</span>
<span class="c1">#nb: bnb_model</span>
<span class="c1">#sgd: sgd_model</span>
<span class="c1">#gb: gs_gb_model.best_estimator_</span>
<span class="c1">#ada: rs_ada_model.best_estimator_</span>

<span class="n">vc_model</span> <span class="o">=</span> <span class="n">VotingClassifier</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;rf&#39;</span><span class="p">,</span> <span class="n">gs_rf_model</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="n">lr_model</span><span class="p">),</span> 
                                        <span class="p">(</span><span class="s1">&#39;knn&#39;</span><span class="p">,</span> <span class="n">gs_knn_model</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;gb&#39;</span><span class="p">,</span> <span class="n">gs_gb_model</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">),</span> 
                                        <span class="p">(</span><span class="s1">&#39;nb&#39;</span><span class="p">,</span> <span class="n">bnb_model</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;sgd&#39;</span><span class="p">,</span> <span class="n">sgd_model</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;ada&#39;</span><span class="p">,</span> <span class="n">rs_ada_model</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">)],</span> <span class="n">voting</span><span class="o">=</span><span class="s1">&#39;soft&#39;</span><span class="p">)</span>
<span class="c1">#vc_model = VotingClassifier(estimators=[(&#39;nb&#39;, bnb_model), (&#39;lr&#39;, lr_model)], voting=&#39;soft&#39;)</span>

<span class="n">vc_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train2</span><span class="p">,</span><span class="n">y_train2</span><span class="p">)</span>
<span class="n">vc_predictions</span> <span class="o">=</span> <span class="n">vc_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test2</span><span class="p">)</span>
<span class="n">vc_score</span> <span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">y_test2</span><span class="p">,</span><span class="n">vc_predictions</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vc_score</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>0.48769409224
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The voting classifier model received a 0.65518 on Kaggle. Better than the other models I submitted (xgboost, the benchmark, and random forest) but still not as well as the log loss on the test data indicated.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[132]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;renthop_vc.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">vc_model</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="3.0-Feature-Selection">3.0 Feature Selection<a class="anchor-link" href="#3.0-Feature-Selection">&#182;</a></h2><p>From what I have read, typically feature selection is done prior to model fitting or in a conjunction with a pipeline. However I decided to do it after fitting a model for a couple of reasons. First, I thought that some bad features that are mostly the same (like almost all bathrooms being equal to 1) would still have some predictive value for the bad inputs. Second, I created many new input features and wanted to get a sense of how they contributed to various models prior to me creating them and then immediately cutting them.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>SelectFromModel feature selection: takes an already fitted model and prunes down the features deemed unnecessary.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#convenience function to see which features are kept or dropped</span>
<span class="k">def</span> <span class="nf">print_selected_features</span><span class="p">(</span><span class="n">column_names</span><span class="p">,</span><span class="n">clf</span><span class="p">):</span>
    <span class="n">features_bool</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">get_support</span><span class="p">()</span>
    <span class="c1">#print(&quot;Kept Features&quot;,column_names[features_bool])</span>
    <span class="nb">print</span><span class="p">(</span> <span class="s2">&quot;Kept Features&quot;</span><span class="p">,</span> <span class="n">column_names</span> <span class="o">*</span> <span class="n">features_bool</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="p">[</span><span class="ow">not</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">features_bool</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span> <span class="s2">&quot;Dropped Features&quot;</span><span class="p">,</span> <span class="n">column_names</span> <span class="o">*</span> <span class="n">z</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[217]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="k">import</span> <span class="n">SelectFromModel</span>

<span class="n">sfm_rf_model</span> <span class="o">=</span> <span class="n">SelectFromModel</span><span class="p">(</span><span class="n">gs_rf_model</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">,</span> <span class="n">prefit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1">#X_transform = sfm_model.transform(X_train2)</span>
<span class="c1">#print_selected_features(X_train2.columns.values,sfm_rf_model)</span>

<span class="n">sfm_xgb_model</span> <span class="o">=</span> <span class="n">SelectFromModel</span><span class="p">(</span><span class="n">gs_gb_model</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">,</span> <span class="n">prefit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1">#X_transform = sfm_model.transform(X_train2)</span>
<span class="c1">#print_selected_features(X_train2.columns.values,sfm_xgb_model)</span>

<span class="n">sfm_ada_model</span> <span class="o">=</span> <span class="n">SelectFromModel</span><span class="p">(</span><span class="n">rs_ada_model</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">,</span> <span class="n">prefit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1">#X_transform = sfm_model.transform(X_train2)</span>
<span class="c1">#print_selected_features(X_train2.columns.values,sfm_ada_model)</span>

<span class="n">sfm_lr_model</span> <span class="o">=</span> <span class="n">SelectFromModel</span><span class="p">(</span><span class="n">lr_model</span><span class="p">,</span> <span class="n">prefit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1">#X_transform = sfm_model.transform(X_train2)</span>
<span class="c1">#print_selected_features(X_train2.columns.values,sfm_lr_model)</span>

<span class="n">sfm_sgd_model</span> <span class="o">=</span> <span class="n">SelectFromModel</span><span class="p">(</span><span class="n">sgd_model</span><span class="p">,</span> <span class="n">prefit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1">#X_transform = sfm_model.transform(X_train2)</span>
<span class="c1">#print_selected_features(X_train2.columns.values,sfm_sgd_model)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[214]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_sfm</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;0_features&#39;</span><span class="p">:</span><span class="n">X_train2</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="p">,</span><span class="s1">&#39;rf&#39;</span><span class="p">:</span><span class="n">sfm_rf_model</span><span class="o">.</span><span class="n">get_support</span><span class="p">(),</span>
                      <span class="s1">&#39;xgb&#39;</span><span class="p">:</span><span class="n">sfm_xgb_model</span><span class="o">.</span><span class="n">get_support</span><span class="p">(),</span><span class="s1">&#39;lr&#39;</span><span class="p">:</span><span class="n">sfm_lr_model</span><span class="o">.</span><span class="n">get_support</span><span class="p">(),</span>
                      <span class="s1">&#39;ada&#39;</span><span class="p">:</span><span class="n">sfm_ada_model</span><span class="o">.</span><span class="n">get_support</span><span class="p">(),</span><span class="s1">&#39;sgd&#39;</span><span class="p">:</span><span class="n">sfm_sgd_model</span><span class="o">.</span><span class="n">get_support</span><span class="p">()})</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_sfm</span><span class="p">)</span>
<span class="c1">#print( sum(df_sfm[:,2:5]))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">df_sfm</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df_temp</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;0_features&#39;</span><span class="p">:</span><span class="n">X_train2</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="p">,</span><span class="s2">&quot;sum&quot;</span><span class="p">:</span><span class="n">x</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_temp</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>                0_features    ada     lr     rf    sgd    xgb
0                bathrooms  False   True  False   True  False
1        bedrooms_modified  False   True  False  False  False
2           price_modified   True   True   True   True   True
3            price_per_bed   True   True   True   True   True
4             created_hour  False  False  False  False  False
5              created_dow  False  False  False  False  False
6              created_day  False  False   True  False   True
7            created_month  False  False  False  False  False
8       description_length   True  False   True  False   True
9           features_count  False  False  False  False  False
10    apt_feature_elevator  False  False  False   True  False
11        apt_feature_cats  False  False  False  False  False
12    apt_feature_hardwood  False  False  False  False  False
13        apt_feature_dogs  False  False  False  False  False
14     apt_feature_doorman  False  False  False   True  False
15  apt_feature_dishwasher  False  False  False  False  False
16      apt_feature_no fee  False   True  False   True  False
17     apt_feature_laundry  False   True  False  False  False
18     apt_feature_fitness  False  False  False  False  False
19     apt_feature_pre-war  False   True  False  False  False
20           manager_count  False  False   True  False   True
21             manager_low   True  False   True  False   True
22          manager_medium   True  False   True  False   True
23            manager_high   True  False   True  False   True
24          building_count  False  False   True  False  False
25            building_low  False  False   True  False   True
26         building_medium   True  False   True  False   True
27           building_high   True  False   True  False  False
28             image_count  False  False  False  False  False
29       latitude_modified   True  False   True  False   True
30      longitude_modified   True   True   True  False   True
                0_features  sum
0                bathrooms    2
1        bedrooms_modified    1
2           price_modified    5
3            price_per_bed    5
4             created_hour    0
5              created_dow    0
6              created_day    2
7            created_month    0
8       description_length    3
9           features_count    0
10    apt_feature_elevator    1
11        apt_feature_cats    0
12    apt_feature_hardwood    0
13        apt_feature_dogs    0
14     apt_feature_doorman    1
15  apt_feature_dishwasher    0
16      apt_feature_no fee    2
17     apt_feature_laundry    1
18     apt_feature_fitness    0
19     apt_feature_pre-war    1
20           manager_count    2
21             manager_low    3
22          manager_medium    3
23            manager_high    3
24          building_count    1
25            building_low    2
26         building_medium    3
27           building_high    2
28             image_count    0
29       latitude_modified    3
30      longitude_modified    4
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>From the SelectFromModel analysis, the five models that have feature importance or coef attributes show what features were important to them. The unimportant features that all models agreed upon: 'created_hour', 'created_dow','created_month','features_count', many of the one hot apartment features, and 'image_count'. <br/></p>
<p>Image count not mattering surprised me a bit and led me to look again at a table of image_count vs. % of low, medium, and high (which in hindsight I should have done initially). 95% of listings with no images are low interest. The results of this analysis strongly suggest either simplifying image_count into 0 for no images and 1 for any or simplifying the dimensionality to something lower (like 0,1,2, and 3 or more).<br/></p>
<p>The 'created_x' data did not prove useful with maybe the exception of created day (day of the month). Perhaps eliminating some features or simplifying the data into ranges would help.</p>
<p>Feature_count and almost none of the 'apt_feature_x' (with maybe the exception of 'no fee') were deemed helpful. Perhaps there is some feature elimination, combination, or a natural language processing technique I should consider.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="3.2-Variance-Threshold-Feature-Selection">3.2 Variance Threshold Feature Selection<a class="anchor-link" href="#3.2-Variance-Threshold-Feature-Selection">&#182;</a></h3><p>Analysis of which features do not have high variance. Would obviously want to eliminate any features that have 0 variance (as no new information is gained). Can consider elimination, combination, or transformation of low variance features; particularly in consideration with other insights gained from feature selection.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[245]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="k">import</span> <span class="n">VarianceThreshold</span>

<span class="n">vt</span> <span class="o">=</span> <span class="n">VarianceThreshold</span><span class="p">()</span>
<span class="n">X_transformed</span> <span class="o">=</span> <span class="n">vt</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train2</span><span class="p">)</span>
<span class="n">column_names</span> <span class="o">=</span> <span class="n">X_train2</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span>

<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">/</span><span class="mi">10</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">column_names</span><span class="p">[</span><span class="n">vt</span><span class="o">.</span><span class="n">variances_</span> <span class="o">&lt;=</span> <span class="n">x</span><span class="p">])</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Threshold: &#39;</span><span class="p">,</span><span class="n">x</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">column_names</span><span class="p">[</span><span class="n">vt</span><span class="o">.</span><span class="n">variances_</span> <span class="o">&lt;=</span> <span class="n">x</span><span class="p">]),</span><span class="n">column_names</span><span class="p">[</span><span class="n">vt</span><span class="o">.</span><span class="n">variances_</span> <span class="o">&lt;=</span> <span class="n">x</span><span class="p">])</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Threshold:  0.2 2 [&#39;apt_feature_fitness&#39; &#39;apt_feature_pre-war&#39;]
Threshold:  0.3 11 [&#39;bathrooms&#39; &#39;apt_feature_elevator&#39; &#39;apt_feature_cats&#39;
 &#39;apt_feature_hardwood&#39; &#39;apt_feature_dogs&#39; &#39;apt_feature_doorman&#39;
 &#39;apt_feature_dishwasher&#39; &#39;apt_feature_no fee&#39; &#39;apt_feature_laundry&#39;
 &#39;apt_feature_fitness&#39; &#39;apt_feature_pre-war&#39;]
Threshold:  0.4 11 [&#39;bathrooms&#39; &#39;apt_feature_elevator&#39; &#39;apt_feature_cats&#39;
 &#39;apt_feature_hardwood&#39; &#39;apt_feature_dogs&#39; &#39;apt_feature_doorman&#39;
 &#39;apt_feature_dishwasher&#39; &#39;apt_feature_no fee&#39; &#39;apt_feature_laundry&#39;
 &#39;apt_feature_fitness&#39; &#39;apt_feature_pre-war&#39;]
Threshold:  0.5 11 [&#39;bathrooms&#39; &#39;apt_feature_elevator&#39; &#39;apt_feature_cats&#39;
 &#39;apt_feature_hardwood&#39; &#39;apt_feature_dogs&#39; &#39;apt_feature_doorman&#39;
 &#39;apt_feature_dishwasher&#39; &#39;apt_feature_no fee&#39; &#39;apt_feature_laundry&#39;
 &#39;apt_feature_fitness&#39; &#39;apt_feature_pre-war&#39;]
Threshold:  0.6 11 [&#39;bathrooms&#39; &#39;apt_feature_elevator&#39; &#39;apt_feature_cats&#39;
 &#39;apt_feature_hardwood&#39; &#39;apt_feature_dogs&#39; &#39;apt_feature_doorman&#39;
 &#39;apt_feature_dishwasher&#39; &#39;apt_feature_no fee&#39; &#39;apt_feature_laundry&#39;
 &#39;apt_feature_fitness&#39; &#39;apt_feature_pre-war&#39;]
Threshold:  0.7 12 [&#39;bathrooms&#39; &#39;created_month&#39; &#39;apt_feature_elevator&#39; &#39;apt_feature_cats&#39;
 &#39;apt_feature_hardwood&#39; &#39;apt_feature_dogs&#39; &#39;apt_feature_doorman&#39;
 &#39;apt_feature_dishwasher&#39; &#39;apt_feature_no fee&#39; &#39;apt_feature_laundry&#39;
 &#39;apt_feature_fitness&#39; &#39;apt_feature_pre-war&#39;]
Threshold:  0.8 12 [&#39;bathrooms&#39; &#39;created_month&#39; &#39;apt_feature_elevator&#39; &#39;apt_feature_cats&#39;
 &#39;apt_feature_hardwood&#39; &#39;apt_feature_dogs&#39; &#39;apt_feature_doorman&#39;
 &#39;apt_feature_dishwasher&#39; &#39;apt_feature_no fee&#39; &#39;apt_feature_laundry&#39;
 &#39;apt_feature_fitness&#39; &#39;apt_feature_pre-war&#39;]
Threshold:  0.9 13 [&#39;bathrooms&#39; &#39;bedrooms_modified&#39; &#39;created_month&#39; &#39;apt_feature_elevator&#39;
 &#39;apt_feature_cats&#39; &#39;apt_feature_hardwood&#39; &#39;apt_feature_dogs&#39;
 &#39;apt_feature_doorman&#39; &#39;apt_feature_dishwasher&#39; &#39;apt_feature_no fee&#39;
 &#39;apt_feature_laundry&#39; &#39;apt_feature_fitness&#39; &#39;apt_feature_pre-war&#39;]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="SelectKBest">SelectKBest<a class="anchor-link" href="#SelectKBest">&#182;</a></h3><p>Method of dropping features. Once again, the 'created_x' features did not add much to the model.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[257]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="k">import</span> <span class="n">SelectKBest</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="k">import</span> <span class="n">f_classif</span> <span class="c1">#chi2</span>

<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="mi">30</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">sk_best_model</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">f_classif</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
    <span class="n">X_new</span> <span class="o">=</span> <span class="n">sk_best_model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train2</span><span class="p">,</span> <span class="n">y_train2</span><span class="p">)</span>
    <span class="n">print_selected_features</span><span class="p">(</span><span class="n">X_train2</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="p">,</span><span class="n">sk_best_model</span><span class="p">)</span>
    
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Kept Features [&#39;bathrooms&#39; &#39;bedrooms_modified&#39; &#39;price_modified&#39; &#39;price_per_bed&#39;
 &#39;created_hour&#39; &#39;&#39; &#39;created_day&#39; &#39;created_month&#39; &#39;description_length&#39;
 &#39;features_count&#39; &#39;apt_feature_elevator&#39; &#39;apt_feature_cats&#39;
 &#39;apt_feature_hardwood&#39; &#39;apt_feature_dogs&#39; &#39;apt_feature_doorman&#39;
 &#39;apt_feature_dishwasher&#39; &#39;apt_feature_no fee&#39; &#39;apt_feature_laundry&#39;
 &#39;apt_feature_fitness&#39; &#39;apt_feature_pre-war&#39; &#39;manager_count&#39; &#39;manager_low&#39;
 &#39;manager_medium&#39; &#39;manager_high&#39; &#39;building_count&#39; &#39;building_low&#39;
 &#39;building_medium&#39; &#39;building_high&#39; &#39;image_count&#39; &#39;latitude_modified&#39;
 &#39;longitude_modified&#39;]
Dropped Features [&#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;created_dow&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39;
 &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39;]
Kept Features [&#39;bathrooms&#39; &#39;bedrooms_modified&#39; &#39;price_modified&#39; &#39;price_per_bed&#39;
 &#39;created_hour&#39; &#39;&#39; &#39;created_day&#39; &#39;&#39; &#39;description_length&#39; &#39;features_count&#39;
 &#39;&#39; &#39;apt_feature_cats&#39; &#39;apt_feature_hardwood&#39; &#39;apt_feature_dogs&#39;
 &#39;apt_feature_doorman&#39; &#39;apt_feature_dishwasher&#39; &#39;apt_feature_no fee&#39;
 &#39;apt_feature_laundry&#39; &#39;apt_feature_fitness&#39; &#39;apt_feature_pre-war&#39; &#39;&#39;
 &#39;manager_low&#39; &#39;manager_medium&#39; &#39;manager_high&#39; &#39;building_count&#39;
 &#39;building_low&#39; &#39;building_medium&#39; &#39;building_high&#39; &#39;image_count&#39;
 &#39;latitude_modified&#39; &#39;longitude_modified&#39;]
Dropped Features [&#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;created_dow&#39; &#39;&#39; &#39;created_month&#39; &#39;&#39; &#39;&#39;
 &#39;apt_feature_elevator&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;manager_count&#39; &#39;&#39; &#39;&#39; &#39;&#39;
 &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39;]
Kept Features [&#39;bathrooms&#39; &#39;bedrooms_modified&#39; &#39;price_modified&#39; &#39;price_per_bed&#39;
 &#39;created_hour&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;description_length&#39; &#39;features_count&#39; &#39;&#39;
 &#39;apt_feature_cats&#39; &#39;apt_feature_hardwood&#39; &#39;apt_feature_dogs&#39;
 &#39;apt_feature_doorman&#39; &#39;apt_feature_dishwasher&#39; &#39;apt_feature_no fee&#39;
 &#39;apt_feature_laundry&#39; &#39;apt_feature_fitness&#39; &#39;apt_feature_pre-war&#39; &#39;&#39; &#39;&#39;
 &#39;manager_medium&#39; &#39;manager_high&#39; &#39;building_count&#39; &#39;building_low&#39;
 &#39;building_medium&#39; &#39;building_high&#39; &#39;image_count&#39; &#39;&#39; &#39;longitude_modified&#39;]
Dropped Features [&#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;created_dow&#39; &#39;created_day&#39; &#39;created_month&#39; &#39;&#39; &#39;&#39;
 &#39;apt_feature_elevator&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;manager_count&#39;
 &#39;manager_low&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;latitude_modified&#39; &#39;&#39;]
Kept Features [&#39;bathrooms&#39; &#39;&#39; &#39;price_modified&#39; &#39;price_per_bed&#39; &#39;created_hour&#39; &#39;&#39; &#39;&#39; &#39;&#39;
 &#39;description_length&#39; &#39;features_count&#39; &#39;&#39; &#39;apt_feature_cats&#39;
 &#39;apt_feature_hardwood&#39; &#39;apt_feature_dogs&#39; &#39;apt_feature_doorman&#39;
 &#39;apt_feature_dishwasher&#39; &#39;apt_feature_no fee&#39; &#39;apt_feature_laundry&#39;
 &#39;apt_feature_fitness&#39; &#39;apt_feature_pre-war&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;manager_high&#39;
 &#39;building_count&#39; &#39;building_low&#39; &#39;building_medium&#39; &#39;building_high&#39; &#39;&#39; &#39;&#39;
 &#39;longitude_modified&#39;]
Dropped Features [&#39;&#39; &#39;bedrooms_modified&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;created_dow&#39; &#39;created_day&#39;
 &#39;created_month&#39; &#39;&#39; &#39;&#39; &#39;apt_feature_elevator&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39;
 &#39;manager_count&#39; &#39;manager_low&#39; &#39;manager_medium&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39;
 &#39;image_count&#39; &#39;latitude_modified&#39; &#39;&#39;]
Kept Features [&#39;bathrooms&#39; &#39;&#39; &#39;price_modified&#39; &#39;price_per_bed&#39; &#39;created_hour&#39; &#39;&#39; &#39;&#39; &#39;&#39;
 &#39;description_length&#39; &#39;&#39; &#39;&#39; &#39;apt_feature_cats&#39; &#39;apt_feature_hardwood&#39;
 &#39;apt_feature_dogs&#39; &#39;apt_feature_doorman&#39; &#39;apt_feature_dishwasher&#39;
 &#39;apt_feature_no fee&#39; &#39;apt_feature_laundry&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;manager_high&#39;
 &#39;building_count&#39; &#39;building_low&#39; &#39;building_medium&#39; &#39;building_high&#39; &#39;&#39; &#39;&#39;
 &#39;longitude_modified&#39;]
Dropped Features [&#39;&#39; &#39;bedrooms_modified&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;created_dow&#39; &#39;created_day&#39;
 &#39;created_month&#39; &#39;&#39; &#39;features_count&#39; &#39;apt_feature_elevator&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39;
 &#39;&#39; &#39;&#39; &#39;apt_feature_fitness&#39; &#39;apt_feature_pre-war&#39; &#39;manager_count&#39;
 &#39;manager_low&#39; &#39;manager_medium&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;image_count&#39;
 &#39;latitude_modified&#39; &#39;&#39;]
Kept Features [&#39;bathrooms&#39; &#39;&#39; &#39;price_modified&#39; &#39;price_per_bed&#39; &#39;created_hour&#39; &#39;&#39; &#39;&#39; &#39;&#39;
 &#39;description_length&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;apt_feature_hardwood&#39; &#39;&#39;
 &#39;apt_feature_doorman&#39; &#39;apt_feature_dishwasher&#39; &#39;apt_feature_no fee&#39;
 &#39;apt_feature_laundry&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;building_count&#39; &#39;building_low&#39;
 &#39;building_medium&#39; &#39;building_high&#39; &#39;&#39; &#39;&#39; &#39;longitude_modified&#39;]
Dropped Features [&#39;&#39; &#39;bedrooms_modified&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;created_dow&#39; &#39;created_day&#39;
 &#39;created_month&#39; &#39;&#39; &#39;features_count&#39; &#39;apt_feature_elevator&#39;
 &#39;apt_feature_cats&#39; &#39;&#39; &#39;apt_feature_dogs&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;apt_feature_fitness&#39;
 &#39;apt_feature_pre-war&#39; &#39;manager_count&#39; &#39;manager_low&#39; &#39;manager_medium&#39;
 &#39;manager_high&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;image_count&#39; &#39;latitude_modified&#39; &#39;&#39;]
Kept Features [&#39;&#39; &#39;&#39; &#39;price_modified&#39; &#39;price_per_bed&#39; &#39;created_hour&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39;
 &#39;apt_feature_hardwood&#39; &#39;&#39; &#39;apt_feature_doorman&#39; &#39;apt_feature_dishwasher&#39;
 &#39;apt_feature_no fee&#39; &#39;apt_feature_laundry&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39;
 &#39;building_count&#39; &#39;building_low&#39; &#39;building_medium&#39; &#39;building_high&#39; &#39;&#39; &#39;&#39; &#39;&#39;]
Dropped Features [&#39;bathrooms&#39; &#39;bedrooms_modified&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;created_dow&#39; &#39;created_day&#39;
 &#39;created_month&#39; &#39;description_length&#39; &#39;features_count&#39;
 &#39;apt_feature_elevator&#39; &#39;apt_feature_cats&#39; &#39;&#39; &#39;apt_feature_dogs&#39; &#39;&#39; &#39;&#39; &#39;&#39;
 &#39;&#39; &#39;apt_feature_fitness&#39; &#39;apt_feature_pre-war&#39; &#39;manager_count&#39;
 &#39;manager_low&#39; &#39;manager_medium&#39; &#39;manager_high&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;image_count&#39;
 &#39;latitude_modified&#39; &#39;longitude_modified&#39;]
Kept Features [&#39;&#39; &#39;&#39; &#39;price_modified&#39; &#39;price_per_bed&#39; &#39;created_hour&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39;
 &#39;apt_feature_hardwood&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;apt_feature_no fee&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39;
 &#39;building_count&#39; &#39;building_low&#39; &#39;building_medium&#39; &#39;building_high&#39; &#39;&#39; &#39;&#39; &#39;&#39;]
Dropped Features [&#39;bathrooms&#39; &#39;bedrooms_modified&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;created_dow&#39; &#39;created_day&#39;
 &#39;created_month&#39; &#39;description_length&#39; &#39;features_count&#39;
 &#39;apt_feature_elevator&#39; &#39;apt_feature_cats&#39; &#39;&#39; &#39;apt_feature_dogs&#39;
 &#39;apt_feature_doorman&#39; &#39;apt_feature_dishwasher&#39; &#39;&#39; &#39;apt_feature_laundry&#39;
 &#39;apt_feature_fitness&#39; &#39;apt_feature_pre-war&#39; &#39;manager_count&#39; &#39;manager_low&#39;
 &#39;manager_medium&#39; &#39;manager_high&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;image_count&#39;
 &#39;latitude_modified&#39; &#39;longitude_modified&#39;]
Kept Features [&#39;&#39; &#39;&#39; &#39;price_modified&#39; &#39;price_per_bed&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39;
 &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;building_count&#39; &#39;building_low&#39; &#39;building_medium&#39;
 &#39;building_high&#39; &#39;&#39; &#39;&#39; &#39;&#39;]
Dropped Features [&#39;bathrooms&#39; &#39;bedrooms_modified&#39; &#39;&#39; &#39;&#39; &#39;created_hour&#39; &#39;created_dow&#39;
 &#39;created_day&#39; &#39;created_month&#39; &#39;description_length&#39; &#39;features_count&#39;
 &#39;apt_feature_elevator&#39; &#39;apt_feature_cats&#39; &#39;apt_feature_hardwood&#39;
 &#39;apt_feature_dogs&#39; &#39;apt_feature_doorman&#39; &#39;apt_feature_dishwasher&#39;
 &#39;apt_feature_no fee&#39; &#39;apt_feature_laundry&#39; &#39;apt_feature_fitness&#39;
 &#39;apt_feature_pre-war&#39; &#39;manager_count&#39; &#39;manager_low&#39; &#39;manager_medium&#39;
 &#39;manager_high&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;image_count&#39; &#39;latitude_modified&#39;
 &#39;longitude_modified&#39;]
Kept Features [&#39;&#39; &#39;&#39; &#39;&#39; &#39;price_per_bed&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39;
 &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;building_count&#39; &#39;building_low&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39; &#39;&#39;]
Dropped Features [&#39;bathrooms&#39; &#39;bedrooms_modified&#39; &#39;price_modified&#39; &#39;&#39; &#39;created_hour&#39;
 &#39;created_dow&#39; &#39;created_day&#39; &#39;created_month&#39; &#39;description_length&#39;
 &#39;features_count&#39; &#39;apt_feature_elevator&#39; &#39;apt_feature_cats&#39;
 &#39;apt_feature_hardwood&#39; &#39;apt_feature_dogs&#39; &#39;apt_feature_doorman&#39;
 &#39;apt_feature_dishwasher&#39; &#39;apt_feature_no fee&#39; &#39;apt_feature_laundry&#39;
 &#39;apt_feature_fitness&#39; &#39;apt_feature_pre-war&#39; &#39;manager_count&#39; &#39;manager_low&#39;
 &#39;manager_medium&#39; &#39;manager_high&#39; &#39;&#39; &#39;&#39; &#39;building_medium&#39; &#39;building_high&#39;
 &#39;image_count&#39; &#39;latitude_modified&#39; &#39;longitude_modified&#39;]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Feature-Selection-Conclusions">Feature Selection Conclusions<a class="anchor-link" href="#Feature-Selection-Conclusions">&#182;</a></h3><ul>
<li>Image count should be simplified to 0 images, 1 image, 2 images and 3 or more</li>
<li>Apartment features and feature count is not adding much to the model. Attempt Tf-idf and a support vector classifier on apartment features and descriptions to come up with some potential topics. Drop the Apartment features input features (except for 'no fee').</li>
<li>Drop created_month feature. Turn created_dow into Friday (1) and not Friday (0). Consolidate the created_hour features into three buckets (1-4,5-8, and any other time of day)</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[57]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_pre_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="s2">&quot;train_checkpoint_2&quot;</span><span class="p">)</span>
<span class="n">df_kaggle_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="s2">&quot;test_checkpoint_2&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[58]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_image_count</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;image_count_range&#39;</span><span class="p">:</span><span class="n">df_pre_train</span><span class="p">[</span><span class="s1">&#39;image_count&#39;</span><span class="p">]})</span>
<span class="n">df_image_count</span><span class="p">[</span><span class="s1">&#39;image_count_range&#39;</span><span class="p">][</span><span class="n">df_image_count</span><span class="p">[</span><span class="s1">&#39;image_count_range&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="mi">3</span>

<span class="n">df_test_image_count</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;image_count_range&#39;</span><span class="p">:</span><span class="n">df_kaggle_test</span><span class="p">[</span><span class="s1">&#39;image_count&#39;</span><span class="p">]})</span>
<span class="n">df_test_image_count</span><span class="p">[</span><span class="s1">&#39;image_count_range&#39;</span><span class="p">][</span><span class="n">df_test_image_count</span><span class="p">[</span><span class="s1">&#39;image_count_range&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="mi">3</span>
<span class="c1">#df_image_count.describe()</span>
<span class="c1">#df_test_image_count.describe()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[59]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_created</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;created_friday&#39;</span><span class="p">:</span><span class="n">df_pre_train</span><span class="p">[</span><span class="s1">&#39;created_dow&#39;</span><span class="p">],</span><span class="s1">&#39;created_hour_range&#39;</span><span class="p">:</span><span class="n">df_pre_train</span><span class="p">[</span><span class="s1">&#39;created_hour&#39;</span><span class="p">]})</span>
<span class="c1">#df_created.head()</span>
<span class="n">df_created</span><span class="p">[</span><span class="s1">&#39;created_friday&#39;</span><span class="p">][</span><span class="n">df_created</span><span class="p">[</span><span class="s1">&#39;created_friday&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">4</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">df_created</span><span class="p">[</span><span class="s1">&#39;created_friday&#39;</span><span class="p">][</span><span class="n">df_created</span><span class="p">[</span><span class="s1">&#39;created_friday&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">4</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">df_created</span><span class="p">[</span><span class="s1">&#39;created_hour_range&#39;</span><span class="p">][(</span><span class="n">df_created</span><span class="p">[</span><span class="s1">&#39;created_hour_range&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df_created</span><span class="p">[</span><span class="s1">&#39;created_hour_range&#39;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">4</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">df_created</span><span class="p">[</span><span class="s1">&#39;created_hour_range&#39;</span><span class="p">][(</span><span class="n">df_created</span><span class="p">[</span><span class="s1">&#39;created_hour_range&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">5</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df_created</span><span class="p">[</span><span class="s1">&#39;created_hour_range&#39;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">8</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">df_created</span><span class="p">[</span><span class="s1">&#39;created_hour_range&#39;</span><span class="p">][(</span><span class="n">df_created</span><span class="p">[</span><span class="s1">&#39;created_hour_range&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">9</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">df_created</span><span class="p">[</span><span class="s1">&#39;created_hour_range&#39;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">3</span>

<span class="n">df_test_created</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;created_friday&#39;</span><span class="p">:</span><span class="n">df_kaggle_test</span><span class="p">[</span><span class="s1">&#39;created_dow&#39;</span><span class="p">],</span><span class="s1">&#39;created_hour_range&#39;</span><span class="p">:</span><span class="n">df_kaggle_test</span><span class="p">[</span><span class="s1">&#39;created_hour&#39;</span><span class="p">]})</span>
<span class="c1">#df_created.head()</span>
<span class="n">df_test_created</span><span class="p">[</span><span class="s1">&#39;created_friday&#39;</span><span class="p">][</span><span class="n">df_test_created</span><span class="p">[</span><span class="s1">&#39;created_friday&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">4</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">df_test_created</span><span class="p">[</span><span class="s1">&#39;created_friday&#39;</span><span class="p">][</span><span class="n">df_test_created</span><span class="p">[</span><span class="s1">&#39;created_friday&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">4</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">df_test_created</span><span class="p">[</span><span class="s1">&#39;created_hour_range&#39;</span><span class="p">][(</span><span class="n">df_test_created</span><span class="p">[</span><span class="s1">&#39;created_hour_range&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">)</span> 
                                      <span class="o">&amp;</span> <span class="p">(</span><span class="n">df_test_created</span><span class="p">[</span><span class="s1">&#39;created_hour_range&#39;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">4</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">df_test_created</span><span class="p">[</span><span class="s1">&#39;created_hour_range&#39;</span><span class="p">][(</span><span class="n">df_test_created</span><span class="p">[</span><span class="s1">&#39;created_hour_range&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">5</span><span class="p">)</span> 
                                      <span class="o">&amp;</span> <span class="p">(</span><span class="n">df_test_created</span><span class="p">[</span><span class="s1">&#39;created_hour_range&#39;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">8</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">df_test_created</span><span class="p">[</span><span class="s1">&#39;created_hour_range&#39;</span><span class="p">][(</span><span class="n">df_test_created</span><span class="p">[</span><span class="s1">&#39;created_hour_range&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">9</span><span class="p">)</span> 
                                      <span class="o">|</span> <span class="p">(</span><span class="n">df_test_created</span><span class="p">[</span><span class="s1">&#39;created_hour_range&#39;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">3</span>

<span class="c1"># df_created[&#39;created_hour_range&#39;][(df_created[&#39;created_hour_range&#39;] &gt;= 13) &amp; (df_created[&#39;created_hour_range&#39;] &lt;= 16)] = 4</span>
<span class="c1"># df_created[&#39;created_hour_range&#39;][(df_created[&#39;created_hour_range&#39;] &gt;= 17) &amp; (df_created[&#39;created_hour_range&#39;] &lt;= 20)] = 5</span>
<span class="c1"># df_created[&#39;created_hour_range&#39;][(df_created[&#39;created_hour_range&#39;] &gt;= 21) | (df_created[&#39;created_hour_range&#39;] &lt;= 0)] = 6</span>
<span class="c1">#df_created.describe()</span>
<span class="c1">#df_created[&#39;created_friday&#39;].plot(kind=&#39;hist&#39;)</span>
<span class="c1">#df_created[&#39;created_hour_range&#39;].plot(kind=&#39;hist&#39;)</span>
<span class="c1">#df_test_created.describe()</span>
<span class="c1">#plt.show()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="4.0-Reflection">4.0 Reflection<a class="anchor-link" href="#4.0-Reflection">&#182;</a></h2><p>Based on how my models have performed so far and the results of the Kaggle leaderboard, I believe there is room for improvement and further model complexity can be justified. In my proposal, I hypothesized about some potential further steps. The two main parts that I will be adding:</p>
<ul>
<li>Text Classification with Tf-idf and a support vector machine (SVM). In light of the lackluster performance of most apartment features and the text from the apartment features, I am hoping some text classification will be helpful.</li>
<li>A simple feedforward neural network. I am concerned that there might not be enough training examples to produce a useful feedforward network. However my best performing models on Kaggle so far has been the voting classifier. At the very least, I'm hoping a neural network can be added to the ensemble to improve performance. I also am hoping that the neural network can help better model the interaction between manager/building and counts/low/medium/high.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="4.1-Tf-idf-and-SVM">4.1 Tf-idf and SVM<a class="anchor-link" href="#4.1-Tf-idf-and-SVM">&#182;</a></h2><p>I combined the description and the list of features into one text blob for each listing. I fit a tf-idf to each blob and then used a support vector classifier to predict high, medium, and low interest probabilities based on the tf-idf representation of each text blob.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[154]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">preprocessing</span>
<span class="c1">#lb = preprocessing.LabelBinarizer()</span>
<span class="c1">#le = preprocessing.LabelEncoder()</span>

<span class="n">df_pre_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="s2">&quot;train_checkpoint_2&quot;</span><span class="p">)</span>
<span class="n">df_kaggle_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="s2">&quot;test_checkpoint_2&quot;</span><span class="p">)</span>
<span class="c1">#print(len(df_pre_train.columns.values),len(df_kaggle_test.columns.values))</span>

<span class="c1">#temp = lb.fit_transform(df_pre_train[&#39;interest_level&#39;])</span>

<span class="c1">#df_pre_train_label_matrix = pd.DataFrame({&#39;interest0_low&#39;:temp[:,1],&#39;interest1_medium&#39;:temp[:,2],&#39;interest2_high&#39;:temp[:,0]})</span>
<span class="c1">#df_pre_train_label_vector = df_pre_train[&#39;interest_level&#39;].map({&#39;low&#39;:0,&#39;medium&#39;:1,&#39;high&#39;:2})</span>

<span class="c1"># drop_columns = [&#39;bedrooms&#39;,&#39;building_id&#39;,&#39;created&#39;,&#39;description&#39;,&#39;display_address&#39;,&#39;features&#39;,&#39;interest_level&#39;,&#39;latitude&#39;,</span>
<span class="c1">#                 &#39;listing_id&#39;,&#39;longitude&#39;,&#39;manager_id&#39;,&#39;photos&#39;,&#39;price&#39;,</span>
<span class="c1">#                &#39;street_address&#39;]</span>
<span class="c1"># df_pre_train.drop(drop_columns, axis = 1, inplace = True)</span>

<span class="c1"># drop_columns_test = [&#39;bedrooms&#39;,&#39;building_id&#39;,&#39;created&#39;,&#39;description&#39;,&#39;display_address&#39;,&#39;features&#39;,&#39;latitude&#39;,</span>
<span class="c1">#                 &#39;listing_id&#39;,&#39;longitude&#39;,&#39;manager_id&#39;,&#39;photos&#39;,&#39;price&#39;,</span>
<span class="c1">#                &#39;street_address&#39;]</span>
<span class="c1"># df_kaggle_test.drop(drop_columns_test, axis = 1, inplace = True)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[155]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_lda</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span> <span class="p">{</span><span class="s1">&#39;description&#39;</span><span class="p">:</span> <span class="n">df_pre_train</span><span class="p">[</span><span class="s1">&#39;description&#39;</span><span class="p">],</span><span class="s1">&#39;features&#39;</span><span class="p">:</span><span class="n">df_pre_train</span><span class="p">[</span><span class="s1">&#39;features&#39;</span><span class="p">],</span>
                        <span class="s1">&#39;interest_level&#39;</span><span class="p">:</span><span class="n">df_pre_train</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]})</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[156]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lda_text</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">row_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df_lda</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">row_length</span><span class="p">):</span>
    <span class="n">z_string</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
    <span class="n">description</span> <span class="o">=</span> <span class="n">df_lda</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="n">df_lda</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="s1">&#39;description&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">description</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span> <span class="o">&gt;</span> <span class="mi">3</span><span class="p">:</span>
        <span class="n">z_string</span> <span class="o">+=</span> <span class="n">description</span>

    <span class="n">feature_list</span> <span class="o">=</span> <span class="n">df_lda</span><span class="p">[</span><span class="s1">&#39;features&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
    <span class="n">z_string2</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">feature_list</span><span class="p">)</span>
    <span class="n">z_string</span> <span class="o">+=</span> <span class="n">z_string2</span>
    <span class="n">lda_text</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">z_string</span><span class="p">)</span>
    
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[157]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_lda2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span> <span class="p">{</span><span class="s1">&#39;listing_text&#39;</span><span class="p">:</span> <span class="n">lda_text</span><span class="p">,</span><span class="s1">&#39;interest_level&#39;</span><span class="p">:</span><span class="n">df_pre_train</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]})</span>
<span class="n">df_lda2</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_lda2</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="s1">&#39;low&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;medium&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;high&#39;</span><span class="p">:</span><span class="mi">2</span><span class="p">})</span>
<span class="n">df_lda2</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt output_prompt">Out[157]:</div>

<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>interest_level</th>
      <th>listing_text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>10</th>
      <td>1</td>
      <td>A Brand New 3 Bedroom 1.5 bath ApartmentEnjoy ...</td>
    </tr>
    <tr>
      <th>10000</th>
      <td>0</td>
      <td>Doorman Elevator Fitness Center Cats Allowed D...</td>
    </tr>
    <tr>
      <th>100004</th>
      <td>2</td>
      <td>Top Top West Village location, beautiful Pre-w...</td>
    </tr>
    <tr>
      <th>100007</th>
      <td>0</td>
      <td>Building Amenities - Garage - Garden - fitness...</td>
    </tr>
    <tr>
      <th>100013</th>
      <td>0</td>
      <td>Beautifully renovated 3 bedroom flex 4 bedroom...</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[158]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="k">import</span> <span class="n">TfidfVectorizer</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="k">import</span> <span class="n">SVC</span>

<span class="n">tf_label</span> <span class="o">=</span> <span class="n">df_lda2</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]</span>

<span class="n">tfidf_vectorizer</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">max_df</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">min_df</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                   <span class="n">max_features</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>
                                   <span class="n">stop_words</span><span class="o">=</span><span class="s1">&#39;english&#39;</span><span class="p">)</span>

<span class="n">tfidf</span> <span class="o">=</span> <span class="n">tfidf_vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df_lda2</span><span class="p">[</span><span class="s1">&#39;listing_text&#39;</span><span class="p">])</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[159]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#print(tfidf[0,:])</span>
<span class="c1">#print(tfidf[1,:])</span>
<span class="n">svc_model</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span><span class="n">probability</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">class_weight</span><span class="o">=</span><span class="s1">&#39;balanced&#39;</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">svc_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">tfidf</span><span class="p">,</span> <span class="n">tf_label</span> <span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt output_prompt">Out[159]:</div>


<div class="output_text output_subarea output_execute_result">
<pre>SVC(C=1.0, cache_size=200, class_weight=&#39;balanced&#39;, coef0=0.0,
  decision_function_shape=None, degree=3, gamma=&#39;auto&#39;, kernel=&#39;linear&#39;,
  max_iter=-1, probability=True, random_state=0, shrinking=True, tol=0.001,
  verbose=False)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[160]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">svc_predictions</span> <span class="o">=</span> <span class="n">svc_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">tfidf</span><span class="p">)</span>
<span class="n">svc_score</span> <span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">tf_label</span><span class="p">,</span><span class="n">svc_predictions</span><span class="p">)</span> <span class="c1">#df_pre_train_label_vector</span>
<span class="nb">print</span><span class="p">(</span><span class="n">svc_score</span><span class="p">)</span>

<span class="c1">#print(predictions[0,:])</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>0.754239549421
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Produce predictions for the test data set</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[161]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_tf_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span> <span class="p">{</span><span class="s1">&#39;description&#39;</span><span class="p">:</span> <span class="n">df_kaggle_test</span><span class="p">[</span><span class="s1">&#39;description&#39;</span><span class="p">],</span><span class="s1">&#39;features&#39;</span><span class="p">:</span><span class="n">df_kaggle_test</span><span class="p">[</span><span class="s1">&#39;features&#39;</span><span class="p">]})</span>

<span class="n">tf_test_text</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">row_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df_tf_test</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">row_length</span><span class="p">):</span>
    <span class="n">z_string</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
    <span class="n">description</span> <span class="o">=</span> <span class="n">df_tf_test</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="n">df_tf_test</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="s1">&#39;description&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">description</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span> <span class="o">&gt;</span> <span class="mi">3</span><span class="p">:</span>
        <span class="n">z_string</span> <span class="o">+=</span> <span class="n">description</span>

    <span class="n">feature_list</span> <span class="o">=</span> <span class="n">df_tf_test</span><span class="p">[</span><span class="s1">&#39;features&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
    <span class="n">z_string2</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">feature_list</span><span class="p">)</span>
    <span class="n">z_string</span> <span class="o">+=</span> <span class="n">z_string2</span>
    <span class="n">tf_test_text</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">z_string</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[162]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tfidf_test</span> <span class="o">=</span> <span class="n">tfidf_vectorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">tf_test_text</span><span class="p">)</span>
<span class="n">svc_test_predictions</span> <span class="o">=</span> <span class="n">svc_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">tfidf_test</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[40]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pickle</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;renthop_svc.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">svc_model</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[163]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#create and save the new data frame type</span>
<span class="c1">#load the old one, add the new columns for training and test</span>
<span class="c1">#seperate out the labels</span>
<span class="c1">#drop the unnecessary columns</span>
<span class="c1">#normalize almost everything for the NN, not necessary for the other models</span>
<span class="c1">#save the new data frames</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pickle</span> 
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">preprocessing</span>
<span class="n">lb</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">LabelBinarizer</span><span class="p">()</span>
<span class="c1">#le = preprocessing.LabelEncoder()</span>

<span class="n">df_pre_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="s2">&quot;train_checkpoint_2&quot;</span><span class="p">)</span>
<span class="n">df_kaggle_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="s2">&quot;test_checkpoint_2&quot;</span><span class="p">)</span>
<span class="c1">#print(len(df_pre_train.columns.values),len(df_kaggle_test.columns.values))</span>

<span class="n">temp</span> <span class="o">=</span> <span class="n">lb</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df_pre_train</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">])</span>

<span class="n">df_pre_train_label_matrix</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;interest0_low&#39;</span><span class="p">:</span><span class="n">temp</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="s1">&#39;interest1_medium&#39;</span><span class="p">:</span><span class="n">temp</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span><span class="s1">&#39;interest2_high&#39;</span><span class="p">:</span><span class="n">temp</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]})</span>
<span class="n">df_pre_train_label_vector</span> <span class="o">=</span> <span class="n">df_pre_train</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="s1">&#39;low&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;medium&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;high&#39;</span><span class="p">:</span><span class="mi">2</span><span class="p">})</span>

<span class="n">drop_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;bedrooms&#39;</span><span class="p">,</span><span class="s1">&#39;building_id&#39;</span><span class="p">,</span><span class="s1">&#39;created&#39;</span><span class="p">,</span><span class="s1">&#39;description&#39;</span><span class="p">,</span><span class="s1">&#39;display_address&#39;</span><span class="p">,</span><span class="s1">&#39;features&#39;</span><span class="p">,</span><span class="s1">&#39;latitude&#39;</span><span class="p">,</span>
                <span class="s1">&#39;listing_id&#39;</span><span class="p">,</span><span class="s1">&#39;longitude&#39;</span><span class="p">,</span><span class="s1">&#39;manager_id&#39;</span><span class="p">,</span><span class="s1">&#39;photos&#39;</span><span class="p">,</span><span class="s1">&#39;price&#39;</span><span class="p">,</span><span class="s1">&#39;street_address&#39;</span><span class="p">,</span>
                <span class="s1">&#39;created_hour&#39;</span><span class="p">,</span><span class="s1">&#39;created_dow&#39;</span><span class="p">,</span> <span class="s1">&#39;created_month&#39;</span><span class="p">,</span> <span class="s1">&#39;features_count&#39;</span><span class="p">,</span> <span class="s1">&#39;apt_feature_elevator&#39;</span><span class="p">,</span>
               <span class="s1">&#39;apt_feature_cats&#39;</span><span class="p">,</span> <span class="s1">&#39;apt_feature_hardwood&#39;</span><span class="p">,</span> <span class="s1">&#39;apt_feature_dogs&#39;</span><span class="p">,</span>
               <span class="s1">&#39;apt_feature_doorman&#39;</span><span class="p">,</span> <span class="s1">&#39;apt_feature_dishwasher&#39;</span><span class="p">,</span>
               <span class="s1">&#39;apt_feature_laundry&#39;</span><span class="p">,</span> <span class="s1">&#39;apt_feature_fitness&#39;</span><span class="p">,</span>
               <span class="s1">&#39;apt_feature_pre-war&#39;</span><span class="p">,</span> <span class="s1">&#39;image_count&#39;</span><span class="p">,</span>
               <span class="s1">&#39;interest_level&#39;</span><span class="p">]</span>
<span class="n">df_pre_train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">drop_columns</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

<span class="n">drop_columns_test</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;bedrooms&#39;</span><span class="p">,</span><span class="s1">&#39;building_id&#39;</span><span class="p">,</span><span class="s1">&#39;created&#39;</span><span class="p">,</span><span class="s1">&#39;description&#39;</span><span class="p">,</span><span class="s1">&#39;display_address&#39;</span><span class="p">,</span><span class="s1">&#39;features&#39;</span><span class="p">,</span><span class="s1">&#39;latitude&#39;</span><span class="p">,</span>
                <span class="s1">&#39;listing_id&#39;</span><span class="p">,</span><span class="s1">&#39;longitude&#39;</span><span class="p">,</span><span class="s1">&#39;manager_id&#39;</span><span class="p">,</span><span class="s1">&#39;photos&#39;</span><span class="p">,</span><span class="s1">&#39;price&#39;</span><span class="p">,</span><span class="s1">&#39;street_address&#39;</span><span class="p">,</span>
                <span class="s1">&#39;created_hour&#39;</span><span class="p">,</span><span class="s1">&#39;created_dow&#39;</span><span class="p">,</span> <span class="s1">&#39;created_month&#39;</span><span class="p">,</span> <span class="s1">&#39;features_count&#39;</span><span class="p">,</span> <span class="s1">&#39;apt_feature_elevator&#39;</span><span class="p">,</span>
               <span class="s1">&#39;apt_feature_cats&#39;</span><span class="p">,</span> <span class="s1">&#39;apt_feature_hardwood&#39;</span><span class="p">,</span> <span class="s1">&#39;apt_feature_dogs&#39;</span><span class="p">,</span>
               <span class="s1">&#39;apt_feature_doorman&#39;</span><span class="p">,</span> <span class="s1">&#39;apt_feature_dishwasher&#39;</span><span class="p">,</span>
               <span class="s1">&#39;apt_feature_laundry&#39;</span><span class="p">,</span> <span class="s1">&#39;apt_feature_fitness&#39;</span><span class="p">,</span>
               <span class="s1">&#39;apt_feature_pre-war&#39;</span><span class="p">,</span> <span class="s1">&#39;image_count&#39;</span><span class="p">]</span>
<span class="n">df_kaggle_test</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">drop_columns_test</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[164]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#df_raw[&#39;price_modified&#39;] = pd.Series(price_modified,index=df_raw.index)</span>
<span class="n">df_pre_train</span><span class="p">[</span><span class="s1">&#39;image_count_range&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">df_image_count</span><span class="p">[</span><span class="s1">&#39;image_count_range&#39;</span><span class="p">],</span><span class="n">index</span><span class="o">=</span><span class="n">df_pre_train</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">df_pre_train</span><span class="p">[</span><span class="s1">&#39;created_friday&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">df_created</span><span class="p">[</span><span class="s1">&#39;created_friday&#39;</span><span class="p">],</span><span class="n">index</span><span class="o">=</span><span class="n">df_pre_train</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">df_pre_train</span><span class="p">[</span><span class="s1">&#39;created_hour_range&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">df_created</span><span class="p">[</span><span class="s1">&#39;created_hour_range&#39;</span><span class="p">],</span><span class="n">index</span><span class="o">=</span><span class="n">df_pre_train</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>

<span class="n">df_pre_train</span><span class="p">[</span><span class="s1">&#39;tf_low_prob&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">svc_predictions</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">index</span><span class="o">=</span><span class="n">df_pre_train</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">df_pre_train</span><span class="p">[</span><span class="s1">&#39;tf_medium_prob&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">svc_predictions</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">index</span><span class="o">=</span><span class="n">df_pre_train</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">df_pre_train</span><span class="p">[</span><span class="s1">&#39;tf_high_prob&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">svc_predictions</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span><span class="n">index</span><span class="o">=</span><span class="n">df_pre_train</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>

<span class="n">df_kaggle_test</span><span class="p">[</span><span class="s1">&#39;image_count_range&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">df_test_image_count</span><span class="p">[</span><span class="s1">&#39;image_count_range&#39;</span><span class="p">],</span><span class="n">index</span><span class="o">=</span><span class="n">df_kaggle_test</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">df_kaggle_test</span><span class="p">[</span><span class="s1">&#39;created_friday&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">df_test_created</span><span class="p">[</span><span class="s1">&#39;created_friday&#39;</span><span class="p">],</span><span class="n">index</span><span class="o">=</span><span class="n">df_kaggle_test</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">df_kaggle_test</span><span class="p">[</span><span class="s1">&#39;created_hour_range&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">df_test_created</span><span class="p">[</span><span class="s1">&#39;created_hour_range&#39;</span><span class="p">],</span><span class="n">index</span><span class="o">=</span><span class="n">df_kaggle_test</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>

<span class="n">df_kaggle_test</span><span class="p">[</span><span class="s1">&#39;tf_low_prob&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">svc_test_predictions</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">index</span><span class="o">=</span><span class="n">df_kaggle_test</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">df_kaggle_test</span><span class="p">[</span><span class="s1">&#39;tf_medium_prob&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">svc_test_predictions</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">index</span><span class="o">=</span><span class="n">df_kaggle_test</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">df_kaggle_test</span><span class="p">[</span><span class="s1">&#39;tf_high_prob&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">svc_test_predictions</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span><span class="n">index</span><span class="o">=</span><span class="n">df_kaggle_test</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[165]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_pre_train</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt output_prompt">Out[165]:</div>


<div class="output_text output_subarea output_execute_result">
<pre>array([&#39;bathrooms&#39;, &#39;bedrooms_modified&#39;, &#39;price_modified&#39;, &#39;price_per_bed&#39;,
       &#39;created_day&#39;, &#39;description_length&#39;, &#39;apt_feature_no fee&#39;,
       &#39;manager_count&#39;, &#39;manager_low&#39;, &#39;manager_medium&#39;, &#39;manager_high&#39;,
       &#39;building_count&#39;, &#39;building_low&#39;, &#39;building_medium&#39;,
       &#39;building_high&#39;, &#39;latitude_modified&#39;, &#39;longitude_modified&#39;,
       &#39;image_count_range&#39;, &#39;created_friday&#39;, &#39;created_hour_range&#39;,
       &#39;tf_low_prob&#39;, &#39;tf_medium_prob&#39;, &#39;tf_high_prob&#39;], dtype=object)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[166]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&#39;&#39;&#39;standardize_columns = [&#39;bathrooms&#39;, &#39;bedrooms_modified&#39;, &#39;price_modified&#39;, &#39;price_per_bed&#39;,</span>
<span class="sd">       &#39;created_day&#39;, &#39;description_length&#39;, &#39;apt_feature_no fee&#39;,</span>
<span class="sd">       &#39;manager_count&#39;, &#39;manager_low&#39;, &#39;manager_medium&#39;, &#39;manager_high&#39;,</span>
<span class="sd">       &#39;building_count&#39;, &#39;building_low&#39;, &#39;building_medium&#39;,</span>
<span class="sd">       &#39;building_high&#39;, &#39;latitude_modified&#39;, &#39;longitude_modified&#39;,</span>
<span class="sd">       &#39;image_count_range&#39;, &#39;created_friday&#39;, &#39;created_hour_range&#39;,</span>
<span class="sd">       &#39;tf_low_prob&#39;, &#39;tf_medium_prob&#39;, &#39;tf_high_prob&#39;]&#39;&#39;&#39;</span>

<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="k">import</span> <span class="n">StandardScaler</span>

<span class="n">standardize_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;price_modified&#39;</span><span class="p">,</span> <span class="s1">&#39;price_per_bed&#39;</span><span class="p">,</span><span class="s1">&#39;latitude_modified&#39;</span><span class="p">,</span>
       <span class="s1">&#39;longitude_modified&#39;</span><span class="p">,</span><span class="s1">&#39;description_length&#39;</span><span class="p">]</span>

<span class="n">X_scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">df_pre_train</span><span class="p">[</span><span class="n">standardize_columns</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df_pre_train</span><span class="p">[</span><span class="n">standardize_columns</span><span class="p">])</span>

<span class="n">df_kaggle_test</span><span class="p">[</span><span class="n">standardize_columns</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df_kaggle_test</span><span class="p">[</span><span class="n">standardize_columns</span><span class="p">])</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[167]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#print( len(svc_predictions[:,0]))</span>
<span class="c1">#pd.Series(svc_test_predictions[:,0],index=df_pre_train.index)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[168]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_pre_train</span><span class="o">.</span><span class="n">to_pickle</span><span class="p">(</span><span class="s2">&quot;train_checkpoint_3&quot;</span><span class="p">)</span>
<span class="n">df_kaggle_test</span><span class="o">.</span><span class="n">to_pickle</span><span class="p">(</span><span class="s2">&quot;test_checkpoint_3&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Checkpoint-3">Checkpoint 3<a class="anchor-link" href="#Checkpoint-3">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[297]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pickle</span> 
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">preprocessing</span>

<span class="n">lb</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">LabelBinarizer</span><span class="p">()</span>

<span class="n">df_train_3</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="s2">&quot;train_checkpoint_3&quot;</span><span class="p">)</span>
<span class="n">df_kaggle_test_3</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="s2">&quot;test_checkpoint_3&quot;</span><span class="p">)</span>

<span class="c1">#load the old checkpoint to get the labels</span>
<span class="n">df_pre_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="s2">&quot;train_checkpoint_2&quot;</span><span class="p">)</span>
<span class="n">df_kaggle_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="s2">&quot;test_checkpoint_2&quot;</span><span class="p">)</span>

<span class="n">temp</span> <span class="o">=</span> <span class="n">lb</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df_pre_train</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">])</span>

<span class="n">df_pre_train_label_matrix</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;interest0_low&#39;</span><span class="p">:</span><span class="n">temp</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="s1">&#39;interest1_medium&#39;</span><span class="p">:</span><span class="n">temp</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span><span class="s1">&#39;interest2_high&#39;</span><span class="p">:</span><span class="n">temp</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]})</span>
<span class="n">df_pre_train_label_vector</span> <span class="o">=</span> <span class="n">df_pre_train</span><span class="p">[</span><span class="s1">&#39;interest_level&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="s1">&#39;low&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s1">&#39;medium&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;high&#39;</span><span class="p">:</span><span class="mi">2</span><span class="p">})</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[298]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>

<span class="n">X_train2</span><span class="p">,</span> <span class="n">X_val2</span><span class="p">,</span> <span class="n">y_train2</span><span class="p">,</span> <span class="n">y_val2</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df_train_3</span><span class="p">,</span> <span class="n">df_pre_train_label_vector</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X_val2</span><span class="p">,</span> <span class="n">X_test2</span><span class="p">,</span> <span class="n">y_val2</span><span class="p">,</span> <span class="n">y_test2</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_val2</span><span class="p">,</span> <span class="n">y_val2</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="nb">print</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train2</span><span class="p">),</span><span class="nb">len</span><span class="p">(</span><span class="n">X_val2</span><span class="p">),</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test2</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>34546 7403 7403
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="4.2-Feedforward-Neural-Network">4.2 Feedforward Neural Network<a class="anchor-link" href="#4.2-Feedforward-Neural-Network">&#182;</a></h2><p>I decided on a feedforward neural network using three hidden layers of rectified linear units and a softmax cross entropy cost function. From what I have learned from the deeplearningbook.org, quora.com and the Udacity course is that rectified linear units are typically the best hidden unit to start with. Softmax makes sense since I'm looking for probability outputs and cross entropy is similar to the log loss cost function. I also normalized the inputs for easier gradient descent training.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[299]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&#39;&#39;&#39;standardize_columns = [&#39;bathrooms&#39;, &#39;bedrooms_modified&#39;, &#39;price_modified&#39;, &#39;price_per_bed&#39;,</span>
<span class="sd">       &#39;created_day&#39;, &#39;description_length&#39;, &#39;apt_feature_no fee&#39;,</span>
<span class="sd">       &#39;manager_count&#39;, &#39;manager_low&#39;, &#39;manager_medium&#39;, &#39;manager_high&#39;,</span>
<span class="sd">       &#39;building_count&#39;, &#39;building_low&#39;, &#39;building_medium&#39;,</span>
<span class="sd">       &#39;building_high&#39;, &#39;latitude_modified&#39;, &#39;longitude_modified&#39;,</span>
<span class="sd">       &#39;image_count_range&#39;, &#39;created_friday&#39;, &#39;created_hour_range&#39;,</span>
<span class="sd">       &#39;tf_low_prob&#39;, &#39;tf_medium_prob&#39;, &#39;tf_high_prob&#39;]&#39;&#39;&#39;</span>

<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="k">import</span> <span class="n">StandardScaler</span>

<span class="c1">#already normalized columns: &#39;price_modified&#39;, &#39;price_per_bed&#39;,&#39;latitude_modified&#39;,&#39;longitude_modified&#39;,&#39;description_length&#39;</span>
<span class="c1">#columns to not normalize: &#39;apt_feature_no fee&#39;, &#39;created_friday&#39;, &#39;tf_low_prob&#39;, &#39;tf_medium_prob&#39;, &#39;tf_high_prob&#39;</span>
<span class="n">standardize_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;bathrooms&#39;</span><span class="p">,</span> <span class="s1">&#39;bedrooms_modified&#39;</span><span class="p">,</span> 
       <span class="s1">&#39;created_day&#39;</span><span class="p">,</span> <span class="s1">&#39;manager_count&#39;</span><span class="p">,</span> <span class="s1">&#39;manager_low&#39;</span><span class="p">,</span> <span class="s1">&#39;manager_medium&#39;</span><span class="p">,</span> <span class="s1">&#39;manager_high&#39;</span><span class="p">,</span>
       <span class="s1">&#39;building_count&#39;</span><span class="p">,</span> <span class="s1">&#39;building_low&#39;</span><span class="p">,</span> <span class="s1">&#39;building_medium&#39;</span><span class="p">,</span>
       <span class="s1">&#39;building_high&#39;</span><span class="p">,</span><span class="s1">&#39;image_count_range&#39;</span><span class="p">,</span>  <span class="s1">&#39;created_hour_range&#39;</span><span class="p">]</span>

<span class="n">nn_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="s2">&quot;train_checkpoint_3&quot;</span><span class="p">)</span>
<span class="n">nn_kaggle_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="s2">&quot;test_checkpoint_3&quot;</span><span class="p">)</span>

<span class="n">X_scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">nn_train</span><span class="p">[</span><span class="n">standardize_columns</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">nn_train</span><span class="p">[</span><span class="n">standardize_columns</span><span class="p">])</span>
<span class="n">nn_kaggle_test</span><span class="p">[</span><span class="n">standardize_columns</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">nn_kaggle_test</span><span class="p">[</span><span class="n">standardize_columns</span><span class="p">])</span>
<span class="n">nn_kaggle_text_xgb</span> <span class="o">=</span> <span class="n">nn_kaggle_test</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[300]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>

<span class="n">X_train_nn</span><span class="p">,</span> <span class="n">X_val_nn</span><span class="p">,</span> <span class="n">y_train_nn</span><span class="p">,</span> <span class="n">y_val_nn</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">nn_train</span><span class="p">,</span> <span class="n">df_pre_train_label_matrix</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X_val_nn</span><span class="p">,</span> <span class="n">X_test_nn</span><span class="p">,</span> <span class="n">y_val_nn</span><span class="p">,</span> <span class="n">y_test_nn</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_val_nn</span><span class="p">,</span> <span class="n">y_val_nn</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">X_train_nn</span> <span class="o">=</span> <span class="n">X_train_nn</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span>
<span class="n">X_val_nn</span> <span class="o">=</span> <span class="n">X_val_nn</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span>
<span class="n">X_test_nn</span> <span class="o">=</span> <span class="n">X_test_nn</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span>
<span class="n">y_train_nn</span> <span class="o">=</span> <span class="n">y_train_nn</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span>
<span class="n">y_val_nn</span> <span class="o">=</span> <span class="n">y_val_nn</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span>
<span class="n">y_test_nn</span> <span class="o">=</span> <span class="n">y_test_nn</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span>

<span class="n">nn_kaggle_test</span> <span class="o">=</span> <span class="n">nn_kaggle_test</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span>
<span class="n">test_sample</span> <span class="o">=</span> <span class="n">nn_kaggle_test</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="c1">#print(test_sample)</span>

<span class="nb">print</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train_nn</span><span class="p">),</span><span class="nb">len</span><span class="p">(</span><span class="n">X_val_nn</span><span class="p">),</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test_nn</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>34546 7403 7403
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[301]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#creating data for other models, using vector instead of matrix for y</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">nn_train</span><span class="p">,</span> <span class="n">df_pre_train_label_vector</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X_val</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_val</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="nb">print</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span><span class="nb">len</span><span class="p">(</span><span class="n">X_val</span><span class="p">),</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>34546 7403 7403
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[206]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># Remove previous weights, bias, inputs, etc..</span>
<span class="n">tf</span><span class="o">.</span><span class="n">reset_default_graph</span><span class="p">()</span>

<span class="n">epochs</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="c1">#learning_rate = 0.01 #0.001</span>
<span class="n">keep_probability</span> <span class="o">=</span> <span class="mf">0.5</span>

<span class="c1">#network hidden layer size</span>
<span class="n">n_hidden_layer_1</span> <span class="o">=</span> <span class="mi">1024</span>
<span class="n">n_hidden_layer_2</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">n_hidden_layer_3</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">n_classes</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">n_features</span> <span class="o">=</span> <span class="n">X_train_nn</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="n">X_inputs</span> <span class="o">=</span> <span class="n">X_train_nn</span>
<span class="n">y_labels</span> <span class="o">=</span> <span class="n">y_train_nn</span>

<span class="n">weights</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">([</span><span class="n">n_features</span><span class="p">,</span><span class="n">n_hidden_layer_1</span><span class="p">],</span><span class="n">stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)),</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">([</span><span class="n">n_hidden_layer_1</span><span class="p">,</span><span class="n">n_hidden_layer_2</span><span class="p">],</span><span class="n">stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)),</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">([</span><span class="n">n_hidden_layer_2</span><span class="p">,</span><span class="n">n_hidden_layer_3</span><span class="p">],</span><span class="n">stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)),</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">([</span><span class="n">n_hidden_layer_3</span><span class="p">,</span><span class="n">n_classes</span><span class="p">],</span><span class="n">stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">))</span>
<span class="p">]</span>

<span class="n">biases</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">([</span><span class="n">n_hidden_layer_1</span><span class="p">],</span><span class="n">stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)),</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">([</span><span class="n">n_hidden_layer_2</span><span class="p">],</span><span class="n">stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)),</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">([</span><span class="n">n_hidden_layer_3</span><span class="p">],</span><span class="n">stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)),</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">([</span><span class="n">n_classes</span><span class="p">],</span><span class="n">stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">))</span>
<span class="p">]</span>


<span class="k">def</span> <span class="nf">nn_model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">weight_array</span><span class="p">,</span><span class="n">bias_array</span><span class="p">,</span><span class="n">keep_prob</span><span class="p">):</span> <span class="c1">#</span>
    <span class="n">hidden_input_1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">weight_array</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span><span class="n">bias_array</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">hidden_out_1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">hidden_input_1</span><span class="p">)</span>
    <span class="n">hidden_drop_1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">hidden_out_1</span><span class="p">,</span><span class="mf">1.0</span><span class="p">)</span>
    
    <span class="n">hidden_input_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">hidden_drop_1</span><span class="p">,</span><span class="n">weight_array</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span><span class="n">bias_array</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">hidden_out_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">hidden_input_2</span><span class="p">)</span>
    <span class="n">hidden_drop_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">hidden_out_2</span><span class="p">,</span><span class="n">keep_prob</span><span class="p">)</span>
    
    <span class="n">hidden_input_3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">hidden_drop_2</span><span class="p">,</span><span class="n">weight_array</span><span class="p">[</span><span class="mi">2</span><span class="p">]),</span><span class="n">bias_array</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">hidden_out_3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">hidden_input_3</span><span class="p">)</span>
    <span class="n">hidden_drop_3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">hidden_out_3</span><span class="p">,</span><span class="n">keep_prob</span><span class="p">)</span>
    
    <span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">hidden_drop_3</span><span class="p">,</span><span class="n">weight_array</span><span class="p">[</span><span class="mi">3</span><span class="p">]),</span><span class="n">bias_array</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">output</span>

<span class="k">def</span> <span class="nf">train_neural_network</span><span class="p">(</span><span class="n">session</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">keep_probability</span><span class="p">,</span> <span class="n">feature_batch</span><span class="p">,</span> <span class="n">label_batch</span><span class="p">):</span>
    <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span><span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">feature_batch</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span><span class="n">label_batch</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">:</span><span class="n">keep_probability</span><span class="p">})</span>
    <span class="k">pass</span>


<span class="c1"># Inputs</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span><span class="n">n_features</span><span class="p">),</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">)</span> <span class="c1">#neural_net_image_input((32, 32, 3))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span><span class="n">n_classes</span><span class="p">),</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">)</span> <span class="c1">#neural_net_label_input(10)</span>
<span class="n">keep_prob</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;keep_prob&quot;</span><span class="p">)</span><span class="c1">#neural_net_keep_prob_input()</span>

<span class="c1"># Model</span>
<span class="n">model_logits</span> <span class="o">=</span> <span class="n">nn_model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">weights</span><span class="p">,</span> <span class="n">biases</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span> <span class="c1">#</span>

<span class="c1"># Name logits Tensor, so that is can be loaded from disk after training</span>
<span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">model_logits</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;logits&#39;</span><span class="p">)</span>

<span class="c1"># Loss and Optimizer</span>
<span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax_cross_entropy_with_logits</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">y</span><span class="p">))</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">()</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
<span class="c1"># cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))</span>
<span class="c1"># optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)</span>

<span class="c1"># Accuracy</span>
<span class="n">correct_pred</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">correct_pred</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[207]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">print_stats</span><span class="p">(</span><span class="n">session</span><span class="p">,</span> <span class="n">feature_batch</span><span class="p">,</span> <span class="n">label_batch</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">val_features</span><span class="p">,</span> <span class="n">val_labels</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Print information about loss and validation accuracy</span>
<span class="sd">    : session: Current TensorFlow session</span>
<span class="sd">    : feature_batch: Batch of Numpy image data</span>
<span class="sd">    : label_batch: Batch of Numpy label data</span>
<span class="sd">    : cost: TensorFlow cost function</span>
<span class="sd">    : accuracy: TensorFlow accuracy function</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Calculate batch loss and accuracy</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">cost</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
        <span class="n">x</span><span class="p">:</span> <span class="n">feature_batch</span><span class="p">,</span>
        <span class="n">y</span><span class="p">:</span> <span class="n">label_batch</span><span class="p">,</span>
        <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>
    <span class="n">valid_acc</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">accuracy</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
        <span class="n">x</span><span class="p">:</span> <span class="n">val_features</span><span class="p">,</span><span class="c1">#valid_features,#valid_features[:test_valid_size],#valid_features[200:(200+test_valid_size)],</span>
        <span class="n">y</span><span class="p">:</span> <span class="n">val_labels</span><span class="p">,</span><span class="c1">#valid_labels,#valid_labels[:test_valid_size],#valid_labels[200:(200+test_valid_size)],</span>
        <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Loss: </span><span class="si">{:&gt;10.4f}</span><span class="s1"> Validation Accuracy: </span><span class="si">{:.6f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">valid_acc</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[208]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">35</span>
<span class="n">keep_probability</span> <span class="o">=</span> <span class="mf">0.5</span>

<span class="n">save_file</span> <span class="o">=</span> <span class="s1">&#39;./nn_full_model&#39;</span>
<span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
    <span class="n">total_batch</span>  <span class="o">=</span> <span class="nb">int</span><span class="p">(</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_labels</span><span class="p">)</span><span class="o">/</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="n">batch_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_labels</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">current_epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">total_batch</span><span class="p">):</span>
            <span class="n">batch_x</span> <span class="o">=</span> <span class="n">X_inputs</span><span class="p">[(</span><span class="n">i</span><span class="o">*</span><span class="n">batch_size</span><span class="p">):((</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">batch_size</span><span class="p">),:]</span>
            <span class="n">batch_y</span> <span class="o">=</span> <span class="n">y_labels</span><span class="p">[(</span><span class="n">i</span><span class="o">*</span><span class="n">batch_size</span><span class="p">):((</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">batch_size</span><span class="p">),:]</span>
            <span class="n">train_neural_network</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span><span class="n">optimizer</span><span class="p">,</span><span class="n">keep_probability</span><span class="p">,</span><span class="n">batch_x</span><span class="p">,</span><span class="n">batch_y</span><span class="p">)</span>
        <span class="n">print_stats</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_y</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span><span class="n">X_val_nn</span><span class="p">,</span><span class="n">y_val_nn</span><span class="p">)</span>
    
    <span class="c1">#getting predictions</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">model_logits</span><span class="p">)</span>
    <span class="n">nn_output</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">x</span><span class="p">:</span><span class="n">nn_kaggle_test</span><span class="p">,</span><span class="n">keep_prob</span><span class="p">:</span><span class="mf">1.0</span><span class="p">})</span>    
    
    <span class="c1">#saving model</span>
    <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
    <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span><span class="n">save_file</span><span class="p">)</span>
    
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Loss:     0.5842 Validation Accuracy: 0.727273
Loss:     0.5711 Validation Accuracy: 0.731730
Loss:     0.5792 Validation Accuracy: 0.734297
Loss:     0.5730 Validation Accuracy: 0.736998
Loss:     0.5682 Validation Accuracy: 0.739835
Loss:     0.5677 Validation Accuracy: 0.739970
Loss:     0.5561 Validation Accuracy: 0.737674
Loss:     0.5500 Validation Accuracy: 0.735783
Loss:     0.5555 Validation Accuracy: 0.741321
Loss:     0.5452 Validation Accuracy: 0.740376
Loss:     0.5436 Validation Accuracy: 0.741186
Loss:     0.5444 Validation Accuracy: 0.742267
Loss:     0.5480 Validation Accuracy: 0.740105
Loss:     0.5415 Validation Accuracy: 0.735242
Loss:     0.5390 Validation Accuracy: 0.740916
Loss:     0.5295 Validation Accuracy: 0.743482
Loss:     0.5270 Validation Accuracy: 0.742807
Loss:     0.5285 Validation Accuracy: 0.743077
Loss:     0.5279 Validation Accuracy: 0.740511
Loss:     0.5210 Validation Accuracy: 0.744428
Loss:     0.5141 Validation Accuracy: 0.742807
Loss:     0.5094 Validation Accuracy: 0.739970
Loss:     0.5097 Validation Accuracy: 0.744293
Loss:     0.5152 Validation Accuracy: 0.742132
Loss:     0.5118 Validation Accuracy: 0.739835
Loss:     0.4927 Validation Accuracy: 0.736323
Loss:     0.5068 Validation Accuracy: 0.740240
Loss:     0.4875 Validation Accuracy: 0.744023
Loss:     0.4884 Validation Accuracy: 0.740105
Loss:     0.4877 Validation Accuracy: 0.737269
Loss:     0.4848 Validation Accuracy: 0.738755
Loss:     0.4920 Validation Accuracy: 0.737809
Loss:     0.4830 Validation Accuracy: 0.737269
Loss:     0.4809 Validation Accuracy: 0.738620
Loss:     0.4725 Validation Accuracy: 0.739565
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[209]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">output_predictions</span><span class="p">(</span><span class="n">nn_output</span><span class="p">,</span><span class="s2">&quot;nn&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>        listing_id      high    medium       low
0          7142618  0.072987  0.332242  0.594772
1          7210040  0.029062  0.219447  0.751492
100        7103890  0.014308  0.246023  0.739670
1000       7143442  0.133491  0.347781  0.518729
100000     6860601  0.000360  0.127271  0.872370
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="kaggle-score-of-0.60874-on-test-data-set">kaggle score of 0.60874 on test data set<a class="anchor-link" href="#kaggle-score-of-0.60874-on-test-data-set">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Convenience-Functions">Convenience Functions<a class="anchor-link" href="#Convenience-Functions">&#182;</a></h3><p>Functions used when re-running the models with the modified set of features, re-tuning the hyperparameters for the models, and outputting predictions.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[237]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">ShuffleSplit</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">log_loss</span><span class="p">,</span> <span class="n">make_scorer</span>
<span class="kn">from</span> <span class="nn">sklearn.calibration</span> <span class="k">import</span> <span class="n">CalibratedClassifierCV</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">GridSearchCV</span>

<span class="c1">#cross validation sets used by GridSearch</span>
<span class="n">rs</span> <span class="o">=</span> <span class="n">ShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.20</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">cv_sets</span> <span class="o">=</span> <span class="n">rs</span><span class="o">.</span><span class="n">get_n_splits</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="c1">#custom scorer used in GridSearchCV.</span>
<span class="c1">#Training data is used in cross-validation sets by GridSearch to train the initial model.</span>
<span class="c1">#heldout part of the cv set is used as X,y in the function.</span>
<span class="c1">#outside validation set used to fit the CalibratedClassifierCV</span>

<span class="k">def</span> <span class="nf">custom_ccv_scorer</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
    <span class="n">ccv</span> <span class="o">=</span> <span class="n">CalibratedClassifierCV</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s2">&quot;isotonic&quot;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="s2">&quot;prefit&quot;</span><span class="p">)</span>
    <span class="n">ccv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span><span class="n">y_val</span><span class="p">)</span> <span class="c1">#fit to overall validation set</span>
    <span class="n">ccv_predictions</span> <span class="o">=</span> <span class="n">ccv</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">ccv_score</span> <span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">ccv_predictions</span><span class="p">)</span>
    <span class="c1">#Take the negative as GridSearchCV optimizes by highest value while smaller positive values are better for log loss.</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">ccv_score</span>
    
<span class="c1">#log_loss argument works by default, don&#39;t need to implement a custom log_loss scoring function</span>
<span class="c1">#scoring_fnc = make_scorer(log_loss,greater_is_better=False, needs_proba=True)</span>

<span class="k">def</span> <span class="nf">describe_grid_model</span><span class="p">(</span><span class="n">grid_model</span><span class="p">,</span> <span class="n">is_get_ccv</span><span class="p">):</span>
    <span class="n">best_model</span> <span class="o">=</span> <span class="n">grid_model</span><span class="o">.</span><span class="n">best_estimator_</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">best_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">predictions</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">is_get_ccv</span><span class="p">:</span>
        <span class="n">ccv</span> <span class="o">=</span> <span class="n">CalibratedClassifierCV</span><span class="p">(</span><span class="n">best_model</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s2">&quot;isotonic&quot;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="s2">&quot;prefit&quot;</span><span class="p">)</span>
        <span class="n">ccv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span><span class="n">y_val</span><span class="p">)</span> <span class="c1">#fit to overall validation set</span>
        <span class="n">ccv_predictions</span> <span class="o">=</span> <span class="n">ccv</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
        <span class="n">ccv_score</span> <span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">ccv_predictions</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;CCV Score, Base Model Score:&#39;</span><span class="p">,</span> <span class="n">ccv_score</span><span class="p">,</span><span class="s1">&#39;,&#39;</span><span class="p">,</span><span class="n">score</span> <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Best Model Score:&#39;</span><span class="p">,</span><span class="n">score</span><span class="p">)</span>
        
    <span class="n">df_grid</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">grid_model</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">df_grid</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">df_grid</span><span class="p">[</span><span class="s1">&#39;mean_test_score&#39;</span><span class="p">])</span>
    
<span class="c1">#outputs the predictions to a .csv for kaggle</span>
<span class="k">def</span> <span class="nf">output_predictions</span><span class="p">(</span><span class="n">out_prob</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
    <span class="n">df_kaggle_test_pickle</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="s2">&quot;test_checkpoint_2&quot;</span><span class="p">)</span>
    <span class="n">df_out</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;alisting_id&quot;</span><span class="p">:</span><span class="n">df_kaggle_test_pickle</span><span class="p">[</span><span class="s1">&#39;listing_id&#39;</span><span class="p">],</span><span class="s2">&quot;bhigh&quot;</span><span class="p">:</span><span class="n">out_prob</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span>
                       <span class="s2">&quot;cmedium&quot;</span><span class="p">:</span><span class="n">out_prob</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="s2">&quot;dlow&quot;</span><span class="p">:</span><span class="n">out_prob</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]})</span>
    <span class="n">df_out</span> <span class="o">=</span> <span class="n">df_out</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span> <span class="s1">&#39;alisting_id&#39;</span><span class="p">:</span><span class="s1">&#39;listing_id&#39;</span><span class="p">,</span> <span class="s1">&#39;bhigh&#39;</span><span class="p">:</span><span class="s1">&#39;high&#39;</span><span class="p">,</span><span class="s1">&#39;cmedium&#39;</span><span class="p">:</span><span class="s1">&#39;medium&#39;</span>
                          <span class="p">,</span><span class="s1">&#39;dlow&#39;</span><span class="p">:</span><span class="s1">&#39;low&#39;</span><span class="p">})</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">df_out</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
    <span class="n">df_out</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">name</span><span class="o">+</span><span class="s2">&quot;_renthop_kaggle_submission.csv&quot;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Model-Selection-Part-2">Model Selection Part 2<a class="anchor-link" href="#Model-Selection-Part-2">&#182;</a></h1><p>I redid each of the models from the prior section with the new feature space. For most models, I try to select the best hyper-parameters using GridSearchCV. I output the predictions of each model on the kaggle test set and submit the predictions to kaggle to receive a score.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="4.3-Logistic-Regression">4.3 Logistic Regression<a class="anchor-link" href="#4.3-Logistic-Regression">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[239]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="k">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">GridSearchCV</span>

<span class="n">lr_model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">,</span><span class="n">multi_class</span><span class="o">=</span><span class="s1">&#39;multinomial&#39;</span><span class="p">,</span><span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="c1">#choosing between solver and class_weight first</span>
<span class="n">gs_parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;solver&#39;</span><span class="p">:(</span><span class="s1">&#39;sag&#39;</span><span class="p">,</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">,</span><span class="s1">&#39;newton-cg&#39;</span><span class="p">),</span><span class="s1">&#39;class_weight&#39;</span><span class="p">:(</span><span class="s1">&#39;balanced&#39;</span><span class="p">,</span><span class="kc">None</span><span class="p">)}</span>

<span class="n">gs_lr_model</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">lr_model</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">gs_parameters</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;neg_log_loss&quot;</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">cv_sets</span><span class="p">)</span>
<span class="n">gs_lr_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\Decoud\Anaconda3\envs\py35\lib\site-packages\sklearn\linear_model\sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  &#34;the coef_ did not converge&#34;, ConvergenceWarning)
C:\Users\Decoud\Anaconda3\envs\py35\lib\site-packages\sklearn\linear_model\sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  &#34;the coef_ did not converge&#34;, ConvergenceWarning)
C:\Users\Decoud\Anaconda3\envs\py35\lib\site-packages\sklearn\linear_model\sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  &#34;the coef_ did not converge&#34;, ConvergenceWarning)
C:\Users\Decoud\Anaconda3\envs\py35\lib\site-packages\sklearn\linear_model\sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  &#34;the coef_ did not converge&#34;, ConvergenceWarning)
C:\Users\Decoud\Anaconda3\envs\py35\lib\site-packages\sklearn\linear_model\sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  &#34;the coef_ did not converge&#34;, ConvergenceWarning)
C:\Users\Decoud\Anaconda3\envs\py35\lib\site-packages\sklearn\linear_model\sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  &#34;the coef_ did not converge&#34;, ConvergenceWarning)
C:\Users\Decoud\Anaconda3\envs\py35\lib\site-packages\sklearn\linear_model\sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  &#34;the coef_ did not converge&#34;, ConvergenceWarning)
C:\Users\Decoud\Anaconda3\envs\py35\lib\site-packages\sklearn\linear_model\sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  &#34;the coef_ did not converge&#34;, ConvergenceWarning)
C:\Users\Decoud\Anaconda3\envs\py35\lib\site-packages\sklearn\linear_model\sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  &#34;the coef_ did not converge&#34;, ConvergenceWarning)
C:\Users\Decoud\Anaconda3\envs\py35\lib\site-packages\sklearn\linear_model\sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  &#34;the coef_ did not converge&#34;, ConvergenceWarning)
</pre>
</div>
</div>

<div class="output_area"><div class="prompt output_prompt">Out[239]:</div>


<div class="output_text output_subarea output_execute_result">
<pre>GridSearchCV(cv=5, error_score=&#39;raise&#39;,
       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class=&#39;multinomial&#39;,
          n_jobs=1, penalty=&#39;l2&#39;, random_state=0, solver=&#39;lbfgs&#39;,
          tol=0.0001, verbose=0, warm_start=False),
       fit_params={}, iid=True, n_jobs=1,
       param_grid={&#39;class_weight&#39;: (&#39;balanced&#39;, None), &#39;solver&#39;: (&#39;sag&#39;, &#39;lbfgs&#39;, &#39;newton-cg&#39;)},
       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=True,
       scoring=&#39;neg_log_loss&#39;, verbose=0)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[240]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">describe_grid_model</span><span class="p">(</span><span class="n">gs_lr_model</span><span class="p">,</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Best Model Score: 0.621135241287
0        {&#39;solver&#39;: &#39;sag&#39;, &#39;class_weight&#39;: &#39;balanced&#39;}
1      {&#39;solver&#39;: &#39;lbfgs&#39;, &#39;class_weight&#39;: &#39;balanced&#39;}
2    {&#39;solver&#39;: &#39;newton-cg&#39;, &#39;class_weight&#39;: &#39;balan...
3              {&#39;solver&#39;: &#39;sag&#39;, &#39;class_weight&#39;: None}
4            {&#39;solver&#39;: &#39;lbfgs&#39;, &#39;class_weight&#39;: None}
5        {&#39;solver&#39;: &#39;newton-cg&#39;, &#39;class_weight&#39;: None}
Name: params, dtype: object
0   -0.827284
1   -0.826832
2   -0.826691
3   -0.630690
4   -0.630243
5   -0.630092
Name: mean_test_score, dtype: float64
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[241]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#None preferred over balanced, solvers close with newton-cg slightly better</span>
<span class="c1">#testing C values</span>
<span class="n">lr_model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;newton-cg&#39;</span><span class="p">,</span><span class="n">multi_class</span><span class="o">=</span><span class="s1">&#39;multinomial&#39;</span><span class="p">,</span><span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">gs_parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:[</span><span class="o">.</span><span class="mi">1</span><span class="p">,</span><span class="o">.</span><span class="mi">3</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">1.5</span><span class="p">]}</span>

<span class="n">gs_lr_model</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">lr_model</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">gs_parameters</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;neg_log_loss&quot;</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">cv_sets</span><span class="p">)</span>
<span class="n">gs_lr_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt output_prompt">Out[241]:</div>


<div class="output_text output_subarea output_execute_result">
<pre>GridSearchCV(cv=5, error_score=&#39;raise&#39;,
       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class=&#39;multinomial&#39;,
          n_jobs=1, penalty=&#39;l2&#39;, random_state=0, solver=&#39;newton-cg&#39;,
          tol=0.0001, verbose=0, warm_start=False),
       fit_params={}, iid=True, n_jobs=1,
       param_grid={&#39;C&#39;: [0.1, 0.3, 1.0, 1.5]}, pre_dispatch=&#39;2*n_jobs&#39;,
       refit=True, return_train_score=True, scoring=&#39;neg_log_loss&#39;,
       verbose=0)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[242]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">describe_grid_model</span><span class="p">(</span><span class="n">gs_lr_model</span><span class="p">,</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Best Model Score: 0.621108566764
0    {&#39;C&#39;: 0.1}
1    {&#39;C&#39;: 0.3}
2    {&#39;C&#39;: 1.0}
3    {&#39;C&#39;: 1.5}
Name: params, dtype: object
0   -0.631106
1   -0.630494
2   -0.630092
3   -0.630035
Name: mean_test_score, dtype: float64
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[243]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#keeping C at 1.0, trying higher iterations</span>
<span class="n">lr_model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;newton-cg&#39;</span><span class="p">,</span><span class="n">multi_class</span><span class="o">=</span><span class="s1">&#39;multinomial&#39;</span><span class="p">,</span><span class="n">C</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span><span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">gs_parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;max_iter&#39;</span><span class="p">:[</span><span class="mi">200</span><span class="p">,</span><span class="mi">500</span><span class="p">,</span><span class="mi">1000</span><span class="p">]}</span>

<span class="n">gs_lr_model</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">lr_model</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">gs_parameters</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;neg_log_loss&quot;</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">cv_sets</span><span class="p">)</span>
<span class="n">gs_lr_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt output_prompt">Out[243]:</div>


<div class="output_text output_subarea output_execute_result">
<pre>GridSearchCV(cv=5, error_score=&#39;raise&#39;,
       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class=&#39;multinomial&#39;,
          n_jobs=1, penalty=&#39;l2&#39;, random_state=0, solver=&#39;newton-cg&#39;,
          tol=0.0001, verbose=0, warm_start=False),
       fit_params={}, iid=True, n_jobs=1,
       param_grid={&#39;max_iter&#39;: [200, 500, 1000]}, pre_dispatch=&#39;2*n_jobs&#39;,
       refit=True, return_train_score=True, scoring=&#39;neg_log_loss&#39;,
       verbose=0)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[244]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">describe_grid_model</span><span class="p">(</span><span class="n">gs_lr_model</span><span class="p">,</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Best Model Score: 0.621135241287
0     {&#39;max_iter&#39;: 200}
1     {&#39;max_iter&#39;: 500}
2    {&#39;max_iter&#39;: 1000}
Name: params, dtype: object
0   -0.630092
1   -0.630092
2   -0.630092
Name: mean_test_score, dtype: float64
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[245]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#saving model</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;final_renthop_lr.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">gs_lr_model</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>

<span class="c1">#getting predictions</span>
<span class="n">nb_kaggle_predictions</span> <span class="o">=</span> <span class="n">gs_lr_model</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">nn_kaggle_test</span><span class="p">)</span>
<span class="c1">#outputing predictions</span>
<span class="n">output_predictions</span><span class="p">(</span><span class="n">nb_kaggle_predictions</span><span class="p">,</span><span class="s2">&quot;lr&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>        listing_id      high    medium       low
0          7142618  0.053951  0.303488  0.642561
1          7210040  0.044526  0.115741  0.839733
100        7103890  0.014787  0.183511  0.801702
1000       7143442  0.237765  0.433806  0.328429
100000     6860601  0.032958  0.287299  0.679744
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="kaggle-test-score:-0.63189">kaggle test score: 0.63189<a class="anchor-link" href="#kaggle-test-score:-0.63189">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="4.4-Random-Forest">4.4 Random Forest<a class="anchor-link" href="#4.4-Random-Forest">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[266]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#getting a preliminary estimate for n_estimators then testing other features before finalizing n_estimators</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="k">import</span> <span class="n">RandomForestClassifier</span>

<span class="n">rf_model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span><span class="n">oob_score</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span><span class="n">class_weight</span><span class="o">=</span><span class="s1">&#39;balanced_subsample&#39;</span><span class="p">,</span>
                                 <span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;gini&#39;</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> 
<span class="n">gs_parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:[</span><span class="mi">10</span><span class="p">,</span><span class="mi">25</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">150</span><span class="p">]}</span> 

<span class="n">gs_rf_model</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">rf_model</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">gs_parameters</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="n">custom_ccv_scorer</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">cv_sets</span><span class="p">)</span>
<span class="n">gs_rf_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\Decoud\Anaconda3\envs\py35\lib\site-packages\sklearn\ensemble\forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.
  warn(&#34;Some inputs do not have OOB scores. &#34;
C:\Users\Decoud\Anaconda3\envs\py35\lib\site-packages\sklearn\ensemble\forest.py:444: RuntimeWarning: invalid value encountered in true_divide
  predictions[k].sum(axis=1)[:, np.newaxis])
C:\Users\Decoud\Anaconda3\envs\py35\lib\site-packages\sklearn\ensemble\forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.
  warn(&#34;Some inputs do not have OOB scores. &#34;
C:\Users\Decoud\Anaconda3\envs\py35\lib\site-packages\sklearn\ensemble\forest.py:444: RuntimeWarning: invalid value encountered in true_divide
  predictions[k].sum(axis=1)[:, np.newaxis])
C:\Users\Decoud\Anaconda3\envs\py35\lib\site-packages\sklearn\ensemble\forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.
  warn(&#34;Some inputs do not have OOB scores. &#34;
C:\Users\Decoud\Anaconda3\envs\py35\lib\site-packages\sklearn\ensemble\forest.py:444: RuntimeWarning: invalid value encountered in true_divide
  predictions[k].sum(axis=1)[:, np.newaxis])
C:\Users\Decoud\Anaconda3\envs\py35\lib\site-packages\sklearn\ensemble\forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.
  warn(&#34;Some inputs do not have OOB scores. &#34;
C:\Users\Decoud\Anaconda3\envs\py35\lib\site-packages\sklearn\ensemble\forest.py:444: RuntimeWarning: invalid value encountered in true_divide
  predictions[k].sum(axis=1)[:, np.newaxis])
C:\Users\Decoud\Anaconda3\envs\py35\lib\site-packages\sklearn\ensemble\forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.
  warn(&#34;Some inputs do not have OOB scores. &#34;
C:\Users\Decoud\Anaconda3\envs\py35\lib\site-packages\sklearn\ensemble\forest.py:444: RuntimeWarning: invalid value encountered in true_divide
  predictions[k].sum(axis=1)[:, np.newaxis])
</pre>
</div>
</div>

<div class="output_area"><div class="prompt output_prompt">Out[266]:</div>


<div class="output_text output_subarea output_execute_result">
<pre>GridSearchCV(cv=5, error_score=&#39;raise&#39;,
       estimator=RandomForestClassifier(bootstrap=True, class_weight=&#39;balanced_subsample&#39;,
            criterion=&#39;gini&#39;, max_depth=None, max_features=&#39;auto&#39;,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=2, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,
            oob_score=True, random_state=0, verbose=0, warm_start=False),
       fit_params={}, iid=True, n_jobs=1,
       param_grid={&#39;n_estimators&#39;: [10, 25, 50, 100, 150]},
       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=True,
       scoring=&lt;function custom_ccv_scorer at 0x0000000032B76840&gt;,
       verbose=0)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[267]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">describe_grid_model</span><span class="p">(</span><span class="n">gs_rf_model</span><span class="p">,</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>CCV Score, Base Model Score: 0.466318529556 , 0.465098380907
0     {&#39;n_estimators&#39;: 10}
1     {&#39;n_estimators&#39;: 25}
2     {&#39;n_estimators&#39;: 50}
3    {&#39;n_estimators&#39;: 100}
4    {&#39;n_estimators&#39;: 150}
Name: params, dtype: object
0   -0.540451
1   -0.497675
2   -0.486718
3   -0.479808
4   -0.478077
Name: mean_test_score, dtype: float64
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[276]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#updating n_estimators then testing max_depth and criterion</span>

<span class="n">rf_model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">150</span><span class="p">,</span><span class="n">oob_score</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span><span class="n">class_weight</span><span class="o">=</span><span class="s1">&#39;balanced_subsample&#39;</span><span class="p">,</span>
                                 <span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;gini&#39;</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> 
<span class="n">gs_parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;max_depth&#39;</span><span class="p">:</span><span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span><span class="s1">&#39;criterion&#39;</span><span class="p">:(</span><span class="s1">&#39;gini&#39;</span><span class="p">,</span><span class="s1">&#39;entropy&#39;</span><span class="p">)}</span>

<span class="n">gs_rf_model</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">rf_model</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">gs_parameters</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="n">custom_ccv_scorer</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">cv_sets</span><span class="p">)</span>
<span class="n">gs_rf_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt output_prompt">Out[276]:</div>


<div class="output_text output_subarea output_execute_result">
<pre>GridSearchCV(cv=5, error_score=&#39;raise&#39;,
       estimator=RandomForestClassifier(bootstrap=True, class_weight=&#39;balanced_subsample&#39;,
            criterion=&#39;gini&#39;, max_depth=None, max_features=&#39;auto&#39;,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=2, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=1,
            oob_score=True, random_state=0, verbose=0, warm_start=False),
       fit_params={}, iid=True, n_jobs=1,
       param_grid={&#39;max_depth&#39;: range(3, 10, 2), &#39;criterion&#39;: (&#39;gini&#39;, &#39;entropy&#39;)},
       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=True,
       scoring=&lt;function custom_ccv_scorer at 0x0000000032B76840&gt;,
       verbose=0)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[277]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">describe_grid_model</span><span class="p">(</span><span class="n">gs_rf_model</span><span class="p">,</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>CCV Score, Base Model Score: 0.550472874549 , 0.696634786462
0       {&#39;max_depth&#39;: 3, &#39;criterion&#39;: &#39;gini&#39;}
1       {&#39;max_depth&#39;: 5, &#39;criterion&#39;: &#39;gini&#39;}
2       {&#39;max_depth&#39;: 7, &#39;criterion&#39;: &#39;gini&#39;}
3       {&#39;max_depth&#39;: 9, &#39;criterion&#39;: &#39;gini&#39;}
4    {&#39;max_depth&#39;: 3, &#39;criterion&#39;: &#39;entropy&#39;}
5    {&#39;max_depth&#39;: 5, &#39;criterion&#39;: &#39;entropy&#39;}
6    {&#39;max_depth&#39;: 7, &#39;criterion&#39;: &#39;entropy&#39;}
7    {&#39;max_depth&#39;: 9, &#39;criterion&#39;: &#39;entropy&#39;}
Name: params, dtype: object
0   -0.619844
1   -0.582617
2   -0.564251
3   -0.542365
4   -0.617129
5   -0.580684
6   -0.561888
7   -0.541111
Name: mean_test_score, dtype: float64
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[278]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#choosing entropy and max_depth of 9</span>
<span class="n">rf_model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">150</span><span class="p">,</span><span class="n">oob_score</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span><span class="n">class_weight</span><span class="o">=</span><span class="s1">&#39;balanced_subsample&#39;</span><span class="p">,</span>
                                 <span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;entropy&#39;</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">9</span><span class="p">,)</span> 
<span class="n">gs_parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;max_features&#39;</span><span class="p">:(</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span><span class="kc">None</span><span class="p">),</span><span class="s1">&#39;min_samples_leaf&#39;</span><span class="p">:[</span><span class="mf">0.05</span><span class="p">,</span><span class="mf">0.10</span><span class="p">,</span><span class="mf">0.20</span><span class="p">]}</span>

<span class="n">gs_rf_model</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">rf_model</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">gs_parameters</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="n">custom_ccv_scorer</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">cv_sets</span><span class="p">)</span>
<span class="n">gs_rf_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt output_prompt">Out[278]:</div>


<div class="output_text output_subarea output_execute_result">
<pre>GridSearchCV(cv=5, error_score=&#39;raise&#39;,
       estimator=RandomForestClassifier(bootstrap=True, class_weight=&#39;balanced_subsample&#39;,
            criterion=&#39;entropy&#39;, max_depth=9, max_features=&#39;auto&#39;,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=1,
            oob_score=True, random_state=0, verbose=0, warm_start=False),
       fit_params={}, iid=True, n_jobs=1,
       param_grid={&#39;max_features&#39;: (&#39;auto&#39;, None), &#39;min_samples_leaf&#39;: [0.05, 0.1, 0.2]},
       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=True,
       scoring=&lt;function custom_ccv_scorer at 0x0000000032B76840&gt;,
       verbose=0)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[279]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">describe_grid_model</span><span class="p">(</span><span class="n">gs_rf_model</span><span class="p">,</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>CCV Score, Base Model Score: 0.629938633661 , 0.865970379992
0    {&#39;max_features&#39;: &#39;auto&#39;, &#39;min_samples_leaf&#39;: 0...
1    {&#39;max_features&#39;: &#39;auto&#39;, &#39;min_samples_leaf&#39;: 0.1}
2    {&#39;max_features&#39;: &#39;auto&#39;, &#39;min_samples_leaf&#39;: 0.2}
3     {&#39;max_features&#39;: None, &#39;min_samples_leaf&#39;: 0.05}
4      {&#39;max_features&#39;: None, &#39;min_samples_leaf&#39;: 0.1}
5      {&#39;max_features&#39;: None, &#39;min_samples_leaf&#39;: 0.2}
Name: params, dtype: object
0   -0.630352
1   -0.660249
2   -0.686606
3   -0.658808
4   -0.684667
5   -0.716437
Name: mean_test_score, dtype: float64
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[280]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#updating with max_features auto and min_samples_leave as 0.05</span>
<span class="c1">#retuning with n_estimators</span>
<span class="n">rf_model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">150</span><span class="p">,</span><span class="n">oob_score</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span><span class="n">class_weight</span><span class="o">=</span><span class="s1">&#39;balanced_subsample&#39;</span><span class="p">,</span>
                                 <span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;entropy&#39;</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span><span class="n">max_features</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span><span class="n">min_samples_leaf</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
<span class="n">gs_parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:[</span><span class="mi">50</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">150</span><span class="p">,</span><span class="mi">200</span><span class="p">,</span><span class="mi">300</span><span class="p">]}</span> 

<span class="n">gs_rf_model</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">rf_model</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">gs_parameters</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="n">custom_ccv_scorer</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">cv_sets</span><span class="p">)</span>
<span class="n">gs_rf_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt output_prompt">Out[280]:</div>


<div class="output_text output_subarea output_execute_result">
<pre>GridSearchCV(cv=5, error_score=&#39;raise&#39;,
       estimator=RandomForestClassifier(bootstrap=True, class_weight=&#39;balanced_subsample&#39;,
            criterion=&#39;entropy&#39;, max_depth=9, max_features=&#39;auto&#39;,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=0.05, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=1,
            oob_score=True, random_state=0, verbose=0, warm_start=False),
       fit_params={}, iid=True, n_jobs=1,
       param_grid={&#39;n_estimators&#39;: [50, 100, 150, 200, 300]},
       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=True,
       scoring=&lt;function custom_ccv_scorer at 0x0000000032B76840&gt;,
       verbose=0)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[281]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#saving model</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;final_renthop_rf.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">gs_rf_model</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>

<span class="c1">#getting predictions</span>
<span class="n">ccv</span> <span class="o">=</span> <span class="n">CalibratedClassifierCV</span><span class="p">(</span><span class="n">gs_rf_model</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s2">&quot;isotonic&quot;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="s2">&quot;prefit&quot;</span><span class="p">)</span>
<span class="n">ccv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span><span class="n">y_val</span><span class="p">)</span> <span class="c1">#fit to overall validation set</span>
<span class="n">nb_kaggle_predictions</span> <span class="o">=</span> <span class="n">ccv</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">nn_kaggle_test</span><span class="p">)</span>
<span class="c1">#nb_kaggle_predictions = gs_knn_model.best_estimator_.predict_proba(nn_kaggle_test)</span>

<span class="c1">#outputing predictions</span>
<span class="n">output_predictions</span><span class="p">(</span><span class="n">nb_kaggle_predictions</span><span class="p">,</span><span class="s2">&quot;rf&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>        listing_id      high    medium       low
0          7142618  0.232205  0.351583  0.416212
1          7210040  0.000000  0.000000  1.000000
100        7103890  0.012847  0.181768  0.805385
1000       7143442  0.314863  0.418233  0.266904
100000     6860601  0.056330  0.387298  0.556373
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[282]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">gs_rf_model</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">,</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="nb">round</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>bathrooms 0.002
bedrooms_modified 0.001
price_modified 0.109
price_per_bed 0.158
created_day 0.0
description_length 0.002
apt_feature_no fee 0.013
manager_count 0.012
manager_low 0.044
manager_medium 0.053
manager_high 0.156
building_count 0.034
building_low 0.077
building_medium 0.106
building_high 0.107
latitude_modified 0.003
longitude_modified 0.006
image_count_range 0.006
created_friday 0.0
created_hour_range 0.009
tf_low_prob 0.043
tf_medium_prob 0.017
tf_high_prob 0.039
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="kaggle-score:-0.78278">kaggle score: 0.78278<a class="anchor-link" href="#kaggle-score:-0.78278">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="4.5-Naive-Bayes">4.5 Naive Bayes<a class="anchor-link" href="#4.5-Naive-Bayes">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[229]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="k">import</span> <span class="n">GaussianNB</span>

<span class="n">bnb_model</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">(</span><span class="n">priors</span><span class="o">=</span><span class="n">benchmark_array</span><span class="p">)</span>
<span class="n">bnb_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">bnb_predictions</span> <span class="o">=</span> <span class="n">bnb_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">bnb_score</span> <span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">bnb_predictions</span><span class="p">,</span><span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>

<span class="c1">#fit the CCV model for later use</span>
<span class="n">bnb_ccv</span> <span class="o">=</span> <span class="n">CalibratedClassifierCV</span><span class="p">(</span><span class="n">bnb_model</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;isotonic&quot;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="s2">&quot;prefit&quot;</span><span class="p">)</span> <span class="c1">#&#39;isotonic&#39; or &#39;sigmoid&#39;</span>
<span class="n">bnb_ccv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span><span class="n">y_val</span><span class="p">)</span>
<span class="n">bnb_ccv_predictions</span> <span class="o">=</span> <span class="n">bnb_ccv</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">bnb_ccv_score</span> <span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">bnb_ccv_predictions</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">bnb_score</span><span class="p">,</span> <span class="n">bnb_ccv_score</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>2.27786481321 0.718408818547
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[230]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#saving model</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;renthop_nb.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">bnb_ccv</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>

<span class="c1">#getting predictions</span>
<span class="n">nb_kaggle_predictions</span> <span class="o">=</span> <span class="n">bnb_ccv</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">nn_kaggle_test</span><span class="p">)</span>
<span class="c1">#outputing predictions</span>
<span class="n">output_predictions</span><span class="p">(</span><span class="n">nb_kaggle_predictions</span><span class="p">,</span><span class="s2">&quot;nb&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>        listing_id      high    medium       low
0          7142618  0.089479  0.335823  0.574698
1          7210040  0.014530  0.055164  0.930306
100        7103890  0.083491  0.298997  0.617512
1000       7143442  0.078564  0.393387  0.528049
100000     6860601  0.037402  0.317728  0.644870
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="kaggle-score-of--0.73364">kaggle score of  0.73364<a class="anchor-link" href="#kaggle-score-of--0.73364">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="4.6-Gradient-Boost">4.6 Gradient Boost<a class="anchor-link" href="#4.6-Gradient-Boost">&#182;</a></h2><p>Some code and the general process was found using <a href="https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/">this article</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[275]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="nn">xgb</span>

<span class="c1">#preliminary guess for n_estimators</span>
<span class="n">gb_model</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">(</span>
 <span class="n">learning_rate</span> <span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
 <span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
 <span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
 <span class="n">min_child_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
 <span class="n">gamma</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
 <span class="n">subsample</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
 <span class="n">colsample_bytree</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
 <span class="n">objective</span><span class="o">=</span> <span class="s1">&#39;binary:logistic&#39;</span><span class="p">,</span>
 <span class="n">scale_pos_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
 <span class="n">nthread</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
 <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1">#Tune max_depth and min_child_weight</span>
<span class="n">param_test1</span> <span class="o">=</span> <span class="p">{</span>
 <span class="s1">&#39;n_estimators&#39;</span><span class="p">:[</span><span class="mi">10</span><span class="p">,</span><span class="mi">25</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">75</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">150</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">gsearch1</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">gb_model</span><span class="p">,</span> 
 <span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_test1</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;neg_log_loss&#39;</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">iid</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv_sets</span><span class="p">)</span>
<span class="n">gsearch1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">gsearch1</span><span class="o">.</span><span class="n">grid_scores_</span><span class="p">,</span> <span class="n">gsearch1</span><span class="o">.</span><span class="n">best_params_</span><span class="p">,</span> <span class="n">gsearch1</span><span class="o">.</span><span class="n">best_score_</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\Decoud\Anaconda3\envs\py35\lib\site-packages\sklearn\model_selection\_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20
  DeprecationWarning)
</pre>
</div>
</div>

<div class="output_area"><div class="prompt output_prompt">Out[275]:</div>


<div class="output_text output_subarea output_execute_result">
<pre>([mean: -0.71950, std: 0.00150, params: {&#39;n_estimators&#39;: 10},
  mean: -0.57009, std: 0.00227, params: {&#39;n_estimators&#39;: 25},
  mean: -0.50574, std: 0.00266, params: {&#39;n_estimators&#39;: 50},
  mean: -0.47644, std: 0.00286, params: {&#39;n_estimators&#39;: 75},
  mean: -0.45615, std: 0.00269, params: {&#39;n_estimators&#39;: 100},
  mean: -0.42702, std: 0.00301, params: {&#39;n_estimators&#39;: 150}],
 {&#39;n_estimators&#39;: 150},
 -0.42701708807001848)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[283]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#update model with n_estimators</span>
<span class="n">gb_model</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">(</span>
 <span class="n">learning_rate</span> <span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
 <span class="n">n_estimators</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span>
 <span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
 <span class="n">min_child_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
 <span class="n">gamma</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
 <span class="n">subsample</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
 <span class="n">colsample_bytree</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
 <span class="n">objective</span><span class="o">=</span> <span class="s1">&#39;binary:logistic&#39;</span><span class="p">,</span>
 <span class="n">scale_pos_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
 <span class="n">nthread</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
 <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1">#Tune max_depth and min_child_weight</span>
<span class="n">param_test1</span> <span class="o">=</span> <span class="p">{</span>
 <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span><span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span>
 <span class="s1">&#39;min_child_weight&#39;</span><span class="p">:</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="p">}</span>

<span class="n">gsearch1</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">gb_model</span><span class="p">,</span> 
 <span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_test1</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;neg_log_loss&#39;</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">iid</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv_sets</span><span class="p">)</span>
<span class="n">gsearch1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">gsearch1</span><span class="o">.</span><span class="n">grid_scores_</span><span class="p">,</span> <span class="n">gsearch1</span><span class="o">.</span><span class="n">best_params_</span><span class="p">,</span> <span class="n">gsearch1</span><span class="o">.</span><span class="n">best_score_</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\Decoud\Anaconda3\envs\py35\lib\site-packages\sklearn\model_selection\_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20
  DeprecationWarning)
</pre>
</div>
</div>

<div class="output_area"><div class="prompt output_prompt">Out[283]:</div>


<div class="output_text output_subarea output_execute_result">
<pre>([mean: -0.48065, std: 0.00318, params: {&#39;max_depth&#39;: 3, &#39;min_child_weight&#39;: 1},
  mean: -0.48072, std: 0.00323, params: {&#39;min_child_weight&#39;: 3, &#39;max_depth&#39;: 3},
  mean: -0.48128, std: 0.00293, params: {&#39;min_child_weight&#39;: 5, &#39;max_depth&#39;: 3},
  mean: -0.42702, std: 0.00301, params: {&#39;min_child_weight&#39;: 1, &#39;max_depth&#39;: 5},
  mean: -0.43039, std: 0.00386, params: {&#39;min_child_weight&#39;: 3, &#39;max_depth&#39;: 5},
  mean: -0.43151, std: 0.00490, params: {&#39;min_child_weight&#39;: 5, &#39;max_depth&#39;: 5},
  mean: -0.38650, std: 0.00232, params: {&#39;min_child_weight&#39;: 1, &#39;max_depth&#39;: 7},
  mean: -0.38867, std: 0.00275, params: {&#39;min_child_weight&#39;: 3, &#39;max_depth&#39;: 7},
  mean: -0.39394, std: 0.00307, params: {&#39;max_depth&#39;: 7, &#39;min_child_weight&#39;: 5},
  mean: -0.35871, std: 0.00301, params: {&#39;min_child_weight&#39;: 1, &#39;max_depth&#39;: 9},
  mean: -0.36008, std: 0.00425, params: {&#39;min_child_weight&#39;: 3, &#39;max_depth&#39;: 9},
  mean: -0.36674, std: 0.00557, params: {&#39;min_child_weight&#39;: 5, &#39;max_depth&#39;: 9}],
 {&#39;max_depth&#39;: 9, &#39;min_child_weight&#39;: 1},
 -0.35870617468534266)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[285]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#update model with max_depth and min_child_weight</span>
<span class="n">gb_model</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">(</span>
 <span class="n">learning_rate</span> <span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
 <span class="n">n_estimators</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span>
 <span class="n">max_depth</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span>
 <span class="n">min_child_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
 <span class="n">gamma</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
 <span class="n">subsample</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
 <span class="n">colsample_bytree</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
 <span class="n">objective</span><span class="o">=</span> <span class="s1">&#39;binary:logistic&#39;</span><span class="p">,</span>
 <span class="n">scale_pos_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
 <span class="n">nthread</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
 <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1">#tune gamma</span>
<span class="n">param_test1</span> <span class="o">=</span> <span class="p">{</span>
 <span class="s1">&#39;gamma&#39;</span><span class="p">:[</span><span class="n">i</span><span class="o">/</span><span class="mf">10.0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">)]</span>
<span class="p">}</span>

<span class="n">gsearch1</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">gb_model</span><span class="p">,</span> 
 <span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_test1</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;neg_log_loss&#39;</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">iid</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv_sets</span><span class="p">)</span>
<span class="n">gsearch1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">gsearch1</span><span class="o">.</span><span class="n">grid_scores_</span><span class="p">,</span> <span class="n">gsearch1</span><span class="o">.</span><span class="n">best_params_</span><span class="p">,</span> <span class="n">gsearch1</span><span class="o">.</span><span class="n">best_score_</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\Decoud\Anaconda3\envs\py35\lib\site-packages\sklearn\model_selection\_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20
  DeprecationWarning)
</pre>
</div>
</div>

<div class="output_area"><div class="prompt output_prompt">Out[285]:</div>


<div class="output_text output_subarea output_execute_result">
<pre>([mean: -0.35871, std: 0.00301, params: {&#39;gamma&#39;: 0.0},
  mean: -0.35547, std: 0.00670, params: {&#39;gamma&#39;: 0.1},
  mean: -0.35706, std: 0.00574, params: {&#39;gamma&#39;: 0.2},
  mean: -0.35620, std: 0.00443, params: {&#39;gamma&#39;: 0.3},
  mean: -0.35731, std: 0.00470, params: {&#39;gamma&#39;: 0.4}],
 {&#39;gamma&#39;: 0.1},
 -0.35546744307829503)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[286]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#update model with gamma</span>
<span class="n">gb_model</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">(</span>
 <span class="n">learning_rate</span> <span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
 <span class="n">n_estimators</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span>
 <span class="n">max_depth</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span>
 <span class="n">min_child_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
 <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
 <span class="n">subsample</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
 <span class="n">colsample_bytree</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
 <span class="n">objective</span><span class="o">=</span> <span class="s1">&#39;binary:logistic&#39;</span><span class="p">,</span>
 <span class="n">scale_pos_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
 <span class="n">nthread</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
 <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1">#Tune subsample and colsample_bytree</span>
<span class="n">param_test1</span> <span class="o">=</span> <span class="p">{</span>
 <span class="s1">&#39;subsample&#39;</span><span class="p">:[</span><span class="n">i</span><span class="o">/</span><span class="mf">10.0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">10</span><span class="p">)],</span>
 <span class="s1">&#39;colsample_bytree&#39;</span><span class="p">:[</span><span class="n">i</span><span class="o">/</span><span class="mf">10.0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">10</span><span class="p">)]</span>
<span class="p">}</span>

<span class="n">gsearch1</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">gb_model</span><span class="p">,</span> 
 <span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_test1</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;neg_log_loss&#39;</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">iid</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv_sets</span><span class="p">)</span>
<span class="n">gsearch1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">gsearch1</span><span class="o">.</span><span class="n">grid_scores_</span><span class="p">,</span> <span class="n">gsearch1</span><span class="o">.</span><span class="n">best_params_</span><span class="p">,</span> <span class="n">gsearch1</span><span class="o">.</span><span class="n">best_score_</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\Decoud\Anaconda3\envs\py35\lib\site-packages\sklearn\model_selection\_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20
  DeprecationWarning)
</pre>
</div>
</div>

<div class="output_area"><div class="prompt output_prompt">Out[286]:</div>


<div class="output_text output_subarea output_execute_result">
<pre>([mean: -0.37402, std: 0.00579, params: {&#39;subsample&#39;: 0.6, &#39;colsample_bytree&#39;: 0.6},
  mean: -0.36735, std: 0.00616, params: {&#39;subsample&#39;: 0.7, &#39;colsample_bytree&#39;: 0.6},
  mean: -0.36359, std: 0.00587, params: {&#39;subsample&#39;: 0.8, &#39;colsample_bytree&#39;: 0.6},
  mean: -0.36405, std: 0.00238, params: {&#39;subsample&#39;: 0.9, &#39;colsample_bytree&#39;: 0.6},
  mean: -0.36996, std: 0.00494, params: {&#39;subsample&#39;: 0.6, &#39;colsample_bytree&#39;: 0.7},
  mean: -0.36302, std: 0.00376, params: {&#39;subsample&#39;: 0.7, &#39;colsample_bytree&#39;: 0.7},
  mean: -0.35885, std: 0.00359, params: {&#39;subsample&#39;: 0.8, &#39;colsample_bytree&#39;: 0.7},
  mean: -0.35614, std: 0.00314, params: {&#39;subsample&#39;: 0.9, &#39;colsample_bytree&#39;: 0.7},
  mean: -0.37150, std: 0.00439, params: {&#39;subsample&#39;: 0.6, &#39;colsample_bytree&#39;: 0.8},
  mean: -0.36347, std: 0.00550, params: {&#39;subsample&#39;: 0.7, &#39;colsample_bytree&#39;: 0.8},
  mean: -0.35547, std: 0.00670, params: {&#39;subsample&#39;: 0.8, &#39;colsample_bytree&#39;: 0.8},
  mean: -0.35246, std: 0.00355, params: {&#39;subsample&#39;: 0.9, &#39;colsample_bytree&#39;: 0.8},
  mean: -0.36857, std: 0.00556, params: {&#39;subsample&#39;: 0.6, &#39;colsample_bytree&#39;: 0.9},
  mean: -0.36293, std: 0.00339, params: {&#39;subsample&#39;: 0.7, &#39;colsample_bytree&#39;: 0.9},
  mean: -0.35548, std: 0.00408, params: {&#39;subsample&#39;: 0.8, &#39;colsample_bytree&#39;: 0.9},
  mean: -0.35231, std: 0.00658, params: {&#39;subsample&#39;: 0.9, &#39;colsample_bytree&#39;: 0.9}],
 {&#39;colsample_bytree&#39;: 0.9, &#39;subsample&#39;: 0.9},
 -0.35231493879967563)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[287]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#update model with subsample and colsample_bytree</span>
<span class="n">gb_model</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">(</span>
 <span class="n">learning_rate</span> <span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
 <span class="n">n_estimators</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span>
 <span class="n">max_depth</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span>
 <span class="n">min_child_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
 <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
 <span class="n">subsample</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
 <span class="n">colsample_bytree</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
 <span class="n">objective</span><span class="o">=</span> <span class="s1">&#39;binary:logistic&#39;</span><span class="p">,</span>
 <span class="n">scale_pos_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
 <span class="n">nthread</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
 <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1">#Tune regularization alpha not doing reg_lambda</span>
<span class="n">param_test1</span> <span class="o">=</span> <span class="p">{</span>
 <span class="s1">&#39;reg_alpha&#39;</span><span class="p">:[</span><span class="mi">1</span><span class="n">e</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="n">e</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">gsearch1</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">gb_model</span><span class="p">,</span> 
 <span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_test1</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;neg_log_loss&#39;</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">iid</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv_sets</span><span class="p">)</span>
<span class="n">gsearch1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">gsearch1</span><span class="o">.</span><span class="n">grid_scores_</span><span class="p">,</span> <span class="n">gsearch1</span><span class="o">.</span><span class="n">best_params_</span><span class="p">,</span> <span class="n">gsearch1</span><span class="o">.</span><span class="n">best_score_</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\Decoud\Anaconda3\envs\py35\lib\site-packages\sklearn\model_selection\_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20
  DeprecationWarning)
</pre>
</div>
</div>

<div class="output_area"><div class="prompt output_prompt">Out[287]:</div>


<div class="output_text output_subarea output_execute_result">
<pre>([mean: -0.35257, std: 0.00692, params: {&#39;reg_alpha&#39;: 1e-05},
  mean: -0.35451, std: 0.00468, params: {&#39;reg_alpha&#39;: 0.01},
  mean: -0.35311, std: 0.00587, params: {&#39;reg_alpha&#39;: 0.1},
  mean: -0.35746, std: 0.00517, params: {&#39;reg_alpha&#39;: 1},
  mean: -0.52574, std: 0.00128, params: {&#39;reg_alpha&#39;: 100}],
 {&#39;reg_alpha&#39;: 1e-05},
 -0.35256663175811553)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[288]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#update model with reg_alpha and lower the learning rate</span>
<span class="n">gb_model</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">(</span>
 <span class="n">learning_rate</span> <span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
 <span class="n">n_estimators</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span>
 <span class="n">max_depth</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span>
 <span class="n">min_child_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
 <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
 <span class="n">subsample</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
 <span class="n">colsample_bytree</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
 <span class="n">objective</span><span class="o">=</span> <span class="s1">&#39;binary:logistic&#39;</span><span class="p">,</span>
 <span class="n">scale_pos_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
 <span class="n">nthread</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
 <span class="n">reg_alpha</span><span class="o">=</span><span class="mi">1</span><span class="n">e</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span>
 <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1">#find a better number for n_estimator</span>
<span class="n">param_test1</span> <span class="o">=</span> <span class="p">{</span>
 <span class="s1">&#39;n_estimators&#39;</span><span class="p">:[</span><span class="mi">50</span><span class="p">,</span><span class="mi">150</span><span class="p">,</span><span class="mi">250</span><span class="p">,</span><span class="mi">400</span><span class="p">,</span><span class="mi">600</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">gsearch1</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">gb_model</span><span class="p">,</span> 
 <span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_test1</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;neg_log_loss&#39;</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">iid</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv_sets</span><span class="p">)</span>
<span class="n">gsearch1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">gsearch1</span><span class="o">.</span><span class="n">grid_scores_</span><span class="p">,</span> <span class="n">gsearch1</span><span class="o">.</span><span class="n">best_params_</span><span class="p">,</span> <span class="n">gsearch1</span><span class="o">.</span><span class="n">best_score_</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\Decoud\Anaconda3\envs\py35\lib\site-packages\sklearn\model_selection\_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20
  DeprecationWarning)
</pre>
</div>
</div>

<div class="output_area"><div class="prompt output_prompt">Out[288]:</div>


<div class="output_text output_subarea output_execute_result">
<pre>([mean: -0.82363, std: 0.00137, params: {&#39;n_estimators&#39;: 50},
  mean: -0.59632, std: 0.00228, params: {&#39;n_estimators&#39;: 150},
  mean: -0.51241, std: 0.00279, params: {&#39;n_estimators&#39;: 250},
  mean: -0.45911, std: 0.00278, params: {&#39;n_estimators&#39;: 400},
  mean: -0.42433, std: 0.00299, params: {&#39;n_estimators&#39;: 600}],
 {&#39;n_estimators&#39;: 600},
 -0.4243278602916159)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[289]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">gb_model</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">(</span>
 <span class="n">learning_rate</span> <span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
 <span class="n">n_estimators</span><span class="o">=</span><span class="mi">600</span><span class="p">,</span>
 <span class="n">max_depth</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span>
 <span class="n">min_child_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
 <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
 <span class="n">subsample</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
 <span class="n">colsample_bytree</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
 <span class="n">objective</span><span class="o">=</span> <span class="s1">&#39;binary:logistic&#39;</span><span class="p">,</span>
 <span class="n">scale_pos_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
 <span class="n">nthread</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
 <span class="n">reg_alpha</span><span class="o">=</span><span class="mi">1</span><span class="n">e</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span>
 <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">gb_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">gb_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">predictions</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>0.417317259778
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[290]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#training model on full training set</span>
<span class="n">gb_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">nn_train</span><span class="p">,</span><span class="n">df_pre_train_label_vector</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt output_prompt">Out[290]:</div>


<div class="output_text output_subarea output_execute_result">
<pre>XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.9,
       gamma=0.1, learning_rate=0.01, max_delta_step=0, max_depth=9,
       min_child_weight=1, missing=None, n_estimators=600, nthread=4,
       objective=&#39;multi:softprob&#39;, reg_alpha=1e-05, reg_lambda=1,
       scale_pos_weight=1, seed=0, silent=True, subsample=0.9)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[303]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#saving model</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;final_renthop_xgboost.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">gb_model</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>

<span class="c1">#getting predictions</span>
<span class="n">nb_kaggle_predictions</span> <span class="o">=</span> <span class="n">gb_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">nn_kaggle_text_xgb</span><span class="p">)</span>
<span class="c1">#outputing predictions</span>
<span class="n">output_predictions</span><span class="p">(</span><span class="n">nb_kaggle_predictions</span><span class="p">,</span><span class="s2">&quot;xgb&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>        listing_id      high    medium       low
0          7142618  0.090964  0.423204  0.485832
1          7210040  0.487916  0.199452  0.312633
100        7103890  0.027234  0.207823  0.764943
1000       7143442  0.125767  0.526609  0.347624
100000     6860601  0.033823  0.255509  0.710668
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[304]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">feat_imp</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">gb_model</span><span class="o">.</span><span class="n">booster</span><span class="p">()</span><span class="o">.</span><span class="n">get_fscore</span><span class="p">())</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">feat_imp</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Feature Importances&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Feature Importance Score&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>


<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAZUAAAFjCAYAAAD1kJY/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="kaggle-score:-0.73656">kaggle score: 0.73656<a class="anchor-link" href="#kaggle-score:-0.73656">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="4.7-SGD-Classifier">4.7 SGD Classifier<a class="anchor-link" href="#4.7-SGD-Classifier">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[263]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="k">import</span> <span class="n">SGDClassifier</span>

<span class="n">sgd_model</span> <span class="o">=</span> <span class="n">SGDClassifier</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;modified_huber&#39;</span><span class="p">,</span><span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l2&#39;</span><span class="p">,</span><span class="n">n_iter</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span><span class="n">class_weight</span><span class="o">=</span><span class="s1">&#39;balanced&#39;</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="s1">&#39;optimal&#39;</span><span class="p">)</span>

<span class="n">gs_parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_iter&#39;</span><span class="p">:[</span><span class="mi">100</span><span class="p">,</span><span class="mi">300</span><span class="p">,</span><span class="mi">500</span><span class="p">]}</span>

<span class="n">gs_sgd_model</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">sgd_model</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">gs_parameters</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="n">custom_ccv_scorer</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">cv_sets</span><span class="p">)</span>
<span class="n">gs_sgd_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt output_prompt">Out[263]:</div>


<div class="output_text output_subarea output_execute_result">
<pre>GridSearchCV(cv=5, error_score=&#39;raise&#39;,
       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=&#39;balanced&#39;,
       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,
       learning_rate=&#39;optimal&#39;, loss=&#39;modified_huber&#39;, n_iter=300,
       n_jobs=1, penalty=&#39;l2&#39;, power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False),
       fit_params={}, iid=True, n_jobs=1,
       param_grid={&#39;n_iter&#39;: [100, 300, 500]}, pre_dispatch=&#39;2*n_jobs&#39;,
       refit=True, return_train_score=True,
       scoring=&lt;function custom_ccv_scorer at 0x0000000032B76840&gt;,
       verbose=0)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[264]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">describe_grid_model</span><span class="p">(</span><span class="n">gs_sgd_model</span><span class="p">,</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>CCV Score, Base Model Score: 0.639241692757 , 0.905593116751
0    {&#39;n_iter&#39;: 100}
1    {&#39;n_iter&#39;: 300}
2    {&#39;n_iter&#39;: 500}
Name: params, dtype: object
0   -0.666612
1   -0.656782
2   -0.648176
Name: mean_test_score, dtype: float64
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[265]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#saving model</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;final_renthop_sgd.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">gs_sgd_model</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>

<span class="c1">#getting predictions</span>
<span class="n">ccv</span> <span class="o">=</span> <span class="n">CalibratedClassifierCV</span><span class="p">(</span><span class="n">gs_sgd_model</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s2">&quot;isotonic&quot;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="s2">&quot;prefit&quot;</span><span class="p">)</span>
<span class="n">ccv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span><span class="n">y_val</span><span class="p">)</span> <span class="c1">#fit to overall validation set</span>
<span class="n">nb_kaggle_predictions</span> <span class="o">=</span> <span class="n">ccv</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">nn_kaggle_test</span><span class="p">)</span>
<span class="c1">#outputing predictions</span>
<span class="n">output_predictions</span><span class="p">(</span><span class="n">nb_kaggle_predictions</span><span class="p">,</span><span class="s2">&quot;sgd&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>        listing_id      high    medium       low
0          7142618  0.100518  0.255474  0.644008
1          7210040  0.020695  0.138293  0.841011
100        7103890  0.037359  0.182441  0.780201
1000       7143442  0.275641  0.386056  0.338303
100000     6860601  0.026237  0.268333  0.705430
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="kaggle-score:-0.65002">kaggle score: 0.65002<a class="anchor-link" href="#kaggle-score:-0.65002">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="4.8-Adaboost">4.8 Adaboost<a class="anchor-link" href="#4.8-Adaboost">&#182;</a></h2><p>First GridSearch on DecisionTreeClassifier to fine tune it. Then RandomizedSearch to fine tune the AdaBoost model.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[253]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="k">import</span> <span class="n">AdaBoostClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="k">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">RandomizedSearchCV</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="k">import</span> <span class="n">randint</span> <span class="k">as</span> <span class="n">sp_randint</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="k">import</span> <span class="n">uniform</span> <span class="k">as</span> <span class="n">sp_rand</span>

<span class="n">dtc</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">class_weight</span><span class="o">=</span><span class="s1">&#39;balanced&#39;</span><span class="p">)</span>

<span class="n">ada_model</span> <span class="o">=</span> <span class="n">AdaBoostClassifier</span><span class="p">(</span>
    <span class="n">dtc</span><span class="p">,</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="n">gs_parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;base_estimator__criterion&quot;</span> <span class="p">:</span> <span class="p">[</span><span class="s2">&quot;gini&quot;</span><span class="p">,</span> <span class="s2">&quot;entropy&quot;</span><span class="p">],</span>
              <span class="s2">&quot;base_estimator__splitter&quot;</span> <span class="p">:</span>   <span class="p">[</span><span class="s2">&quot;best&quot;</span><span class="p">,</span> <span class="s2">&quot;random&quot;</span><span class="p">],</span>
                 <span class="s2">&quot;base_estimator__max_depth&quot;</span> <span class="p">:</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span>
                 <span class="s2">&quot;base_estimator__max_features&quot;</span><span class="p">:[</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span><span class="kc">None</span><span class="p">]</span>
             <span class="p">}</span>

<span class="n">gs_ada_model</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">ada_model</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">gs_parameters</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="n">custom_ccv_scorer</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">cv_sets</span><span class="p">)</span>
<span class="n">gs_ada_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt output_prompt">Out[253]:</div>


<div class="output_text output_subarea output_execute_result">
<pre>GridSearchCV(cv=5, error_score=&#39;raise&#39;,
       estimator=AdaBoostClassifier(algorithm=&#39;SAMME.R&#39;,
          base_estimator=DecisionTreeClassifier(class_weight=&#39;balanced&#39;, criterion=&#39;gini&#39;,
            max_depth=None, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter=&#39;best&#39;),
          learning_rate=1.0, n_estimators=50, random_state=None),
       fit_params={}, iid=True, n_jobs=1,
       param_grid={&#39;base_estimator__splitter&#39;: [&#39;best&#39;, &#39;random&#39;], &#39;base_estimator__criterion&#39;: [&#39;gini&#39;, &#39;entropy&#39;], &#39;base_estimator__max_depth&#39;: range(3, 9, 2), &#39;base_estimator__max_features&#39;: [&#39;auto&#39;, None]},
       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=True,
       scoring=&lt;function custom_ccv_scorer at 0x0000000032B76840&gt;,
       verbose=0)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[255]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">describe_grid_model</span><span class="p">(</span><span class="n">gs_ada_model</span><span class="p">,</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>CCV Score, Base Model Score: 0.516917406143 , 0.837728278731
0     {&#39;base_estimator__splitter&#39;: &#39;best&#39;, &#39;base_est...
1     {&#39;base_estimator__splitter&#39;: &#39;random&#39;, &#39;base_e...
2     {&#39;base_estimator__splitter&#39;: &#39;best&#39;, &#39;base_est...
3     {&#39;base_estimator__splitter&#39;: &#39;random&#39;, &#39;base_e...
4     {&#39;base_estimator__splitter&#39;: &#39;best&#39;, &#39;base_est...
5     {&#39;base_estimator__splitter&#39;: &#39;random&#39;, &#39;base_e...
6     {&#39;base_estimator__splitter&#39;: &#39;best&#39;, &#39;base_est...
7     {&#39;base_estimator__splitter&#39;: &#39;random&#39;, &#39;base_e...
8     {&#39;base_estimator__splitter&#39;: &#39;best&#39;, &#39;base_est...
9     {&#39;base_estimator__splitter&#39;: &#39;random&#39;, &#39;base_e...
10    {&#39;base_estimator__splitter&#39;: &#39;best&#39;, &#39;base_est...
11    {&#39;base_estimator__splitter&#39;: &#39;random&#39;, &#39;base_e...
12    {&#39;base_estimator__splitter&#39;: &#39;best&#39;, &#39;base_est...
13    {&#39;base_estimator__splitter&#39;: &#39;random&#39;, &#39;base_e...
14    {&#39;base_estimator__splitter&#39;: &#39;best&#39;, &#39;base_est...
15    {&#39;base_estimator__splitter&#39;: &#39;random&#39;, &#39;base_e...
16    {&#39;base_estimator__splitter&#39;: &#39;best&#39;, &#39;base_est...
17    {&#39;base_estimator__splitter&#39;: &#39;random&#39;, &#39;base_e...
18    {&#39;base_estimator__splitter&#39;: &#39;best&#39;, &#39;base_est...
19    {&#39;base_estimator__splitter&#39;: &#39;random&#39;, &#39;base_e...
20    {&#39;base_estimator__splitter&#39;: &#39;best&#39;, &#39;base_est...
21    {&#39;base_estimator__splitter&#39;: &#39;random&#39;, &#39;base_e...
22    {&#39;base_estimator__splitter&#39;: &#39;best&#39;, &#39;base_est...
23    {&#39;base_estimator__splitter&#39;: &#39;random&#39;, &#39;base_e...
Name: params, dtype: object
0    -0.570828
1    -0.639542
2    -0.518839
3    -0.578762
4    -0.588313
5    -0.613843
6    -0.524370
7    -0.604261
8    -0.618205
9    -0.621968
10   -0.603117
11   -0.638394
12   -0.589274
13   -0.616118
14   -0.548447
15   -0.599301
16   -0.593777
17   -0.616129
18   -0.544561
19   -0.607344
20   -0.619884
21   -0.624224
22   -0.574145
23   -0.635947
Name: mean_test_score, dtype: float64
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[257]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#print(gs_ada_model.cv_results_[&#39;params&#39;])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">gs_ada_model</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>AdaBoostClassifier(algorithm=&#39;SAMME.R&#39;,
          base_estimator=DecisionTreeClassifier(class_weight=&#39;balanced&#39;, criterion=&#39;gini&#39;, max_depth=3,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter=&#39;best&#39;),
          learning_rate=1.0, n_estimators=50, random_state=None)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[258]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dtc</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">class_weight</span><span class="o">=</span><span class="s1">&#39;balanced&#39;</span><span class="p">,</span><span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;gini&#39;</span><span class="p">,</span><span class="n">splitter</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">,</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">max_features</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

<span class="n">ada_model</span> <span class="o">=</span> <span class="n">AdaBoostClassifier</span><span class="p">(</span>
    <span class="n">dtc</span><span class="p">,</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;search_parameters = {&#39;n_estimators&#39;:sp_randint(30,301),</span>
<span class="sd">                    &#39;learning_rate&#39;:sp_randint(0,2)}&#39;&#39;&#39;</span>

<span class="n">search_parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span><span class="n">sp_randint</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span><span class="mi">1001</span><span class="p">),</span>
                    <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span><span class="n">sp_rand</span><span class="p">(</span><span class="o">.</span><span class="mi">001</span><span class="p">,</span><span class="mf">1.0</span><span class="p">)}</span>

<span class="n">rs_ada_model</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">ada_model</span><span class="p">,</span><span class="n">param_distributions</span><span class="o">=</span><span class="n">search_parameters</span><span class="p">,</span>
                                  <span class="n">scoring</span><span class="o">=</span><span class="n">custom_ccv_scorer</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">cv_sets</span><span class="p">,</span><span class="n">n_iter</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">rs_ada_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt output_prompt">Out[258]:</div>


<div class="output_text output_subarea output_execute_result">
<pre>RandomizedSearchCV(cv=5, error_score=&#39;raise&#39;,
          estimator=AdaBoostClassifier(algorithm=&#39;SAMME.R&#39;,
          base_estimator=DecisionTreeClassifier(class_weight=&#39;balanced&#39;, criterion=&#39;gini&#39;, max_depth=3,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter=&#39;best&#39;),
          learning_rate=1.0, n_estimators=100, random_state=None),
          fit_params={}, iid=True, n_iter=20, n_jobs=1,
          param_distributions={&#39;learning_rate&#39;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x000000003536EB70&gt;, &#39;n_estimators&#39;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x000000003536E940&gt;},
          pre_dispatch=&#39;2*n_jobs&#39;, random_state=None, refit=True,
          return_train_score=True,
          scoring=&lt;function custom_ccv_scorer at 0x0000000032B76840&gt;,
          verbose=0)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[260]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">describe_grid_model</span><span class="p">(</span><span class="n">rs_ada_model</span><span class="p">,</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>CCV Score, Base Model Score: 0.467816264238 , 0.980443885228
0     {&#39;learning_rate&#39;: 0.79782021625, &#39;n_estimators...
1     {&#39;learning_rate&#39;: 0.646144132692, &#39;n_estimator...
2     {&#39;learning_rate&#39;: 0.487509747643, &#39;n_estimator...
3     {&#39;learning_rate&#39;: 0.373236699566, &#39;n_estimator...
4     {&#39;learning_rate&#39;: 0.45789264759, &#39;n_estimators...
5     {&#39;learning_rate&#39;: 0.842987324563, &#39;n_estimator...
6     {&#39;learning_rate&#39;: 0.211908149264, &#39;n_estimator...
7     {&#39;learning_rate&#39;: 0.969526923624, &#39;n_estimator...
8     {&#39;learning_rate&#39;: 0.0434287052497, &#39;n_estimato...
9     {&#39;learning_rate&#39;: 0.55042017021, &#39;n_estimators...
10    {&#39;learning_rate&#39;: 0.0658889965366, &#39;n_estimato...
11    {&#39;learning_rate&#39;: 0.121478951209, &#39;n_estimator...
12    {&#39;learning_rate&#39;: 0.926309223155, &#39;n_estimator...
13    {&#39;learning_rate&#39;: 0.0274101532425, &#39;n_estimato...
14    {&#39;learning_rate&#39;: 0.357365278038, &#39;n_estimator...
15    {&#39;learning_rate&#39;: 0.986828879872, &#39;n_estimator...
16    {&#39;learning_rate&#39;: 0.83460471761, &#39;n_estimators...
17    {&#39;learning_rate&#39;: 0.835072629245, &#39;n_estimator...
18    {&#39;learning_rate&#39;: 0.533831404422, &#39;n_estimator...
19    {&#39;learning_rate&#39;: 0.800684228589, &#39;n_estimator...
Name: params, dtype: object
0    -0.501865
1    -0.498409
2    -0.506523
3    -0.490711
4    -0.490449
5    -0.493548
6    -0.495222
7    -0.524566
8    -0.491569
9    -0.499134
10   -0.497335
11   -0.484004
12   -0.513638
13   -0.511236
14   -0.489624
15   -0.521478
16   -0.510051
17   -0.506144
18   -0.503281
19   -0.506397
Name: mean_test_score, dtype: float64
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[261]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#saving model</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;final_renthop_ada.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">rs_ada_model</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>

<span class="c1">#getting predictions</span>
<span class="n">ccv</span> <span class="o">=</span> <span class="n">CalibratedClassifierCV</span><span class="p">(</span><span class="n">rs_ada_model</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s2">&quot;isotonic&quot;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="s2">&quot;prefit&quot;</span><span class="p">)</span>
<span class="n">ccv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span><span class="n">y_val</span><span class="p">)</span> <span class="c1">#fit to overall validation set</span>
<span class="n">nb_kaggle_predictions</span> <span class="o">=</span> <span class="n">ccv</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">nn_kaggle_test</span><span class="p">)</span>
<span class="c1">#nb_kaggle_predictions = gs_knn_model.best_estimator_.predict_proba(nn_kaggle_test)</span>

<span class="c1">#outputing predictions</span>
<span class="n">output_predictions</span><span class="p">(</span><span class="n">nb_kaggle_predictions</span><span class="p">,</span><span class="s2">&quot;ada&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>        listing_id      high    medium       low
0          7142618  0.186254  0.342869  0.470877
1          7210040  0.000000  0.000000  1.000000
100        7103890  0.040376  0.275108  0.684517
1000       7143442  0.006255  0.275739  0.718006
100000     6860601  0.015904  0.256040  0.728056
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[262]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">rs_ada_model</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">,</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="nb">round</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>bathrooms 0.005
bedrooms_modified 0.005
price_modified 0.096
price_per_bed 0.085
created_day 0.023
description_length 0.049
apt_feature_no fee 0.02
manager_count 0.015
manager_low 0.101
manager_medium 0.092
manager_high 0.089
building_count 0.014
building_low 0.056
building_medium 0.039
building_high 0.043
latitude_modified 0.092
longitude_modified 0.074
image_count_range 0.006
created_friday 0.001
created_hour_range 0.013
tf_low_prob 0.02
tf_medium_prob 0.031
tf_high_prob 0.03
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="kaggle-score-of-2.01938">kaggle score of 2.01938<a class="anchor-link" href="#kaggle-score-of-2.01938">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="4.9-K-Nearest-Neighbors">4.9 K Nearest Neighbors<a class="anchor-link" href="#4.9-K-Nearest-Neighbors">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[246]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="k">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">GridSearchCV</span>

<span class="n">knn_model</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">weights</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span><span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>

<span class="c1">#testing weights and p first</span>
<span class="n">gs_parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;weights&#39;</span><span class="p">:(</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span><span class="s1">&#39;distance&#39;</span><span class="p">),</span><span class="s1">&#39;p&#39;</span><span class="p">:[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]}</span>

<span class="n">gs_knn_model</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">knn_model</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">gs_parameters</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="n">custom_ccv_scorer</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">cv_sets</span><span class="p">)</span>
<span class="n">gs_knn_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt output_prompt">Out[246]:</div>


<div class="output_text output_subarea output_execute_result">
<pre>GridSearchCV(cv=5, error_score=&#39;raise&#39;,
       estimator=KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights=&#39;uniform&#39;),
       fit_params={}, iid=True, n_jobs=1,
       param_grid={&#39;p&#39;: [1, 2], &#39;weights&#39;: (&#39;uniform&#39;, &#39;distance&#39;)},
       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=True,
       scoring=&lt;function custom_ccv_scorer at 0x0000000032B76840&gt;,
       verbose=0)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[247]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">describe_grid_model</span><span class="p">(</span><span class="n">gs_knn_model</span><span class="p">,</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>CCV Score, Base Model Score: 0.664731285745 , 2.64690908746
0     {&#39;p&#39;: 1, &#39;weights&#39;: &#39;uniform&#39;}
1    {&#39;p&#39;: 1, &#39;weights&#39;: &#39;distance&#39;}
2     {&#39;p&#39;: 2, &#39;weights&#39;: &#39;uniform&#39;}
3    {&#39;p&#39;: 2, &#39;weights&#39;: &#39;distance&#39;}
Name: params, dtype: object
0   -0.684538
1   -0.717288
2   -0.703128
3   -0.743472
Name: mean_test_score, dtype: float64
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[248]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#uniform and p=1 the best parameters</span>
<span class="c1">#deciding on number of neighbors </span>
<span class="n">knn_model</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">weights</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span><span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span><span class="n">p</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">gs_parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_neighbors&#39;</span><span class="p">:[</span><span class="mi">5</span><span class="p">,</span><span class="mi">15</span><span class="p">,</span><span class="mi">25</span><span class="p">]}</span>

<span class="n">gs_knn_model</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">knn_model</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">gs_parameters</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="n">custom_ccv_scorer</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">cv_sets</span><span class="p">)</span>
<span class="n">gs_knn_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt output_prompt">Out[248]:</div>


<div class="output_text output_subarea output_execute_result">
<pre>GridSearchCV(cv=5, error_score=&#39;raise&#39;,
       estimator=KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
           metric_params=None, n_jobs=1, n_neighbors=5, p=1,
           weights=&#39;uniform&#39;),
       fit_params={}, iid=True, n_jobs=1,
       param_grid={&#39;n_neighbors&#39;: [5, 15, 25]}, pre_dispatch=&#39;2*n_jobs&#39;,
       refit=True, return_train_score=True,
       scoring=&lt;function custom_ccv_scorer at 0x0000000032B76840&gt;,
       verbose=0)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[249]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">describe_grid_model</span><span class="p">(</span><span class="n">gs_knn_model</span><span class="p">,</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>CCV Score, Base Model Score: 0.627033297075 , 0.796548991942
0     {&#39;n_neighbors&#39;: 5}
1    {&#39;n_neighbors&#39;: 15}
2    {&#39;n_neighbors&#39;: 25}
Name: params, dtype: object
0   -0.684538
1   -0.650430
2   -0.642740
Name: mean_test_score, dtype: float64
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[251]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#saving model</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;final_renthop_knn.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">gs_knn_model</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>

<span class="c1">#getting predictions</span>
<span class="n">ccv</span> <span class="o">=</span> <span class="n">CalibratedClassifierCV</span><span class="p">(</span><span class="n">gs_knn_model</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s2">&quot;isotonic&quot;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="s2">&quot;prefit&quot;</span><span class="p">)</span>
<span class="n">ccv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span><span class="n">y_val</span><span class="p">)</span> <span class="c1">#fit to overall validation set</span>
<span class="n">nb_kaggle_predictions</span> <span class="o">=</span> <span class="n">ccv</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">nn_kaggle_test</span><span class="p">)</span>
<span class="c1">#nb_kaggle_predictions = gs_knn_model.best_estimator_.predict_proba(nn_kaggle_test)</span>

<span class="c1">#outputing predictions</span>
<span class="n">output_predictions</span><span class="p">(</span><span class="n">nb_kaggle_predictions</span><span class="p">,</span><span class="s2">&quot;knn&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>        listing_id      high    medium       low
0          7142618  0.126276  0.410624  0.463101
1          7210040  0.035900  0.072810  0.891291
100        7103890  0.009496  0.275372  0.715132
1000       7143442  0.227835  0.345687  0.426478
100000     6860601  0.009060  0.241428  0.749512
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="kaggle-score:-0.65466">kaggle score: 0.65466<a class="anchor-link" href="#kaggle-score:-0.65466">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="4.10-Voting-Classifier">4.10 Voting Classifier<a class="anchor-link" href="#4.10-Voting-Classifier">&#182;</a></h2><p>Since the Adaboost model scored so poorly, I'm not including it in the Voting Classifier. The rest of the models are weighted equally.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[305]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="k">import</span> <span class="n">VotingClassifier</span>
<span class="c1">#rf: 0.78278; gs_rf_model.best_estimator_ </span>
<span class="c1">#lr: 0.63189; gs_lr_model.best_estimator_</span>
<span class="c1">#knn: 0.65466; gs_knn_model.best_estimator_</span>
<span class="c1">#nb: 0.73364; bnb_model</span>
<span class="c1">#sgd: 0.65002; gs_sgd_model.best_estimator_</span>
<span class="c1">#gb: 0.73656; gb_model</span>
<span class="c1">#ada: 2.01938; rs_ada_model.best_estimator_ #(&#39;ada&#39;, rs_ada_model.best_estimator_)</span>
<span class="c1">#nn: 0.60874</span>
<span class="c1">#vc_model = VotingClassifier(estimators=[(&#39;dt&#39;, clf1), (&#39;knn&#39;, clf2), (&#39;svc&#39;, clf3)], voting=&#39;soft&#39;, weights=[2,1,2])</span>

<span class="n">vc_model</span> <span class="o">=</span> <span class="n">VotingClassifier</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;rf&#39;</span><span class="p">,</span> <span class="n">gs_rf_model</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="n">gs_lr_model</span><span class="p">),</span> 
                                        <span class="p">(</span><span class="s1">&#39;knn&#39;</span><span class="p">,</span> <span class="n">gs_knn_model</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;gb&#39;</span><span class="p">,</span> <span class="n">gb_model</span><span class="p">),</span> 
                                        <span class="p">(</span><span class="s1">&#39;nb&#39;</span><span class="p">,</span> <span class="n">bnb_model</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;sgd&#39;</span><span class="p">,</span> <span class="n">gs_sgd_model</span><span class="p">)],</span> 
                            <span class="n">voting</span><span class="o">=</span><span class="s1">&#39;soft&#39;</span><span class="p">)</span>

<span class="n">vc_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">vc_predictions</span> <span class="o">=</span> <span class="n">vc_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">vc_score</span> <span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">vc_predictions</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vc_score</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>0.61931736473
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[306]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#training model on full training set</span>
<span class="n">vc_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">nn_train</span><span class="p">,</span><span class="n">df_pre_train_label_vector</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt output_prompt">Out[306]:</div>


<div class="output_text output_subarea output_execute_result">
<pre>VotingClassifier(estimators=[(&#39;rf&#39;, RandomForestClassifier(bootstrap=True, class_weight=&#39;balanced_subsample&#39;,
            criterion=&#39;entropy&#39;, max_depth=9, max_features=&#39;auto&#39;,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=0.05, min_samples_split=2,
            min_weight_fr...n_score=True,
       scoring=&lt;function custom_ccv_scorer at 0x0000000032B76840&gt;,
       verbose=0))],
         n_jobs=1, voting=&#39;soft&#39;, weights=None)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[308]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#saving model</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;final_renthop_vc.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">vc_model</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>

<span class="c1">#getting predictions</span>
<span class="n">nb_kaggle_predictions</span> <span class="o">=</span> <span class="n">vc_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">nn_kaggle_text_xgb</span><span class="p">)</span>

<span class="c1">#outputing predictions</span>
<span class="n">output_predictions</span><span class="p">(</span><span class="n">nb_kaggle_predictions</span><span class="p">,</span><span class="s2">&quot;vc&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>        listing_id      high    medium       low
0          7142618  0.187493  0.429429  0.383078
1          7210040  0.129772  0.131496  0.738732
100        7103890  0.082758  0.343648  0.573594
1000       7143442  0.294752  0.462539  0.242709
100000     6860601  0.095749  0.432345  0.471906
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="kaggle-score:-0.68491">kaggle score: 0.68491<a class="anchor-link" href="#kaggle-score:-0.68491">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="5.0-Conclusion">5.0 Conclusion<a class="anchor-link" href="#5.0-Conclusion">&#182;</a></h1><p>It's hard to know how to end a project such as this one as there is no correct or final answer. On my withheld test set, I can overfit several models (xgboost, neural net, and voting classifier) to a log loss much lower than what is on the kaggle leaderboard. However when I use that overfitted model on the kaggle test set I predictably score much lower. I can continue to fit and tune the most promising models and get better scores on kaggle but even that does not guarantee that the model is actually better. I may just be overfitting to the revealed portion of the kaggle test set and not actually generalizing well to the hidden portion of the kaggle test set. The best model I came up with was the feedforward neural net, followed by the second logistic regression model. The voting classifier for the second batch of models performed worse than the voting classifier for the first batch of models, despite the second version of most of my individual models performing better than their respective first versions.<br/></p>
<p>While I learned many things by working on this dataset, the main discovery I had was how much there is to know and how many different directions solving a problem such as this one can take. As I worked on the project, I wrote a list of ideas to try and directions to explore. While I implemented and explored some of them, going through the entire list would take months at least and likely lead to many different techniques to try. It's also difficult to tell how successful each attempt is as there are a multitude of factors that can influence the measures of success. My experience here emphasizes to me the importance of pipelines, being able to make incremental changes, analyze the results, and then hopefully improve the model.<br/></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
    </div>
  </div>
</body>
</html>
